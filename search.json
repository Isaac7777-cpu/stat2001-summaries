[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "This site is your companion for revising STAT2001: Introductory Mathematical Statistics at ANU. Whether you‚Äôre preparing for exams or reinforcing weekly concepts, you‚Äôll find concise summaries, worked examples, and practice materials here.\n\n\n\nThe content is structured to mirror the STAT2001 curriculum:\n\nProbability Foundations: Set theory, combinatorics, and Bayes‚Äô theorem.\nRandom Variables: Discrete and continuous distributions, including moment-generating functions and correlation.\nMultivariate Distributions: Joint, marginal, and conditional distributions.\nSampling Distributions: Understanding the central limit theorem and its applications.\nEstimation Techniques: Methods of moments and maximum likelihood estimation.\nHypothesis Testing: Formulating and testing statistical hypotheses.\nBayesian Statistics: Introduction to Bayesian inference and estimators.\n\n\n\n\n\nAll examples and exercises are implemented using R, the primary statistical computing tool for this course. You‚Äôll also find:\n\nInteractive visualizations to aid understanding.\nCheatsheets summarizing key formulas and concepts.\nPractice questions with step-by-step solutions.\n\n\n\n\n\nNavigate to the Topics page to begin exploring specific areas of the course. For more information about this site, visit the About page.\n\nNote: This site is an independent student-led initiative and is not officially affiliated with ANU."
  },
  {
    "objectID": "index.html#topics-covered",
    "href": "index.html#topics-covered",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "The content is structured to mirror the STAT2001 curriculum:\n\nProbability Foundations: Set theory, combinatorics, and Bayes‚Äô theorem.\nRandom Variables: Discrete and continuous distributions, including moment-generating functions and correlation.\nMultivariate Distributions: Joint, marginal, and conditional distributions.\nSampling Distributions: Understanding the central limit theorem and its applications.\nEstimation Techniques: Methods of moments and maximum likelihood estimation.\nHypothesis Testing: Formulating and testing statistical hypotheses.\nBayesian Statistics: Introduction to Bayesian inference and estimators."
  },
  {
    "objectID": "index.html#tools-and-resources",
    "href": "index.html#tools-and-resources",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "All examples and exercises are implemented using R, the primary statistical computing tool for this course. You‚Äôll also find:\n\nInteractive visualizations to aid understanding.\nCheatsheets summarizing key formulas and concepts.\nPractice questions with step-by-step solutions."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "Navigate to the Topics page to begin exploring specific areas of the course. For more information about this site, visit the About page.\n\nNote: This site is an independent student-led initiative and is not officially affiliated with ANU."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "1\n\n\n\n\nüìß Email: isaac.leong@example.com\n\nüíº LinkedIn: linkedin.com/in/isaac-leong\n\nüßë‚Äçüíª GitHub: github.com/Isaac7777-cpu\n\nüìç Location: Canberra, Australia"
  },
  {
    "objectID": "contact.html#contact",
    "href": "contact.html#contact",
    "title": "Contact",
    "section": "",
    "text": "1\n\n\n\n\nüìß Email: isaac.leong@example.com\n\nüíº LinkedIn: linkedin.com/in/isaac-leong\n\nüßë‚Äçüíª GitHub: github.com/Isaac7777-cpu\n\nüìç Location: Canberra, Australia"
  },
  {
    "objectID": "contact.html#footnotes",
    "href": "contact.html#footnotes",
    "title": "Contact",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is just an unrelated photo that I think tastes pretty good.‚Ü©Ô∏é"
  },
  {
    "objectID": "contents/chapter-08/index.html",
    "href": "contents/chapter-08/index.html",
    "title": "Estimation",
    "section": "",
    "text": "This chapter is about estimation of the distribution parameters in general. There are four main aspects that we are going to cover here.\n\nPoint Estimation\nEvaluation Statistics for a Point Estimation\nInterval Estimation\nMonte-Carlo Method\n\nOverall, this is almost the peak of this course as everything we have learnt and will learn is built around this topic.",
    "crumbs": [
      "Home",
      "CH08 : Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/4monte-carlo-method.html",
    "href": "contents/chapter-08/4monte-carlo-method.html",
    "title": "Estimation via Monte Carlo Methods",
    "section": "",
    "text": "This is basically like Dr.¬†Strange in the Infinity War that will go into the future and look at all possible outcomes.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Estimation via Monte Carlo Methods"
    ]
  },
  {
    "objectID": "contents/chapter-08/4monte-carlo-method.html#motivating-problem",
    "href": "contents/chapter-08/4monte-carlo-method.html#motivating-problem",
    "title": "Estimation via Monte Carlo Methods",
    "section": "1 Motivating Problem",
    "text": "1 Motivating Problem\n\nExample 1 (Buffon‚Äôs Needle Problem) A kitchen floor has a pattern of parallel lines that are \\(10\\)cm apart. You have a needle in your hand that is also \\(10\\)cm long. If you randomly throw the needle onto the floor, what is the probability \\(p\\) that it will cross a line?",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Estimation via Monte Carlo Methods"
    ]
  },
  {
    "objectID": "contents/chapter-08/4monte-carlo-method.html#monte-carlo-methods",
    "href": "contents/chapter-08/4monte-carlo-method.html#monte-carlo-methods",
    "title": "Estimation via Monte Carlo Methods",
    "section": "2 Monte Carlo Methods",
    "text": "2 Monte Carlo Methods\nIt is hard to find \\(p\\) exactly. However, it can be approximated simply, as follows.\n\nSolution. We throw the needle onto the floor \\(n = 1000\\) times, and find that the needle crosses a line \\(651\\) times (say). Then an unbiased estimate of \\(p\\) is \\(\\hat{p} = 651/1000= 0.651\\), and a \\(95%\\) CI for \\(p\\) is \\((0.651 \\pm 1.96\\sqrt{0.651(1 - 0.651)/1000)} = (0.621, 0.681)\\). Note that we could get a narrower CI simply by increasing n.¬†We could also use a computer to simulate the throwing of the needle.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Estimation via Monte Carlo Methods"
    ]
  },
  {
    "objectID": "contents/chapter-08/4monte-carlo-method.html#hard-analytical-solutions",
    "href": "contents/chapter-08/4monte-carlo-method.html#hard-analytical-solutions",
    "title": "Estimation via Monte Carlo Methods",
    "section": "3 Hard Analytical Solutions",
    "text": "3 Hard Analytical Solutions\n\nSolution. Let:\n\n\\(X =\\) perpendicular distance from centre of needle to nearest line in units of \\(5\\) cm.\n\\(Y =\\) acute angle between lines and needle in radians\n\\(A =\\) ‚ÄúNeedle crosses a line‚Äù\n\nTherefore, we obtain\n\n\\(X \\sim U(0, 1), \\quad f(x) = 1, 0 &lt; x &lt; 1\\) as we are working in a \\(1\\) unit distance = $5% cm\n\\(Y \\sim U(0, \\pi / 2), \\quad f(y) = \\frac{2}{\\pi}, 0 &lt; y &lt; \\pi / 2\\)\n\\(X \\perp Y\\). Give \\(X\\), we do not have any additional information about orientation \\(y\\).\n\\(f(x, y) = f(x)(fy) = \\frac{2}{\\pi}, 0 &lt; x &lt; 1, 0 &lt; y &lt; \\pi/2\\)\n\nNow, the intuition is that the needle would cross the closer line if \\(X &lt; \\sin(Y)\\) as the needle has a length of \\(5\\) cm from the end to the center. In other word, it is of \\(1\\) unit distance. \\[\\begin{equation*}\nA = \\{(x, y) : x &lt; \\sin(y)\\}\n\\end{equation*}\\]\nThen, it simply comes down to the following integrals,\n\\[\\begin{align*}\np = \\P{A} & = \\iint_{A} f(x, y) \\, dxdy  \\\\\n& = \\frac{2}{\\pi} \\int_{y=0}^{\\pi / 2} \\left( \\int_{x = 0}^{\\sin(y)} dx \\right) dy \\\\\n& = \\frac{2}{\\pi} \\int_{y=0}^{\\pi/2} \\sin(y) \\, dy \\\\\n& = \\frac{2}{\\pi} \\left[ - \\cos(y) \\right]_0^{\\pi / 2} \\\\\n& = \\frac{2}{\\pi} (- 0 - (- 1)) = \\frac{2}{\\pi} \\\\\n\\end{align*}\\]\n\n\n\nSolution. We can also use the following lemma.\n\nLemma 1 (Iterative Probability) \\[\\begin{equation}\n\\P{A} = \\E{\\PCond{A}{Y}}\n\\end{equation}\\]\n\n\nProof. \\[\\begin{align*}\np = \\P{A} &= \\E{\\mathbfcal{1}_A} \\tag{$\\mathbf{1}_A$ is indicator} \\\\\n& = \\E{\\ECond{\\mathbfcal{1}_A}{Y}} \\tag{Law of iterated expectation} \\\\\n& = \\E{\\PCond{A}{Y}} \\\\\n\\end{align*}\\]\n\nThen with Lemma¬†1, we can approach the problem as the following, \\[\n\\PCond{A}{y} = \\P{X &lt; \\sin(y)} = \\sin(y)\n\\] since \\((X \\mid y) = X \\sim U(0, 1)\\).\nSo, \\[\\begin{align*}\np & = \\P{A} \\\\\n& = \\E{\\PCond{A}{Y}} \\\\\n& = \\E{\\sin(Y)} \\\\\n& = \\int_0^{\\pi/2} \\sin(y) \\frac{2}{\\pi} \\, dy \\\\\n& = \\frac{2}{\\pi} \\\\\n\\end{align*}\\] which is the same as before.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Estimation via Monte Carlo Methods"
    ]
  },
  {
    "objectID": "contents/chapter-08/4monte-carlo-method.html#generalisation",
    "href": "contents/chapter-08/4monte-carlo-method.html#generalisation",
    "title": "Estimation via Monte Carlo Methods",
    "section": "4 Generalisation",
    "text": "4 Generalisation\nIf the length of the needle is \\(r\\) times the distance between lines, it can be shown that the probability that the needle will cross a line is \\[\np = \\begin{cases}\n2r/\\pi , & r \\leq 1 \\\\\n1 - \\frac{2}{\\pi}\\left( \\sqrt{r^2 - 1} - r \\sin^{-1}\\left( \\frac{1}{r} \\right) \\right), & r &gt; 1 \\\\\n\\end{cases}\n\\]\nThe first half with \\(r \\leq 1\\) is easy to show in which the inner integral would have an upper bound of \\(r \\sin(y)\\) instead of \\(\\sin(y)\\) and the definition of \\(A\\) should be \\(A \\triangleq \\{ (x, y) : x &lt; r \\sin(y) \\}\\).",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Estimation via Monte Carlo Methods"
    ]
  },
  {
    "objectID": "contents/chapter-08/1point-estimate.html",
    "href": "contents/chapter-08/1point-estimate.html",
    "title": "Point Estimation",
    "section": "",
    "text": "Definition 1 (Point Estimator) A single estimate of a parameter e.g.¬†\\(\\mean{Y}\\) estimates \\(\\mu\\) and \\(S^2\\) estimates \\(\\sigma^2\\)\n\n\n\n\n\n\n\nMotivating Example\n\n\n\n\n\n\nExample 1 (Example 1) We have a bent coin and are interest in \\(p\\), the probability of heads coming up on a single toss. How can we estimate \\(p\\)?\n\nSolution\nFirst we need some data (observable random variable or variables).\nFor example, we toss the coin \\(n\\) times and observe the number of heads that comes up.\nThe data is then that number, and we may call it \\(Y\\).\nWe next need a model for data, e.g.¬†\\(Y \\sim \\Binomial(n, p)\\). Here \\(p\\) may be called the target parameter or estimand. We now need to choose an estimator of \\(p\\), which may really be any statistic. For example, we may, conforming to our intuitions, use the statistic \\(X \\triangleq Y/n\\) as the estimator.\nFinally, we need to actually carry out the experiment and do the calculations.\n\nFor example, we toss the coin \\(n = 10\\) times and get 6 heads. Then, the realised value of the data \\(Y\\) is \\(y = 6\\), and the realised value of our estimator \\(X\\) is \\(x = y/n = 6/10 / 0.6\\). We call \\(x\\) an estimate of \\(p\\). Because \\(x\\) is a single number, we may also call it a point estimate of \\(p\\). Likewise, we may call \\(X\\) a point estimator of \\(p\\). (Note that this is random over repeated sampling).\nA common practice is to denote both the estimator and estimate of a parameter \\(\\theta\\) by \\(\\hat{\\theta}\\). Thus in our example:\n\nthe estimator of \\(p\\) is \\(\\hat{p} = X = Y / n\\) (a random variable)\nthe estimate of \\(p\\) is \\(\\hat{p} = x = y/n = 0.6\\) (a constant)\n\nThis may be a bit confusing because the same symbol is used for a random variable and a constant. But usually the symbol‚Äôs meaning is clear from the context.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Point Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/1point-estimate.html#what-is-a-point-estimator",
    "href": "contents/chapter-08/1point-estimate.html#what-is-a-point-estimator",
    "title": "Point Estimation",
    "section": "",
    "text": "Definition 1 (Point Estimator) A single estimate of a parameter e.g.¬†\\(\\mean{Y}\\) estimates \\(\\mu\\) and \\(S^2\\) estimates \\(\\sigma^2\\)\n\n\n\n\n\n\n\nMotivating Example\n\n\n\n\n\n\nExample 1 (Example 1) We have a bent coin and are interest in \\(p\\), the probability of heads coming up on a single toss. How can we estimate \\(p\\)?\n\nSolution\nFirst we need some data (observable random variable or variables).\nFor example, we toss the coin \\(n\\) times and observe the number of heads that comes up.\nThe data is then that number, and we may call it \\(Y\\).\nWe next need a model for data, e.g.¬†\\(Y \\sim \\Binomial(n, p)\\). Here \\(p\\) may be called the target parameter or estimand. We now need to choose an estimator of \\(p\\), which may really be any statistic. For example, we may, conforming to our intuitions, use the statistic \\(X \\triangleq Y/n\\) as the estimator.\nFinally, we need to actually carry out the experiment and do the calculations.\n\nFor example, we toss the coin \\(n = 10\\) times and get 6 heads. Then, the realised value of the data \\(Y\\) is \\(y = 6\\), and the realised value of our estimator \\(X\\) is \\(x = y/n = 6/10 / 0.6\\). We call \\(x\\) an estimate of \\(p\\). Because \\(x\\) is a single number, we may also call it a point estimate of \\(p\\). Likewise, we may call \\(X\\) a point estimator of \\(p\\). (Note that this is random over repeated sampling).\nA common practice is to denote both the estimator and estimate of a parameter \\(\\theta\\) by \\(\\hat{\\theta}\\). Thus in our example:\n\nthe estimator of \\(p\\) is \\(\\hat{p} = X = Y / n\\) (a random variable)\nthe estimate of \\(p\\) is \\(\\hat{p} = x = y/n = 0.6\\) (a constant)\n\nThis may be a bit confusing because the same symbol is used for a random variable and a constant. But usually the symbol‚Äôs meaning is clear from the context.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Point Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html",
    "href": "contents/chapter-04/1rv.html",
    "title": "Known Continuous Distributions",
    "section": "",
    "text": "Definition 1 Continuous random variable \\(Y \\sim U(a, b)\\) if its pdf is, \\[\nf(y) = \\frac{1}{b - a}, \\qquad a &lt; y &lt; b (a &lt; b)\n\\]\n\n\n\nTheorem 1 Suppose that \\(Y \\sim U(a, b)\\). Find \\(Y\\)‚Äôs cdf.\n\\[\nF(y) = \\int_a^y \\frac{1}{b-a} \\, dt = \\frac{y - a}{b - a}, \\qquad a &lt; y &lt; b\n\\]\n\n\n\n\n\n\nShow the code\nimport { Inputs } from \"@observablehq/inputs\"\nimport { Plot } from \"@observablehq/plot\"\n\nviewof ua = Inputs.range([0, 10], { label: \"Minimum (a)\", step: 0.1, value: 2 })\nviewof ub = Inputs.range([0, 10], { label: \"Maximum (b)\", step: 0.1, value: 8 })\n\nuniform_xs = Array.from({ length: 100 }, (_, i) =&gt; ua - 1 + (i / 99) * (ub - ua + 2))\n\nuniform_pdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &gt;= ua && x &lt;= ub ? 1 / (ub - ua) : 0\n}))\n\nuniform_cdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &lt; ua ? 0 : x &gt; ub ? 1 : (x - ua) / (ub - ua)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistorgram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.max(...uniform_pdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...uniform_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomUniform(ua, ub)})).plot()",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#uniform-distribution",
    "href": "contents/chapter-04/1rv.html#uniform-distribution",
    "title": "Known Continuous Distributions",
    "section": "",
    "text": "Definition 1 Continuous random variable \\(Y \\sim U(a, b)\\) if its pdf is, \\[\nf(y) = \\frac{1}{b - a}, \\qquad a &lt; y &lt; b (a &lt; b)\n\\]\n\n\n\nTheorem 1 Suppose that \\(Y \\sim U(a, b)\\). Find \\(Y\\)‚Äôs cdf.\n\\[\nF(y) = \\int_a^y \\frac{1}{b-a} \\, dt = \\frac{y - a}{b - a}, \\qquad a &lt; y &lt; b\n\\]\n\n\n\n\n\n\nShow the code\nimport { Inputs } from \"@observablehq/inputs\"\nimport { Plot } from \"@observablehq/plot\"\n\nviewof ua = Inputs.range([0, 10], { label: \"Minimum (a)\", step: 0.1, value: 2 })\nviewof ub = Inputs.range([0, 10], { label: \"Maximum (b)\", step: 0.1, value: 8 })\n\nuniform_xs = Array.from({ length: 100 }, (_, i) =&gt; ua - 1 + (i / 99) * (ub - ua + 2))\n\nuniform_pdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &gt;= ua && x &lt;= ub ? 1 / (ub - ua) : 0\n}))\n\nuniform_cdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &lt; ua ? 0 : x &gt; ub ? 1 : (x - ua) / (ub - ua)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistorgram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.max(...uniform_pdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...uniform_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomUniform(ua, ub)})).plot()",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#normal-distribution",
    "href": "contents/chapter-04/1rv.html#normal-distribution",
    "title": "Known Continuous Distributions",
    "section": "2 Normal Distribution",
    "text": "2 Normal Distribution\n\nDefinition 2 (Normal Distribution) A random variable \\(Y\\) has the normal distribution with parameters \\(a\\) and \\(b^2\\) if its pdf is of the form\n\\[\nf(y) = \\frac{1}{b\\sqrt{2\\pi}} e^{-\\frac{(y - a)^2}{2b^2}}, \\quad -\\infty &lt; y &lt; \\infty \\, (-\\infty &lt; a &lt; \\infty, b &gt; 0)\n\\]\nWe write \\(Y \\sim \\mathcal{N}(a, b^2)\\).\n\n\n\n2.1 Interactive Widget\n\n\nShow the code\nviewof normal_mu = Inputs.range([-10, 10], { label: \"mean\", step: 0.1, value: 0 })\nviewof normal_var = Inputs.range([0, 10], { label: \"variance\", step: 0.1, value: 1 })\n\nnormal_xs = Array.from({ length: 200 }, (_, i) =&gt; \n  - 4 * 4 + (i / 199) * 8 * 4  // from Œº - 4œÉ to Œº + 4œÉ\n)\n\n// PDF of Normal Distribution\nnormal_pdf = normal_xs.map(x =&gt; ({\n  x,\n  y: (1 / (normal_var * Math.sqrt(2 * Math.PI))) * Math.exp(-0.5 * ((x - normal_mu) / normal_var) ** 2)\n}))\n\n// CDF of Normal Distribution using the error function approximation\nnormal_cdf = normal_xs.map(x =&gt; ({\n  x,\n  y: 0.5 * (1 + erf((x - normal_mu) / (normal_var * Math.sqrt(2))))\n}))\n\n// Helper: error function approximation\nfunction erf(x) {\n  // Abramowitz and Stegun formula 7.1.26\n  const sign = x &gt;= 0 ? 1 : -1\n  const a1 = 0.254829592,\n        a2 = -0.284496736,\n        a3 = 1.421413741,\n        a4 = -1.453152027,\n        a5 = 1.061405429,\n        p = 0.3275911\n\n  const t = 1 / (1 + p * Math.abs(x))\n  const y = 1 - (((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t) * Math.exp(-x * x)\n  return sign * y\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Normal(${normal_mu}, ${normal_var})`,\n  marks: [\n    Plot.line(normal_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.max(...normal_pdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Normal(${normal_mu}, ${normal_var})`,\n  marks: [\n    Plot.line(normal_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...normal_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomNormal(normal_mu, normal_var ** (0.5))})).plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2 Standardisation\nWithout a computer, the only way to evaluate the probability is using a normal distribution table. However, such table only provides information about the standard normal distribution. Therefore, it becomes important to use standardisation to change any r.v. following normal distribution to the standard normal distribution.\n\nTheorem 2 (Standardisation Normal Technique) If \\(Y \\sim \\mathcal{N}(a, b^2)\\), then \\(Z = \\frac{Y - a}{b} \\sim \\mathcal{N}(0, 1)\\).\n\nWe say that \\(Y\\) has been standardised, and that \\(Z\\) is the standardised version of \\(Y\\).\nNote that this technique is used not only for finding the probability in the exam with normal table, this can also be used to normalise the training data for a machine learning model1.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#gamma-distribution",
    "href": "contents/chapter-04/1rv.html#gamma-distribution",
    "title": "Known Continuous Distributions",
    "section": "3 Gamma Distribution",
    "text": "3 Gamma Distribution\n\nDefinition 3 (Gamma Distribution Pdf) A random variable \\(Y\\) has the gamma distribution with parameters \\(a\\) and \\(b\\) if its pdf is of the form \\[\nf(y) = \\frac{y^{a-1}e^{-y/b}}{b^a \\Gamma(a)}, \\quad y &gt; 0 \\quad (a, b &gt; 0)\n\\]\nWe write \\(Y \\sim \\text{Gam}(a, b)\\).\n\n\n3.1 Mysterious \\(\\Gamma(\\cdot)\\)\n\\(\\Gamma(\\cdot)\\) here is the gamma function, defined by \\(\\Gamma(k) = \\int_0^\\infty t^{k-1}e^{-t}\\, dt\\).\nSome properties:\n\n\\(\\Gamma(k) = (k - 1) \\Gamma(k - 1)\\) if \\(k &gt; 1\\)\n\\(\\Gamma(k) = (k - 1)!\\) if \\(k\\) is a positive integer (e.g.¬†\\(\\Gamma (4) = 3! = 6\\))\n\\(\\Gamma(1/2) = \\sqrt{\\pi}\\)\n\n\n\nShow the code\nfunction gamma(z) {\n  const g = 7\n  const p = [\n    0.99999999999980993,\n    676.5203681218851,\n   -1259.1392167224028,\n    771.32342877765313,\n   -176.61502916214059,\n    12.507343278686905,\n   -0.13857109526572012,\n    9.9843695780195716e-6,\n    1.5056327351493116e-7\n  ]\n\n  if (z &lt; 0.5) {\n    return Math.PI / (Math.sin(Math.PI * z) * gamma(1 - z))\n  } else {\n    z -= 1\n    let x = p[0]\n    for (let i = 1; i &lt; g + 2; i++) {\n      x += p[i] / (z + i)\n    }\n    const t = z + g + 0.5\n    return Math.sqrt(2 * Math.PI) * t**(z + 0.5) * Math.exp(-t) * x\n  }\n}\n\n// Generate values for plotting\ngam_xs = Array.from({ length: 200 }, (_, i) =&gt; 0.01 + i / 199 * (8 - 0.01))\ngamma_data = gam_xs.map(x =&gt; ({ x, y: gamma(x) }))\n\n// Plot\nPlot.plot({\n  title: `Gamma Function Œì(x), from x = 0.01 to ${8}`,\n  marks: [\n    Plot.line(gamma_data, { x: \"x\", y: \"y\", stroke: \"purple\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\", domain: [0, 8] },\n  y: { label: \"Œì(x)\" },\n  width: 600,\n  height: 300\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Mode of Gamma Distribution\n\nTheorem 3 (Mode of Gamma Distribution) \\[\nMode(Y) = \\begin{cases}\nb(a-1) & a \\geq 1 \\\\\n0 & a &lt; 1\n\\end{cases}\n\\]\n\n\n\n\n3.3 Interactive Widget\n\n\nShow the code\nviewof gamma_a = Inputs.range([0.4, 5], { label: \"a\", step: 0.1, value: 1 })\nviewof gamma_b = Inputs.range([0.1, 5], { label: \"b\", step: 0.1, value: 1 })\n\nfunction gammainc_lower(x, a) {\n  // Lower regularized incomplete gamma function P(a, x)\n  // using a simple series expansion\n  let sum = 1 / a\n  let value = 1 / a\n  for (let n = 1; n &lt; 100; n++) {\n    value *= x / (a + n)\n    sum += value\n    if (value &lt; 1e-8) break\n  }\n  return sum * Math.exp(-x + a * Math.log(x)) / gamma(a)\n}\n\nfunction gammaCDF(x, alpha, theta) {\n  if (x &lt;= 0) return 0\n  return gammainc_lower(x / theta, alpha)\n}\n\nfunction gammaPDF(x, a, t) {\n  if (x &lt; 1e-6) return a &lt; 1 ? Infinity : 0\n  return (1 / (t ** a * gamma(a))) * x ** (a - 1) * Math.exp(-x / t)\n}\n\ngamma_xs = [\n  ...Array.from({ length: 100 }, (_, i) =&gt;\n    1e-6 + Math.exp(Math.log(1e-6) + (i / 100) * Math.log(0.5 / 1e-6))  // log scale from 1e-6 to ~0.5\n  ),\n  ...Array.from({ length: 100 }, (_, i) =&gt; 0.5 + i * 0.1)  // linear from 0.5 to 10.4\n]\n\n\n// PDF of Normal Distribution\ngamma_pdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaPDF(x, gamma_a, gamma_b)\n}))\n\n// CDF of Normal Distribution using the error function approximation\ngamma_cdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaCDF(x, gamma_a, gamma_b)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Gamma(${gamma_a}, ${gamma_b})`,\n  marks: [\n    Plot.line(gamma_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...gamma_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Gamma(${gamma_a}, ${gamma_b})`,\n  marks: [\n    Plot.line(gamma_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...gamma_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n// import { Plot, binX, ruleY, line } from \"@observablehq/plot\"\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomGamma(gamma_a, gamma_b)})).plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4 Conclusion on the Gamma Distribution\nNow, it is clear that the gamma distribution is very expressive with two model parameters. In fact, we can define many specific distribution by using this gamma distribution by fixing some of the model parameters.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#the-chi2-distribution",
    "href": "contents/chapter-04/1rv.html#the-chi2-distribution",
    "title": "Known Continuous Distributions",
    "section": "4 The Chi2 Distribution",
    "text": "4 The Chi2 Distribution\nBeing a special case of the gamma distribution.\n\nDefinition 4 (Chi-Square Distribution) If \\(Y \\sim \\text{Gam}(n/2, 2)\\), we say that \\(Y\\) has the chi-square distribution with parameter \\(n\\).\nDenote as \\(Y \\sim \\chi^2(n)\\).\n\n\nDefinition 5 (Chi-Square Degree of Freedom) \\(n\\) in the above formulation is the degrees of freedom (DOF).\n\n\nTheorem 4 (Mode of Chi-Square Distribution) The mode of \\(Y\\) is \\(n - 2\\) if \\(n \\geq 2\\), and it is 0 if \\(n \\leq 2\\).\n\n\n\n4.1 Interactive Widget\n\n\nShow the code\nviewof chi_dof = Inputs.range([1, 5], { label: \"dof\", step: 1, value: 1 })\n\n// PDF of Normal Distribution\nchi_pdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaPDF(x, chi_dof / 2, 2)\n}))\n\n// CDF of Normal Distribution using the error function approximation\nchi_cdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaCDF(x, chi_dof / 2, 2)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\n// @title: Gamma PDF \n\nPlot.plot({\n  title: `PDF of Chi(${chi_dof})`,\n  marks: [\n    Plot.line(chi_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...chi_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Normal CDF\n\nPlot.plot({\n  title:  `CDF of Chi(${chi_dof})`,\n  marks: [\n    Plot.line(chi_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...chi_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomGamma(chi_dof / 2, 2)})).plot()",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#exponential-distribution",
    "href": "contents/chapter-04/1rv.html#exponential-distribution",
    "title": "Known Continuous Distributions",
    "section": "5 Exponential Distribution",
    "text": "5 Exponential Distribution\nAnother special case of the gamma distribution\n\nDefinition 6 (Exponential Distribution PDF) If \\(Y \\sim \\text{Gam}(1, b)\\), then \\(Y\\) has the exponential distribution with parameter \\(b\\).\nWe write \\(Y \\sim \\text{Exp}(b)\\) with the corresponding pdf being, \\[\nf(y) = \\frac{1}{b}e^{-y/b}, \\quad y &gt; 0\n\\]\n\nBy using Theorem¬†3, we obtain the following corollary.\n\nCorollary 1 (Mode of Exponential Distribution) \\[\nMode(Y) = 0\n\\]\n\n\nNow, we can establish the following connection with all the other ones have discovered. \\[\n\\text{Exp}(2) = \\text{Gam}(2/2, 2) = \\chi^2(2)\n\\]\n\nThis distribution is useful for modelling times until failure of components and times between successive arrivals in a queue.\n\n\n5.1 Interactive Widget\n\n\nShow the code\nviewof exp_b = Inputs.range([0.1, 5], { label: \"n\", step: 0.1, value: 1 })\n\n// PDF of Normal Distribution\nexp_pdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaPDF(x, 1, exp_b)\n}))\n\n// CDF of Normal Distribution using the error function approximation\nexp_cdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaCDF(x, 1, exp_b)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Exp(${exp_b})`,\n  marks: [\n    Plot.line(exp_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...exp_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Exp(${exp_b})`,\n  marks: [\n    Plot.line(exp_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...exp_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomGamma(1, exp_b)})).plot()\n\n\n\n\n\n\n\n\n\n\n\n\n5.2 Standard Exponential Distribution\n\nDefinition 7 (Standard Exponential Distribution) A special case of the exponential distribution.\nIf \\(Y \\sim \\text{Exp}(1)\\), we say that \\(Y\\) has the standard exponential distribution.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#beta-distribution",
    "href": "contents/chapter-04/1rv.html#beta-distribution",
    "title": "Known Continuous Distributions",
    "section": "6 Beta Distribution",
    "text": "6 Beta Distribution\n\nDefinition 8 (Beta Distribution) A random variable \\(Y\\) has the beta distribution with parameters \\(a\\) and \\(b\\) if its pdf is of the form \\[\nf(y) = \\frac{y^{a-1}(1-y)^{b-1}}{B(a, b)}, \\quad o &lt; y &lt; 1 \\; (a, b &gt; 0)\n\\]\nWe write \\(Y \\sim \\text{Beta}(a, b)\\).\n\nHere, \\(B(a, b) = \\frac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a + b)}\\) is the beta function.\n\n6.1 Connection with Uniform Distribution\nIf \\(a = b = 1\\), then \\(f(y) = 1\\), \\(0 &lt; y &lt; 1\\). Thus \\(\\text{Beta}(1, 1) = U(0, 1)\\).\nIt can be shown that \\(Mode(Y) = (a - 1)/(a + b -2)\\) if \\(a &gt; 1\\) and \\(b &gt; 1\\).\n\n\n\n6.2 Interactive Widget\n\n\nShow the code\nviewof beta_alpha = Inputs.range([0.1, 10], { label: \"alpha\", step: 0.01, value: 1 })\nviewof beta_beta = Inputs.range([0.1, 10], { label: \"beta\", step: 0.01, value: 1 })\n\n// --- More points near edges ---\nbeta_xs = [\n  ...Array.from({ length: 201 }, (_, i) =&gt; i / 200)\n].filter(x =&gt; x &lt;= 1)\n\n// --- Beta PDF ---\nfunction betaPDF(x, a, b) {\n  if (x &lt;= 0 || x &gt;= 1) return 0\n  const numerator = x ** (a - 1) * (1 - x) ** (b - 1)\n  const denominator = gamma(a) * gamma(b) / gamma(a + b)\n  return numerator / denominator\n}\n\n// Regularized incomplete beta function I_x(a, b)\n// This is a simple continued fraction approximation for 0 &lt; x &lt; 1\n// Based on the continued fraction form in NR, adapted for moderate values\n\nfunction betainc(x, a, b) {\n  if (x &lt;= 0) return 0\n  if (x &gt;= 1) return 1\n\n  const lnBeta = Math.log(gamma(a)) + Math.log(gamma(b)) - Math.log(gamma(a + b))\n  const front = Math.exp(\n    a * Math.log(x) + b * Math.log(1 - x) - lnBeta\n  ) / a\n\n  let f = 1, c = 1, d = 0\n  for (let i = 1; i &lt; 100; i++) {\n    const m = i / 2\n    const numerator = (i % 2 === 1)\n      ? (b - m) * x / (a + 2 * m - 1)\n      : -((a + m - 1) * (a + b + m - 1) * x) / ((a + 2 * m - 2) * (a + 2 * m - 1))\n    d = 1 + numerator * d\n    if (Math.abs(d) &lt; 1e-30) d = 1e-30\n    d = 1 / d\n    c = 1 + numerator / c\n    if (Math.abs(c) &lt; 1e-30) c = 1e-30\n    const delta = c * d\n    f *= delta\n    if (Math.abs(delta - 1) &lt; 1e-8) break\n  }\n\n  return front * f\n}\n\n// --- PDF values ---\nbeta_pdf = beta_xs.map(x =&gt; ({\n  x,\n  y: betaPDF(x, beta_alpha, beta_beta)\n}))\n\n// Compute the CDF points using the approximation\nbeta_cdf = beta_xs.map(x =&gt; ({\n  x,\n  y: betainc(x, beta_alpha, beta_beta)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Beta(${beta_alpha}, ${beta_beta})`,\n  marks: [\n    Plot.line(beta_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...beta_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title: `CDF of Beta(${beta_alpha}, ${beta_beta})`,\n  marks: [\n    Plot.line(beta_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...beta_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomBeta(beta_alpha, beta_beta)})).plot()",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#footnotes",
    "href": "contents/chapter-04/1rv.html#footnotes",
    "title": "Known Continuous Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHowever, it is more common to use min-max normalisation.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "",
    "text": "Motivating Example 2\n\n\n\nA committee of two is randomly selected from three teachers, two students, and one parent.\nLet \\(X\\) be the number of teachers on the committe, and \\(Y\\) the number of students.\nFind:\n\n\nthe marginal pmf of \\(Y\\)\n\n\nthe conditional pmf of \\(Y\\) given that \\(X = 0\\)\n\n\nthe correlation between \\(X\\) and \\(Y\\)\n\n\n\n\n\n\n\\(X\\) and \\(Y\\) have joint probability mass function \\(p(x, y)\\) given by\n\\[\np(x, y) = \\frac{\\binom{3}{x} \\binom{2}{x} \\binom{1}{2 - x - y}}{\\binom{6}{2}}\n\\]\nFor \\(x \\in [0, 2]\\) and \\(y \\in [0, 2]\\) with constraint \\(1 \\leq x + y \\leq 2\\)\nHence, we can fill in the following table remembering that it needs two people for the committee.\n\n\n\nX \\ Y\n0\n1\n2\n\n\n\n\n0\n\\\n2/15 = 0.13\n1 / 15 = 0.07\n\n\n1\n3 / 15 = 0.2\n6/15 = 0.4\n\\\n\n\n2\n3 / 15 = 0.2\n\\\n\\\n\n\n\nTherefore, we get that the marginal probability of \\(Y\\) is\n\\[\np_Y(y) = \\begin{cases}\n6/15, & y = 0 \\\\\n8/15, & y = 1 \\\\\n1/15, & y = 2 \\\\\n\\end{cases}\n\\]\n\n\n\n\nThe conditional pmf of \\(Y\\) given that \\(X = 0\\) is trivial from the above as,\n\\[\np_{Y\\mid X}(y|0) = \\begin{cases}\n0, & y = 0 \\\\\n2/3, & y = 1 \\\\\n1/3, & y = 2 \\\\\n\\end{cases}\n\\]\n\n\nThe Correlation between \\(X\\) and \\(Y\\)\n\nFirst, find the expectations of \\(X\\) and \\(Y\\) first as,\n\\[\n\\begin{align}\nE(X) &= 1 \\times 0.6 + 2 \\times 0.2 = 1 \\\\\nE(Y) &= 1 \\times \\frac{8}{15} + 2 \\times \\frac{1}{15} = 0.67 \\\\\n\\end{align}\n\\]\nHence,\n\\[\n\\begin{align}\nCov(X, Y) &= E(XY) - \\frac{2}{3} \\\\\n&= \\frac{6}{15} - \\frac{2}{3} \\\\\n&= -\\frac{4}{15} = -0.27\n\\end{align}\n\\]\nNow, in order to find the correlation, we also need to find the standard deviation of the two random variables.\n\\[\n\\begin{align}\nVar(X) & = E(X^2) - \\mu_X^2 = \\frac{9}{15} + 2^2 \\frac{3}{15} - 1 = \\frac{9 + 12 - 15}{15} = \\frac{6}{15} \\\\\nVar(Y) & = E(Y^2) - \\mu_Y^2 = \\frac{8}{15} + 2^2 \\frac{1}{15} - \\frac{4}{9} = \\frac{12 * 15 - 100}{225} = \\frac{80}{225} = \\frac{16}{45} = 0.36 \\\\\n\\end{align}\n\\]\nTherefore, the correlation is,\n\\[\nCor(X, Y) = \\frac{Cov(X, Y)}{\\sqrt{6/15}\\sqrt{16/45}} = -\\frac{1}{\\sqrt{2}} = -0.7071\n\\]",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#laws-of-multivariate-expectation",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#laws-of-multivariate-expectation",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "1 Laws of Multivariate Expectation",
    "text": "1 Laws of Multivariate Expectation\n\n\\(E(c) = c\\)\n\\(E(cg(X, Y)) = cE(g(X, Y))\\)\n\\(E(g_1(X, Y) + g_2(X, Y) + \\cdots + g_k(X, Y)) = E(g_1(X, Y)) + \\cdots + E(g_k(X, Y))\\)\nIf \\(X \\perp Y\\) then \\(E(g(X)h(Y)) = E(g(X))E(h(Y))\\)\n\n\nProof. The proof for all these can simply be extended from the single variate situation by simply exchanging the pmf to joint pmf.",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#independence",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#independence",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "2 Independence",
    "text": "2 Independence\nWe say that \\(Y_1, Y_2, \\ldots, Y_n\\) are pairwise independent iff\n\\[\np(y_i, y_j) = p(y_i)p(y_j) \\qquad \\text{for all $i &lt; j$}\n\\]\nWe say that \\(Y_1, Y_2, \\ldots, Y_n\\) are totally independent if\n\\[\n\\begin{align}\n& p(y_i, y_j) = p(y_i)p(y_j) & \\text{for all $i &lt; j$} \\\\\n& p(y_i, y_j, y_k) = p(y_i)p(y_j)p(y_k) & \\text{for all $i &lt; j &lt; k$} \\\\\n& \\dots \\\\\n& p(y_1, y_2, \\ldots, y_n) = p(y_1)p(y_2) \\ldots p(y_n) &  \\\\\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#multinomial-distribution",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#multinomial-distribution",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "3 Multinomial Distribution",
    "text": "3 Multinomial Distribution\nThis is simply a generalisation of the binomial distribution.\nConsider \\(n\\) independent and identical trials, on each of which there are \\(k\\) possible outcomes. On each trial let \\(p_i\\) be the probability of outcome \\(i\\) and let \\(Y_i\\) be the total number of trials with outcome \\(i\\) (\\(i = 1, \\ldots k\\)).\nThen \\(Y_1, Y_2, \\ldots , Y_k\\) have a multinominal distribution with joint pmf\n\\[\np(y_1, y_2, \\ldots, y_k) = \\frac{n!}{y_1 !y_2 ! \\ldots y_k !} p_1^{y_1}p_2^{y_2}\\cdots p_k^{y_k}, \\qquad y_i \\in \\{ 0, 1, \\ldots, n\\}, \\sum_{j = 1}^k y_j = n,\n\\]\n(\\(p_i \\in [0, 1] and p_1 + p_2 + \\cdots + p_k = 1\\)).\nWe write \\(Y_1, Y_2, \\ldots, Y_k \\sim \\text{Mult}(n; p_1, p_2, \\ldots , p_k)\\).\n\n3.1 Multinomial Cefficients\nThe number of ways of partitioning \\(n\\) distinct objects into \\(k\\) distinct groups is\n\\[\n\\binom{n}{y_1 \\ldots y_k} = \\frac{n!}{y_1 ! y_2 ! \\ldots y_k !}, \\qquad y_i = \\text{count in $i$-th group}\n\\]\n\n\n\nTable¬†1: An Example Sequence\n\n\n\n\n\nTrial\n1\n2\n3\n4\n5\n\nn\n\n\n\n\nGroup\n1\n3\n5\n1\n1\n\n2\n\n\n\n\n\n\nGiven the sequence in Table¬†1, we can state the probability as \\[\n\\begin{align}\nP(sequence) &= p_1p_3p_5p_1p_1\\cdots p_2 \\\\\n&= p_1^{y_1} \\ldots p_k^{y_k}\n\\end{align}\n\\]\nThe probability of obtaining a distinct sequene where we observe \\(y_1, y_2, \\ldots y_k\\) is given by \\[\nP(y_1, y_2, \\ldots , y_k) = \\binom{n}{y_1 \\ldots y_k} p_1^{y_1}p_2^{y_2} \\ldots p_k^{y_k}\n\\]\n\n\n3.2 Example\nOn 10 rolls of a die, what‚Äôs the pr there will result 3 even numbers and 2 ones?\nLet \\(Y_1\\) be the number of even numbers, \\(Y_2\\) be number of ones, and \\(Y_3\\) be number of threes and fives (non-evens and non-ones).\nThen \\(Y_1, Y_2, Y_3 \\sim \\text{Multi}(10; 1/2, 1/6, 1/3)\\) with pmf \\[\np(y_1, y_2, y_3) = \\frac{10!}{y_1 ! y_2 ! y_3 !} \\left( \\frac{1}{2} \\right)^{y_1} \\left( \\frac{1}{6} \\right)^{y_2} \\left( \\frac{1}{3} \\right)^{y_3}\n\\] So, \\[\np(3, 2, 5) =\\frac{10!}{3! 2! 5!} \\left( \\frac{1}{2} \\right)^3 \\left( \\frac{1}{6} \\right)^2 \\left( \\frac{1}{3} \\right)^5 = 0.03601\n\\]",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#three-important-theorems-regarding-linear-combinations-of-random-variables",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#three-important-theorems-regarding-linear-combinations-of-random-variables",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "4 Three Important Theorems Regarding Linear Combinations of Random Variables",
    "text": "4 Three Important Theorems Regarding Linear Combinations of Random Variables\n\nTheorem 1 ¬†\n\n\\[\nE \\left\\{ \\sum_{i = 1}^n a_i Y_i \\right\\} = \\sum_{i = 1}^n a_i\\mu_i\n\\]\n\n\nTheorem 2 \\[\nVar\\left( \\sum_{i = 1}^n a_i Y_i \\right) = \\sum_{i=1}^n a_i^2 \\sigma_i^2 + 2 \\sum_{i = 1}^{n - 1}\\sum_{j = i + 1}^n a_i a_j \\sigma_{ij} = \\sum_{i = 1}^n \\sum_{j = 1}^n a_i a_j \\sigma_{ij}\n\\]\n\n\nTheorem 3 \\[\nCov\\left( \\sum_{i = 1}^n a_i Y_i, \\sum_{i = 1}^n b_i Y_i \\right) = \\sum_{i=1}^n \\sum_{j = 1}^n a_i b_j \\sigma_{ij}\n\\]\n\n\nProof. The proof of Theorem¬†1 is trivial given the linearity of the expectation. The proof of Theorem¬†2 is also trivial if Theorem¬†3 is proven. Hence, we would only need to prove Theorem¬†3.\n\\[\n\\begin{align}\n\\text{LHS} & = E \\left[ \\left( \\sum_{i = 1}^n a_i Y_i - E\\left( \\sum_{i = 1}^n a_i Y_i \\right) \\right) \\left( \\sum_{j = 1}^n b_j Y_j - E\\left( \\sum_{j=1}^n b_j Y_j \\right) \\right) \\right] \\\\\n& = E \\left[ \\left( \\sum_{i = 1}^n a_i Y_i - \\sum_{i = 1}^n a_i \\mu_i \\right) \\left( \\sum_{j = 1}^n b_j Y_j - \\sum_{j = 1}^n b_j \\mu_j \\right) \\right] \\\\\n& = E \\left[ \\left( \\sum_{i = 1}^n a_i (Y_i - \\mu_i) \\right) \\left( \\sum_{j = 1}^n b_j (Y_j - \\mu_j) \\right) \\right] \\\\\n& = \\sum_{i = 1}^n \\sum_{j = 1}^n a_i b_j E\\left\\{ (Y_i - \\mu_i) (Y_j - \\mu_j) \\right\\} = RHS \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\n\nExample 4\n\n\n\nSuppose that \\(Y_1\\), \\(Y_2\\), and \\(Y_3\\) are three rv‚Äôs with means 2, -7, and 5, variances 10, 6, and 9, and covariances \\(\\sigma_{12} = -1\\), \\(\\sigma_{13} = 3\\), and \\(\\sigma_{23} = 0\\).\nFind:\n\n\\(E(3Y_1 - 2Y_2 + Y_3)\\)\n\\(Var(3Y_1 - 2Y_2 + Y_3)\\)\n\\(Cov(3Y_1 - 2Y_2, Y_2 + 8 Y_3)\\)\n\n\n\n\\(E(3Y_1 - 2Y_2 + Y_3)\\)\n\n\\[\n\\begin{align}\nE(3Y_1 - 2Y_2 + Y_3) & = 3 \\mu_1 - 2\\mu_2 + \\mu_3 \\\\\n& = 3 * 2 - 2 * (-7) + 5 = 25 \\\\\n\\end{align}\n\\]\n\n\n\\(Var(3Y_1 - 2Y_2 + Y_3)\\)\n\n\\[\n\\begin{align}\nVar(3Y_1 - 2Y_2 + Y_3) & = \\sum_{i = 1}^n \\sum_{j = 1}^n a_i a_j \\sigma_{ij} \\\\\n& = 3 \\times 3 \\times 10 + 3 \\times (-2) \\times (-1) + 3 \\times 1 \\times 3 \\\\\n& \\qquad + (-2) \\times 3 \\times (-1) + (-2) \\times (-2) \\times 6 + (-2) \\times 1 \\times 0 \\\\\n& \\qquad + 1 \\times 3 \\times 3 + 0 \\times 1 \\times 1 \\times 9 \\\\\n& = 105 + 33 + 18  = 156 \\\\\n\\end{align}\n\\]\n\n\n\\(Cov(3Y_1 - 2Y_2, Y_2 + 8 Y_3)\\)\n\nNow, in order to use Theorem¬†3, we need to have the same list of variables. Therefore, we can use the following transformation,\n\\[\nCov(3 Y_1 - 2 Y_2, Y_2 + 8 Y_3) = Cov(3 Y_1 - 2 Y_2 + 0 Y_3, 0 Y_1 + Y_2 + 8 Y_3)\n\\]\nThen, we can apply Theorem¬†3 as the following,\n\\[\n\\begin{align}\nCov(3 Y_1 - 2 Y_2, Y_2 + 8 Y_3) &= Cov(3 Y_1 - 2 Y_2 + 0 Y_3, 0 Y_1 + Y_2 + 8 Y_3) \\\\\n& = 3(1)\\sigma_{12} + 3(8)\\sigma_{13} + (-2)1\\sigma_{22} + (-2)8\\sigma_{23} \\\\\n& = 3(-1) + 24(3) - 2(6) - 16(0) \\\\\n& = 57\n\\end{align}\n\\]\n\n\n\n\n\n\n\n\nUse the above three theorems to find the mean and variance of the hypergeometric distribution\n\n\n\n\n\nIn order to determine the mean with Theorem¬†1, we first need to decompose the random variable into linear combinations of smaller chuncks. In fact, we need to know the marginal distribution of all these randome variables while importantly, note that each of these trials are clearly not independent. In other words, suppose \\(X_i\\) be the random variable that denotes whether the outcome at trial \\(i\\) is successful (1) or not (0). Then, the marginal distribution of \\(X_i\\) is the following assuming \\(Y \\sim \\text{HyperGeom}(N, r, n)\\) and \\(X_1 + \\cdots + X_n = Y\\) \\[\n\\begin{align}\nP(X_i = 1) &= \\sum_{\\text{all configurations with $X_i = 1$}} p(x_1, x_2, \\ldots , x_{i-1}, 1, x_{i+1}, \\ldots , x_n) \\\\\n& = \\sum_{\\text{all configurations with $X_i = 1$}} P(X_i = 1 \\mid X_1 = x_1, \\ldots X_{i - 1} = x_{i - 1}, X_{i + 1} = x_{i+1}, \\ldots, X_{n} = x_n) P(\\text{all other configurations}) \\\\\n& = \\sum_{y' = 0}^{\\min(r, n - 1)}{\\left(\\frac{r - y'}{N - n + 1}\\right) \\frac{\\binom{r}{y'}\\binom{N - r}{n - 1 - y'}}{\\binom{N}{n - 1}}} \\\\\n& = \\frac{1}{(N - n + 1)\\binom{N}{n - 1}} \\sum_{y' = 0}^{\\min(r, n - 1)}{(r - y') \\binom{r}{y'}\\binom{N - r}{n - 1 - y'}} \\\\\n& = \\frac{1}{(N - n + 1)\\binom{N}{n - 1}} \\sum_{y' = 0}^{\\min(r, n - 1)}{r \\binom{r - 1}{y'}\\binom{N - r}{n - 1 - y'}} \\\\\n& = \\frac{r}{(N - n + 1)\\binom{N}{n - 1}} \\sum_{y' = 0}^{\\min(r, n - 1)}{ \\binom{r - 1}{y'}\\binom{N - r}{n - 1 - y'}} \\\\\n& = \\frac{r}{(N - n + 1)\\binom{N}{n - 1}} \\binom{N - 1}{n - 1} \\\\\n& = \\frac{r \\binom{N-1}{n-1}}{(N-n+1)\\frac{N}{N-n+1} \\binom{N-1}{n-1}} \\\\\n& = \\frac{r}{N} \\\\\n\\end{align}\n\\tag{1}\\]\nNote that:\n\nGoing from line 2 to line 3, we have assumed that there are \\(y'\\) number of possible cases from \\(X_1, \\ldots , X_{i - 1}, X_{i + 1}, \\ldots, X_n\\).\nGoing from line 3 to line 4 is nothing more than just algebraic manipulations.\nGoing from line 4 to line 5 requires a relatively simple combinatoric identiy as \\((r - k)\\binom{r}{k} = r \\binom{r-1}{k}\\).\nGoing from line 5 to line 6 requires only moving \\(r\\) out from the summation.\nGoing from line 6 to line 7 requires the Vandermonde‚Äôs identity but assuming that \\(r \\geq n - 1\\) 1. This identity simply states that \\(\\sum_{k = 0}^{m} \\binom{a}{k} \\binom{b}{m - k} = \\binom{a + b}{m}\\). The proof of this identity can be done by considering the binomial expansion of the binomial \\((1+x)^a(1+x)^b\\), which is essential the same as \\((1+x)^{a+b}\\).\nGoing from line 7 to line 8 requires this identity: \\(\\binom{N}{n - 1} = \\frac{N}{N - n + 1}\\binom{N - 1}{n - 1}\\). The proof of this identity is relatively obvious from the expansion of the binomial coefficient into the full form.\nGoing from line 8 to line 9 requires only algebraic manipulations.\n\nThen, from this probability, it is clear that for each trial, it still follows a bernoulli distribution \\(\\text{Bern}(r/N)\\). Therefore, the mean and variance of each \\(X_i\\) is trivial from existing results. However, the covariances can be derived as, \\[\n\\begin{align}\nCov(X_i, X_j) & = E(X_i X_j) - E(X_i)E(X_j) \\\\\n& = \\sum_{x_i = 0}^1 \\sum_{x_j = 0}^1 x_i x_j P(X_i = x_i, X_j = x_j) - \\left( \\frac{r}{N} \\right)^2 \\\\\n& = P(X_i = 1, X_j = 1) - \\left( \\frac{r}{N} \\right)^2 \\\\\n& = \\frac{r(r-1)}{N(N-1)} - \\left( \\frac{r}{N} \\right)^2 = \\frac{r(r-N)}{N^2(N-1)} \\\\\n\\end{align}\n\\tag{2}\\] Note that:\n\nGoing from second last to last line can be proven with a similar proof above. However, an intuitive way of thinking about it is using the law of total probability and first find \\(P(X_i)\\) and then the condintional probability \\(P(X_j \\mid X_i)\\). This argument is possible because we can assume W.L.O.G by the unconditional is taken on the earlier event and the conditional even taken on the later event out of the two events. However, I suppose a more mathematical approach would be use a similar argument as Equation¬†1 but replace the first term in the summation in line 3 with \\[\\frac{\\binom{r - y'}{2}\\binom{N - (n - 2) - (r - y')}{0}}{\\binom{N - n + 2}{2}}\\] which should now be clear that it is simply a special of hypergeometric distribution where we only want positive cases.\n\nHence, now, we can apply Theorem¬†1 and Theorem¬†2 to obtain the required mean and variance of the hypergeometric distribution.\n\\[\n\\begin{align}\nE(Y) & = E \\left( \\sum_{i = 1}^n X_i \\right) \\\\\n& = \\sum_{i=1}^n E(X_i) \\\\\n& = \\frac{nr}{N} \\\\\nVar(Y) & = Var\\left( \\sum_{i=1}^n X_i \\right) \\\\\n& = \\sum_{i = 1}^n \\sum_{j = 1}^n \\sigma_{ij} \\\\\n& = \\left(\\sum_{i = 1}^n \\sigma_i^2\\right) + \\left( \\sum_{i=1}^{n-1} \\sum_{j = 1 + 1}^n \\sigma_{ij} \\right) \\\\\n& = n \\frac{r}{N} (1 - \\frac{r}{N}) + n(n-1) \\frac{r(r-N)}{N^2(N-1)} \\\\\n& = \\frac{nr}{N} \\left( 1 - \\frac{r}{N} + \\frac{(n - 1)(r - N)}{N(N - 1)} \\right) \\\\\n& = \\frac{nr}{N} \\left( \\frac{N^2 - N}{N(N - 1)} - \\frac{rN - r}{N(N - 1)} + \\frac{(n - 1)(r - N)}{N(N - 1)} \\right) \\\\\n& = \\frac{nr}{N} \\left( \\frac{N^2 - rN + rn - nN}{N(N-1)}\\right) \\\\\n& = \\frac{nr}{N} \\left( \\frac{N(N - n) - r(N - n)}{N(N-1)} \\right) \\\\\n& = \\frac{nr(N - r)(N - n)}{N^2(N - 1)} \\\\\n\\end{align}\n\\]\nThis confirms with the formula sheet given as well.\n\n\n\n\n\n\n\n\n\nCovariance of Multinomial Distribution\n\n\n\nUse the above three theorems to find \\(Cov(Y_i, Y_j)\\) when \\(i \\neq j\\) and \\(Y_1, Y_2, \\ldots , Y_k \\sim \\text{Mult}(n; p_1, p_2, \\ldots, p_k)\\).\n\nI don‚Äôt think there is an easy way to use the above three theorems. Instead a common way to approach this question is to actually consider two set of indicator variables that indicate whether the class is \\(i\\) or \\(j\\) at certain trial.",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#continuous-multivariate-probability-distributions",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#continuous-multivariate-probability-distributions",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "5 Continuous Multivariate Probability Distributions",
    "text": "5 Continuous Multivariate Probability Distributions\n\\(Y_1, Y_2, \\ldots , Y_n\\) have a continuous multivariate probability distribution if their joint cdf \\[\nF(y_1, y_2, \\ldots , y_n) = P(Y_1 \\leq y_1, Y_2 \\leq y_2, \\ldots , Y_n \\leq y_n)\n\\] is continuous everywhere.\nThe joint pdf of \\(Y_1, Y_2, \\ldots, Y_n\\) is then \\[\nf(y_1, y_2, \\ldots , y_n) = \\frac{\\partial^n F(y_1, y_2, \\ldots y_n)}{\\partial y_1 \\partial y_2 \\ldots \\partial y_n}\n\\].\nAll the definitions and results made for discrete joint distributions also hold for continuous ones, except that summations must be replaced by integrals, and \\(p\\)‚Äôs need to be replaced by \\(f\\)‚Äôs.\nThus: \\[\n\\idotsint_{\\mathbb{R}^n} f(y_1, y_2, \\ldots, y_n) \\, dy_1 dy_2 \\ldots dy_n = 1\n\\]\nAlso, we can calculate the probability by evaluating the integrals at the corret region. Similar to discrete we define the following (assume that we have two random variables for easiness of demonstrations):\n\n\\(f_X(x) = \\int f(x, y) \\, dy\\) (marginal pdf of \\(X\\))\n\\(f_{X|Y}(x|y) = \\frac{f(x, y)}{f(y)}\\) (conditional pdf of \\(X\\) given \\(Y = y\\))\n\\(E(g(X, Y)) = \\iint g(x, y) f(x, y) \\, dx dy\\)\n\\(E(c) = c\\), etc.",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#conditional-expectation",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#conditional-expectation",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "6 Conditional Expectation",
    "text": "6 Conditional Expectation\nNow, wtih the definition of the conditional probability, we can define the conditional expectations as the following. \\[\nE(X \\mid Y = y) = \\begin{cases}\n\\sum_x xp(x \\mid y), & \\text{if $X$ is discrete} \\\\\n\\int x f(x\\mid y) dx, & \\text{if $X$ is continuous} \\\\\n\\end{cases}\n\\]\n\n\n\n\n\n\nExample 6 ‚Äî Multivariate Continuous Random Variables\n\n\n\n\n\nSuppose \\(X\\) and \\(Y\\) are two continuous random variables with joint pdf \\[\nf(x, y) = cxy, \\qquad 0 &lt; x &lt; 2y &lt; 4\n\\]. Find:\n\n\\(P(X &gt; 1, Y &lt; 1)\\)\n\\(E(Y)\\)\n\\(\\rho\\)\n\\(E(X|Y = 1)\\)\n\n\n\n\\(P(X &gt; 1, Y &lt; 1)\\)\n\nThis question is nothing hard when you recognise the fact that it is simply a multi-variate integral question. However, we first need to determine the constant.\n\\[\n\\begin{align}\n1 & = \\int_{x=0}^4 \\int_{y=\\frac{1}{2}x}^2 cxy \\, dydx \\\\\n& = c\\int_{x=0}^4 x \\left[ \\frac{1}{2}y^2 \\right]_{\\frac{1}{2}x}^2 dx \\\\\n& = c \\int_{x=0}^4 x \\left( 2 - \\frac{1}{8} x^2 \\right)  dx \\\\\n& = c \\left[ x^2 - \\frac{1}{32}x^4 \\right]_{0}^4 \\\\\n& = c \\left(16 - \\frac{256}{32}\\right) = 8c \\\\\n\\end{align}\n\\]\nTherefore, we know that \\(c = \\frac{1}{8}\\). Now, we can proceed to evaluate the integral.\n\\[\n\\begin{align}\nP(X &gt; 1, Y &lt; 1) & = \\int_{x=1}^2 \\int_{y=\\frac{1}{2}x}^1 \\frac{xy}{8} \\, dy dx \\\\\n& = \\frac{1}{8} \\int_{x=1}^2 x \\left[ \\frac{y^2}{2} \\right]_{\\frac{1}{2}x}^1 \\, dx \\\\\n& = \\frac{1}{8} \\int_{x=1}^2 x \\left( \\frac{1}{2} - \\frac{x^2}{8} \\right) \\, dx \\\\\n& = \\frac{1}{8} \\left[ \\frac{x^2}{4} - \\frac{x^4}{32} \\right]_1^2 \\\\\n& = \\frac{9}{256} \\approx 0.035\n\\end{align}\n\\]\n\n\n\\(E(Y)\\)\n\nIn order to find the expectations, we need to have the marginal distribution. However, it can be combined into one step.\n\\[\n\\begin{align}\nE(Y) & = \\int_{y = 0}^2 y \\int_{x=0}^{2y} \\frac{xy}{8} \\, dxdy \\\\\n& = \\int_{y = 0}^2 \\frac{y^2}{8} \\left[ \\frac{x^2}{2} \\right]_0^{2y} \\, dy \\\\\n& = \\int_{y=0}^2 \\frac{y^2}{8} \\left( 2y^2 \\right) = \\int_{y=0}^2 \\frac{y^4}{4} \\, dy \\\\\n& = \\left[ \\frac{y^5}{20} \\right]_0^2  = \\frac{32}{20} = \\frac{8}{5}\n\\end{align}\n\\]\n\n\n\\(\\rho\\)\n\n\\[\n\\begin{align}\nE(Y^2) &= \\int_{y = 0}^2 y^2 \\frac{y^3}{4} \\, dy \\\\\n& = \\frac{2^6}{24} = \\frac{8}{3} \\\\\nVar(Y) & = \\frac{8}{3} - \\left( \\frac{8}{5} \\right)^2 \\\\\n& = \\frac{8}{75} \\\\\n\\end{align}\n\\]\nAlso, we need to determine the same things for \\(X\\) as well.\n\\[\n\\begin{align}\nE(X) & = \\int_{y = 0}^2 \\int_{x=0}^{2y} x f(x, y) \\, dxdy \\\\\n&= \\int_{y=0}^2 \\frac{y}{8} \\int_{x=0}^{2y} x^2 \\, dxdy \\\\\n& = \\int_{y = 0}^2 \\frac{y}{8} \\frac{8y^3}{3} \\, dy \\\\\n& = \\left[ \\frac{y^5}{15} \\right]_0^2 = \\frac{32}{15} \\\\\nE(X^2) & = \\int_{y = 0}^2 \\int_{x=0}^{2y} x^2 f(x, y) \\, dxdy \\\\\n&= \\int_{y=0}^2 \\frac{y}{8} \\int_{x=0}^{2y} x^3 \\, dxdy \\\\\n& = \\int_{y = 0}^2 \\frac{y}{8} \\frac{16y^4}{4} \\, dy = \\int_{y = 0}^2 \\frac{y^5}{2} \\, dy \\\\\n& = \\left[ \\frac{y^6}{12} \\right]_0^2 = \\frac{16}{3} \\\\\nVar(X) & = E(X^2) - (E(X))^2 \\\\\n& = \\frac{16}{3} - \\left( \\frac{32}{15} \\right)^2 \\\\\n& = \\frac{176}{225} \\\\\nE(XY) & = \\int_{y = 0}^2 \\int_{x=0}^{2y} xy f(x, y) \\, dxdy \\\\\n&= \\int_{y=0}^2 \\frac{y^2}{8} \\int_{x=0}^{2y} x^2 \\, dxdy \\\\\n& = \\int_{y = 0}^2 \\frac{y^2}{8} \\frac{8y^3}{3} \\, dy = \\int_{y = 0}^2 \\frac{y^5}{3} \\, dy \\\\\n& = \\left[ \\frac{y^6}{18} \\right]_0^2 \\\\\n& = \\frac{32}{9} \\\\\nCov(X, Y) & = E(XY) - E(X)E(Y) \\\\\n& = \\frac{32}{9} - \\frac{32}{15}\\frac{8}{5} = \\frac{32}{225} \\\\\n\\rho & = \\frac{Cov(X, Y)}{\\sqrt{Var(X)}\\sqrt{Var(Y)}} \\\\\n& = \\frac{\\frac{32}{225}}{\\sqrt{\\frac{176}{225}}\\sqrt{\\frac{8}{75}}} = 0.4924\n\\end{align}\n\\]\n\n\n\\(E(X|Y = 1)\\)\n\nLet‚Äôs first calculate the conditional distribution.\n\\[\n\\begin{align}\nf(x \\mid y) &= \\frac{f(x, y)}{f(y)}  \\\\\n& = \\frac{\\frac{xy}{8}}{\\frac{y^3}{4}} \\\\\n& = \\frac{x}{2y^2} \\, (0 &lt; x &lt; 2y) \\\\\n\\end{align}\n\\]\nThen, we can find the expectation as,\n\\[\n\\begin{align}\nE(X \\mid Y = y) & = \\int_0^{2y} \\frac{x^2}{2y^2} dx \\\\\n& = \\frac{1}{2y^2} \\frac{8y^3}{3} \\\\\n& = \\frac{4y}{3} \\\\\n\\end{align}\n\\]\nTherefore, \\(E(X | Y = 1) = \\frac{4}{3}\\).\n\n\n\n\n6.1 Random Expectations\n\nDefinition 1 (Random Expectations) By \\(E(X\\mid Y)\\), we denote the function \\(E(X\\mid Y = y)\\) with \\(y\\) replaced by \\(Y\\). This would then makes \\(E(X \\mid Y)\\) also be a random variable for which we can also apply expectations.\n\nFor example, the above would have the random expectations fo \\(X|Y\\) as \\[\nE(X \\mid Y) = \\frac{4}{3} Y\n\\]. Note that \\(E(X \\mid Y)\\) would be a random variable about \\(Y\\) rather than \\(X\\) as we have already taken the expectation over \\(X\\).\n\n\n6.2 The Law of Iterated Expectation\n\n\n\n\n\n\nApplications\n\n\n\nThis theorem is commonly used in Bayesian Inference as we will discuss in CH16.\n\n\n\nTheorem 4 (Law of Iterated Expectation) \\[\nE(X) = E(E(X \\mid Y))\n\\]\n\n\nProof. \\[\n\\begin{align}\nE(E(X\\mid Y)) & = \\int E(X | Y = y) f(y) \\, dy = \\int \\left( \\int x f(x \\mid y) \\, dx \\right) f(y) \\, dy \\\\\n& = \\iint x f(x, y) \\, dxdy = E(X)\n\\end{align}\n\\]\n\n\n\n6.3 Related Definitions and Results\n\nDefinition 2 (Conditional Expectation on Function of Random Variable) \\[\nE(g(X) \\mid Y = y) = \\begin{cases}\n\\sum_x g(x) p(x\\mid y), & \\text{if $X$ is discrete} \\\\\n\\int g(x) f(x \\mid y), & \\text{if $X$ is continuous} \\\\\n\\end{cases}\n\\]\n\\[\nE(g(X) \\mid Y) = E(g(X) \\mid Y)\n\\]\n\n\nDefinition 3 (Variance on Conditional Variable) As before, since we have obtained the expectation, we can also in a similar fashion define the variance with the expectation.\n\\[\nVar(X \\mid Y = y) = E \\left[ \\left( X - E(X \\mid Y = y) \\right)^2 \\middle\\vert Y = y \\right]\n\\]\n\n\nDefinition 4 (Conditional Covariance) \\[\nCov(X,Z) = E \\left[ (X - E(X \\mid Y = y))(Z - E(Z \\mid Y = y)) \\middle \\vert Y =y  \\right]\n\\]\n\n\nEquipped with the three definitions above, we can derivce the following alternative expression of the unconditional variables.\n\nTheorem 5 (Law of Iterated Expectation (Function of R.V.)) \\[\nE(g(X)) = E(E(g(X) \\mid Y))\n\\]\n\n\nTheorem 6 (Iterated Variance) Similar to Theorem¬†5, we can use that to derive a ‚Äúiterated‚Äù variance.\n\\[\nVar(X) = E(Var(X \\mid Y)) + Var(E(X \\mid Y))\n\\]\n\n\nTheorem 7 (Iterated Covariance) \\[\nCov(X, Z) = E(Cov(X, Z \\mid Y)) + Cov(E(X \\mid Y), E(Z \\mid Y))\n\\]\n\n\n\n6.3.1 Proofs‚Ä¶?\nThe proof of Theorem¬†5 is almost equivalent as the proof that is required for Theorem¬†4. The following will present the proof of Theorem¬†6 and Theorem¬†7.\n\n6.3.1.1 Proof of Theorem¬†6\n\nProof (Proof of Theorem¬†6). \\[\n\\begin{align}\n\\text{RHS} &= E\\left[ E\\left[ \\left( X - E\\left[X \\middle \\vert Y\\right] \\right)^2 \\middle \\vert Y \\right] \\right] + E\\left[ \\left(E\\left[X \\mid Y\\right] - E\\left[E\\left[X \\middle \\vert Y\\right]\\right]\\right)^2 \\right] \\\\\n& = E\\left[ (X - E(X \\mid Y))^2 \\right] + E\\left[ (E(X \\mid Y) - E(X))^2 \\right] \\\\\n& = E \\left[ (X-E[X \\mid Y])^2 + (E(X \\mid Y) - E(X))^2 \\right] \\\\\n& = E \\left[ X^2 - 2XE[X\\mid Y] + (E[X \\mid Y])^2 + (E[X \\mid Y])^2 - 2E(X)E(X|Y) + (E[X])^2 \\right] \\\\\n& = E[X^2] - 2 E[XE[X \\mid Y]] + 2E[(E[X \\mid Y])^2] -2E[X]E[E[X \\mid Y]] + (E[X])^2 \\\\\n& = E[X^2] - (E[X])^2 - 2E[XE[X \\mid Y]] + 2E[(E[X\\mid Y])^2] \\\\\n& = Var(X) - 2E[XE[X \\mid Y]] + 2E[(E[X \\mid Y])^2] \\\\\n\\end{align}\n\\]\nNow, if we can prove the law two terms sum to zero, we have proven the identity. In fact, we only need to show that \\[E[XE[X \\mid Y]] = E[(E[X \\mid Y])^2]\\]. Before, that, we will first show the following lemman is true.\n\nLemma 1 \\[\nE[X \\cdot g(Y)] = E[E[X \\mid Y] \\cdot g(Y)]\n\\]\n\nThe following gives the proof for continuous case in Lemma¬†1 and discrete case should follow closely. First, we again apply Theorem¬†5 (The Law of Iterated Expectations). \\[\nE[X \\cdot g(Y)] = E[E[X \\cdot g(Y) \\mid Y]]\n\\]\nNow, the following will fill in the proof for Lemma¬†1. \\[\n\\begin{align}\nE[X \\cdot g(Y) \\mid Y = y] & = E[X \\cdot g(y) \\mid Y = y] \\\\\n& = \\int_x xg(y) P[X = x \\mid Y = y] \\, dx \\\\\n& = g(y) \\int_x x P[X = x \\mid Y = y] \\, dx \\\\\n& = g(y) E[X \\mid Y = y]\n\\end{align}\n\\]\nTherefore, from the definition of random expectations (Definition¬†1), we know the following, \\[\nE[X \\cdot g(Y) \\mid Y] = g(Y) E[X \\mid Y = Y] = g(Y) E[X \\mid Y]\n\\]\nThen, we can simply apply Lemma¬†1 to the following by treating \\(g(Y) = E[X \\mid Y]\\), \\[\n\\begin{align}\nE[XE[X \\mid Y]] &= E[E[X\\cdot E[X \\mid Y] \\mid Y ]] \\\\\n&= E[E[X \\cdot g(Y) \\mid Y]] \\qquad (\\text{Let $g(Y) = E[X \\mid Y]$}) \\\\\n&= E[g(Y) E[X \\mid Y]] = E[(E[X \\mid Y])^2]\n\\end{align}\n\\] in which the lemman is applied in the second step.\n\n\n\n6.3.1.2 Proof of Theorem¬†7\n\nProof (Proof of Theorem¬†7). Similar to above, we will first expand the terms and see if there is any things we can reduce.\n\\[\n\\begin{align}\n\\text{RHS} &= E\\left[ E\\left[ (X - E[X \\mid Y])(Z - E[Z \\mid Y]) \\mid Y \\right] \\right] + E\\left[ (E[X \\mid Y] - E[E[X \\mid Y]])(E[Z \\mid Y] - E[E[Z \\mid Y]]) \\right] \\\\\n& = E[(X - E[X \\mid Y])(Z - E[Z \\mid Y])] + E\\left[ (E[X \\mid Y] - E[X])(E[Z \\mid Y] - E[Z]) \\right] \\\\\n\\end{align}\n\\]\nThe last step is arrived by using the law of iterated expectation. Now, let‚Äôs simply the first term first,\n\\[\n\\begin{align}\nE\\left[ (X - E[X \\mid Y])(Z - E[Z \\mid Y]) \\right] & = E[XZ - X E[Z \\mid Y] - ZE[X \\mid Y] + E[X\\mid Y]E[Z \\mid Y]] \\\\\n& = E[XZ] - E[XE[Z \\mid Y]] - E[Z E[X \\mid Y]] + E[E[X \\mid Y]E[Z \\mid Y]] \\\\\n& = E[XZ - E[X\\mid Y]E[Z \\mid Y]]\n\\end{align}\n\\]\nGoing from line (2) to line (3) is by using Lemma¬†1 as same way as it is applied in the last step in the proof of Theorem¬†6 above. Then, the original expression is simplified as,\n\\[\n\\begin{align}\n\\text{Exp} & = E[XZ - E[X\\mid Y]E[Z\\mid Y] + (E[X \\mid Y] - E[X])(E[Z \\mid Y] - E[Z])] \\\\\n& = E[XZ - E[X \\mid Y][Z \\mid Y] + E[X\\mid Y][Z \\mid Y] - E[X]E[Z \\mid Y] - E[Z]E[X \\mid Y] + E[X]E[Z]] \\\\\n& = E[XZ] - E[X]E[Z] - E[X]E[E[Z \\mid Y] + E[Z]E[E[X\\mid Y]]] \\\\\n& = E[XZ] - E[X]E[Z] - E[X]E[Z] + E[Z]E[X] \\\\\n& = E[XZ] - E[X]E[Z] = Cov(X, Z) \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\n\nComment\n\n\n\nHence, we can see that the hard part is actually to see Lemma¬†1 which is done in the last proof. Hence, this proof is relatively simple.\n\n\n\n\n\n6.3.2 Examples\n\n\n\n\n\n\nExample 7\n\n\n\nTwenty bolts have just been randomly sampled from the production line in a factory. You are now going to count the number of defectives amongst them.\nFrom experience, you know that the proportion of defective bolts produced in the factory is constant throughout any given day, but varies from day to day in a uniform manner between \\(0.1\\) and \\(0.3\\).\nFind:\n\nHow many defective bolts do you expect to find?\nWhat is the variance of the number of defective bolts?\n\nSolution:\n\n\nHow many defective bolts do you expect to find?\n\nLet \\(X\\) be the number of defectives amongst the 20, and let \\(Y\\) be the proportion of defectives amongst all bolts produced in the factory today.\nThen \\((X | Y = y) \\sim \\text{Bin}(20, y)\\), and \\(Y \\sim U(0.1, 0.3)\\). So \\(E[X \\mid Y = y] = 20y \\implies E[X \\mid Y] = 20Y\\) and \\(E[Y] = 0.2\\).\nTherefore, \\(E[X] = E[E[X \\mid Y]] = E[20Y] = 20 \\times 0.2 = 4\\).\n\n\nWhat is the variance of the number of defective bolts?\n\nSimilarly, we will use Theorem¬†6 to determine the variance.\nFirst, \\[Var[Y] = \\frac{0.04}{12} = \\frac{1}{300} = 0.0033 \\hspace{30pt} E[Y^2] = Var(Y) + (E[Y])^2 = \\frac{13}{300} = 0.43\\]. Also, we now that \\[Var(X \\mid Y) = nY(1-Y)\\] since \\((X \\mid Y = y) \\sim \\text{Bin}(20, y)\\). Therefore, \\[\n\\begin{align}\nVar(X) &= E[Var(X \\mid Y)] + Var(E[X \\mid Y]) \\\\\n& = E[20Y(1 - Y)] + Var(20Y) \\\\\n& = E[20Y] - E[20Y^2] + 400Var(Y) \\\\\n& = 20 * 0.2 - 20 \\left(\\frac{13}{300}\\right) + 400 \\left( \\frac{1}{300} \\right) = \\frac{67}{15} = 4.4667 \\\\\n\\end{align}\n\\]\n\nI think this example question can easily become a bayesian estimate question by throwing another question about the distribution of \\(Y | X\\).",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#footnotes",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#footnotes",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI believe this is generally a plausible assumptions to make otherwise it is possible to run out of items when you are performing the trials.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html",
    "href": "contents/chapter-05/01-distributions.html",
    "title": "Introduction",
    "section": "",
    "text": "Motivating Example\n\n\n\nA die is rolled. Let \\(X\\) = no. of 6‚Äôs and \\(Y\\) = no. of even numbers. Find the joint probability distribution of \\(X\\) and \\(Y\\).\n\n\n\n\nTable¬†1: Possible Outcomes\n\n\n\n\n\nNumber on Die\n1\n2\n3\n4\n5\n6\n\n\n\n\nValue of X\n0\n0\n0\n0\n0\n1\n\n\nValue of Y\n0\n1\n0\n1\n0\n1\n\n\n\n\n\n\nHence,\n\\[\n\\begin{align}\n   P(X = 1, Y = 1) &= P(6) = 1 / 6 \\\\\n   P(X = 0, Y = 1) &= P(2 \\text{ or } 4)  = 1/ 3 \\\\\n   P(X = 0, Y = 0) &= P(1 \\text{ or } 3 \\text{ or } 5) = 1/2 \\\\\n\\end{align}\n\\]\nWe say that \\(X\\) and \\(Y\\) have a joint probability distribution. The joint pmf of \\(X\\) and \\(Y\\) is\n\\[\np(x, y) = P(X = x, Y = y) = \\begin{cases}\n   1/2, & x = y = 0 \\\\\n   1/3, & x = 0, y = 1 \\\\\n   1/6, & x = y = 1 \\\\\n\\end{cases}\n\\]\nNote that the joint probability distribution of \\(X\\) and \\(Y\\) can be presented as,\n\n\n\nAnother way to present",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#discrete-joint-pmf",
    "href": "contents/chapter-05/01-distributions.html#discrete-joint-pmf",
    "title": "Introduction",
    "section": "1 Discrete Joint PMF",
    "text": "1 Discrete Joint PMF\n\n1.1 Properties\n\n\\(0 \\leq p(x, y) \\leq 1\\) for all \\(x\\) and \\(y\\)\n\\(\\sum_{x, y} p(x, y) = 1\\)",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#joint-cdf",
    "href": "contents/chapter-05/01-distributions.html#joint-cdf",
    "title": "Introduction",
    "section": "2 Joint CDF",
    "text": "2 Joint CDF\nThe joint cdf of \\(X\\) and \\(Y\\) is \\(F(x, y) = P(X \\leq x, Y \\leq y)\\).\n\n2.1 Properties of joint CDFs\n\n\\(F(x, y) \\to 0\\) as \\(x \\to -\\infty\\) or \\(y \\to -\\infty\\) (or both).\n\\(F(x, y) \\to 1\\) as \\(x \\to \\infty\\) and \\(y \\to \\infty\\)\n\\(F(x, y)\\) is nondecreasing in both \\(x\\) and \\(y\\) directions.\n\\(F(x, y)\\) is right-continuous in both \\(x\\) and \\(y\\) directions.\n\nNote that with their properties in mind, the joint cdf of \\(X\\) and \\(Y\\) in our example could be written more simply as\n\\[\nF(x, y) = \\begin{cases}\n   1/2, & x \\geq 0, 0 \\leq y &lt; 1 \\\\\n   5/6, & 0 \\leq x &lt; 1, y \\geq 1  \\\\\n\\end{cases}\n\\]",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#marginal-pmfs",
    "href": "contents/chapter-05/01-distributions.html#marginal-pmfs",
    "title": "Introduction",
    "section": "3 Marginal PMFs",
    "text": "3 Marginal PMFs\nThe marginal pmf of \\(X\\) is\n\\[\np(x) = \\sum_y p(x, y)\n\\]\nThis pmf defines the marginal probability mass function of \\(X\\). Can also write \\(p(x)\\) as \\(p_X(x)\\).\n\n3.1 Marginal CDF\nThen, we can easily define the cdf of \\(X\\) with the above definition of the marginal pmf of \\(X\\) as \\[\nF(x) = P(X \\leq x)\n\\]",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#conditional-pmf",
    "href": "contents/chapter-05/01-distributions.html#conditional-pmf",
    "title": "Introduction",
    "section": "4 Conditional PMF",
    "text": "4 Conditional PMF\nThe conditional pmf of \\(X\\) given that \\(Y = y\\) is \\[\np(x \\mid y) = \\frac{p(x, y)}{p(y)}\n\\]\nThis density defines the conditional probability distribution for \\(X\\) given that \\(Y = y\\).\n\n4.1 Degenerate Distribution\nIt is possible that the probability of \\(X\\) collapses to only one outcome and it is certain about that outcome with the given y-values.",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#independence-of-random-variables",
    "href": "contents/chapter-05/01-distributions.html#independence-of-random-variables",
    "title": "Introduction",
    "section": "5 Independence of Random Variables",
    "text": "5 Independence of Random Variables\nRecall that two events \\(A\\) and \\(B\\) are independent if \\(P(AB) = P(A)P(B)\\). Then, we can similarity define that the two random variables \\(X\\) and \\(Y\\) are independent if for all \\(x\\) and \\(y\\), \\[\np(x, y) = p(x) p(y)\n\\]\nWe then write \\(X \\perp Y\\) if the two are independent.",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#expectations",
    "href": "contents/chapter-05/01-distributions.html#expectations",
    "title": "Introduction",
    "section": "6 Expectations",
    "text": "6 Expectations\n\\[\nE(g(X, Y)) = \\sum_{x, y} g(x, y) p(x, y)\n\\]\nFor example,\n\\[\nE(XY) = \\sum_{x, y} xyp(x, y) = 0 * p(0, 0) + 0 * p(0, 1) + 1 p(1, 1) = p(1, 1) = 1/ 6\n\\]\n\n6.1 Covariance and Correlation\n\nTheorem 1 (Another Expression of Covariance) The covariance between \\(X\\) and \\(Y\\) is \\[\nCov(X,Y) = E\\{ ( X - E(X))(Y - E(Y)) \\}\n\\]\n\nWhat‚Äôs the covariance between \\(X\\) and \\(Y\\) in our example?\nRecall that \\(X \\sim \\text{Bern}(1/6)\\) and \\(Y \\sim \\text{Bern}(1/2)\\). Therefore \\(E(X) = 1/6\\) and \\(E(Y) = 1/2\\).\nIt follows that \\[\n\\begin{align}\nCov(X, Y) & = \\sum_{x, y} \\left(x - \\frac{1}{6} \\right)\\left(y - \\frac{1}{2}\\right) p(x, y) \\\\\n& =\\frac{1}{12} \\frac{1}{2} + \\left(-\\frac{1}{12}\\right)\\frac{1}{3} + \\frac{5}{12}\\frac{1}{6} = \\frac{1}{12} \\\\\n\\end{align}\n\\]\nA useful result: \\[\nCov(X, Y) = E(XY) - E(X)E(Y)\n\\]\n\nProof. \\[\n\\begin{align}\n\\text{LHS} &= E\\{ (X - \\mu_X)(Y - \\mu_Y) \\} = E \\{ XY - X \\mu_X - Y \\mu_Y + \\mu_X \\mu_Y \\} \\\\\n& = E(XY) - E(X)\\mu_Y - E(Y)\\mu_X + \\mu_X \\mu_Y \\\\\n& = E(XY) - \\mu_X \\mu_Y = \\text{RHS}\n\\end{align}\n\\]\n\n\n\n6.2 Correlation\nThe correlation between \\(X\\) and \\(Y\\) is \\[\n\\rho = Cor(X, Y) = \\frac{Cov(X, Y)}{SD(X)SD(Y)} = \\frac{Cov(X, Y)}{\\sqrt{Var(X)} \\sqrt{Var(Y)}}\n\\]\nNote that this is slightly more useful because this coefficient is ‚Äúnormalised‚Äù between \\(-1\\) and \\(1\\).\n\n6.2.1 Meaning\n\\(\\rho\\) provides information about the relationship between \\(X\\) and \\(Y\\). If \\(\\rho &gt; 0\\) then high values of \\(X\\) are associated with high values of \\(Y\\). If \\(\\rho &lt; 0\\), then high values of \\(X\\) are associated with low values of \\(Y\\).\n\\(-1 \\leq \\rho \\leq 1\\) (In contrast \\(Cov(X, Y) \\in [-\\infty, \\infty]\\).\n\nTheorem 2 \\[X \\perp Y \\implies \\rho = 0\\]\n\n\nProof. First, we can show that \\(Cov(X, Y) = 0\\) if the two random variables are independent.\n\\[\n\\begin{align}\nCov(X, Y) &= E(XY) - \\mu_X \\mu_Y \\\\\n& = E(X)E(Y) - \\mu_X \\mu_Y = 0\n\\end{align}\n\\]\nWhere as the first line is by Theorem¬†1 and the second line is by independence of the two random variables.\nNow, since \\(\\rho = \\frac{Cov(X, Y)}{SD(X)SD(Y)}\\), \\(\\rho = 0\\).",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html",
    "href": "contents/chapter-03/1rv.html",
    "title": "Known Discrete Distributions",
    "section": "",
    "text": "The first is the binomial distribution. This has to do with experiments which involve doing something several times, independently, and observing the number of ‚Äòsuccesses‚Äô.\n\n\nExample 1 A die is rolled 7 times. Let \\(Y\\) be the number of 6‚Äôs which come up. Find \\(Y\\)‚Äôs pmf.\n\\[\\begin{align*}\nP(Y = 3) & = P(Three 6's and four non-6's, in any order) \\\\\n& = P(6660000) + P(6606000) + \\cdots + P(0000666) \\\\\n& = \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 + \\left( \\frac{1}{6}\\right)^2 \\frac{5}{6} \\frac{1}{6} \\left( \\frac{5}{6}\\right)^3 + \\cdots + \\left( \\frac{5}{6}\\right)^4 \\left( \\frac{1}{6} \\right)^3 \\\\\n& = \\binom{7}{3} \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 \\approx 0.0781\n\\end{align*}\\]\n\n\nOverall, we can conclude that,\n\nTheorem 1 A random variable \\(Y\\) has the binomial distribution with parameters \\(n\\) and \\(p\\) if its pmf is of the form\n\\[\np(y) = \\binom{n}{y} p^y(1-p)^{n-y}, \\quad y = 0, 1, 2, \\ldots, n\n\\]\n\nWe write \\(Y \\sim \\text{Bin}(n, p)\\). We call \\(n\\) the number of trials and \\(p\\) the probability of success.\n\n\nExample 2 A coin is going to be tossed 10 times. Find the probability that 3 heads come up. Let \\(Y\\) be the number of heads that come up. Then \\(Y \\sim \\text{Bin}(10, 0.5)\\).\nThen this problem is simply evaluating \\(p(3)\\) by using the pm from Theorem¬†1.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#binomial-distribution",
    "href": "contents/chapter-03/1rv.html#binomial-distribution",
    "title": "Known Discrete Distributions",
    "section": "",
    "text": "The first is the binomial distribution. This has to do with experiments which involve doing something several times, independently, and observing the number of ‚Äòsuccesses‚Äô.\n\n\nExample 1 A die is rolled 7 times. Let \\(Y\\) be the number of 6‚Äôs which come up. Find \\(Y\\)‚Äôs pmf.\n\\[\\begin{align*}\nP(Y = 3) & = P(Three 6's and four non-6's, in any order) \\\\\n& = P(6660000) + P(6606000) + \\cdots + P(0000666) \\\\\n& = \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 + \\left( \\frac{1}{6}\\right)^2 \\frac{5}{6} \\frac{1}{6} \\left( \\frac{5}{6}\\right)^3 + \\cdots + \\left( \\frac{5}{6}\\right)^4 \\left( \\frac{1}{6} \\right)^3 \\\\\n& = \\binom{7}{3} \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 \\approx 0.0781\n\\end{align*}\\]\n\n\nOverall, we can conclude that,\n\nTheorem 1 A random variable \\(Y\\) has the binomial distribution with parameters \\(n\\) and \\(p\\) if its pmf is of the form\n\\[\np(y) = \\binom{n}{y} p^y(1-p)^{n-y}, \\quad y = 0, 1, 2, \\ldots, n\n\\]\n\nWe write \\(Y \\sim \\text{Bin}(n, p)\\). We call \\(n\\) the number of trials and \\(p\\) the probability of success.\n\n\nExample 2 A coin is going to be tossed 10 times. Find the probability that 3 heads come up. Let \\(Y\\) be the number of heads that come up. Then \\(Y \\sim \\text{Bin}(10, 0.5)\\).\nThen this problem is simply evaluating \\(p(3)\\) by using the pm from Theorem¬†1.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#bernoulli-distribution",
    "href": "contents/chapter-03/1rv.html#bernoulli-distribution",
    "title": "Known Discrete Distributions",
    "section": "2 Bernoulli Distribution",
    "text": "2 Bernoulli Distribution\nThis is a special case of the binomial distribution when \\(n = 1\\). Hence, we can define a very simple form of pmf.1\n\nTheorem 2 It is easy to see from Theorem¬†1 that\n\\[\np(y) = \\begin{cases}\np & y = 1 \\\\\n1 - p & y = 0 \\\\\n\\end{cases}\n\\]\nwhere \\(0 \\leq p \\leq 1\\).\n\nWe write \\(Y \\sim \\text{Bern}(p)\\) and we cal \\(p\\) the probability of success, as before.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#geometric-distribution",
    "href": "contents/chapter-03/1rv.html#geometric-distribution",
    "title": "Known Discrete Distributions",
    "section": "3 Geometric Distribution",
    "text": "3 Geometric Distribution\nHere is a motivating example for geometric distribution.\n\n\nExample 3 A die is rolled repeated until the first 6 comes up. Find the pmf of \\(Y\\), the number of rolls.\n$P(Y = 3) = P() = P(006) = (5/6)^2(1/6) = 0.0231. Similarly, $P(Y = 4) = (5/6)^3(1/6) = 0.00386.\n\n\nNow, from the above example, we can see that \\(p(y) = (5/6)^{y-1}(1/6), \\quad y = 1, 2, \\ldots\\). We say that \\(Y\\) has a geometric distribution (with parameter \\(1/6\\)).\n\nTheorem 3 A random variable \\(Y\\) has the geometric distribution with parameter \\(p\\) if its pmf is of the form.\n\\[\np(y) = (1 - p)^{y-1}p, \\qquad y = 1, 2, 3, \\ldots\n\\]\nwhere \\(0 \\leq p \\leq 1\\).\n\nWe write \\(Y \\sim \\text{Geo}(p)\\). We call \\(p\\) the probability of success, as before.\n\nTheorem 4 Note that the above geometric pmf is proper.\n\n\nProof. \\[\\begin{align*}\n\\sum_{y=1}^\\infty (1 - p)^{y-1}p & = p \\sum_{x = 0}^{\\infty} (1 - p)^x \\tag{put $x = y - 1$} \\\\\n& = p \\times \\frac{1}{1 - (1 - p)} = 1 \\tag{Property 2}\n\\end{align*}\\]\n\n\n3.1 Application of Geometric Distribution\nNote that the geometric distribution can be used to model waiting times.\n\nExample 4 Suppose that the probability of an engine malfunctioning during any 1-hr period is 0.02. Find the pr that the engine will survive 2 hours.\nLet \\(Y\\) be the number of 1-hr periods until the first malfunction (including the 1-hr period in which that malfunction occurs). Then \\(Y \\sim \\text{Geo}(p)\\), where \\(p = 0.02\\)\nExample: A malfunction in the 3rd 1-hr period means that \\(Y = 3\\).\n\\[\\begin{align*}\nP(Y &gt; 2) & = \\sum_{y=3}^{\\infty} q^{y-1}p \\tag{$q = 1 - p = 0.98$} \\\\\n& = pq^2 \\sum_{y=3}^{\\infty} q^{y-3} \\\\\n& = pq^2 \\sum_{x=0}^{\\infty} q^x \\tag{after putting $x=y - 3$} \\\\\n& = pq^2 \\frac{1}{1 - q} = q^2 = 0.98^ = 0.9604 \\\\\n\\end{align*}\\]\nThis may be calculated more simply as: \\[\nP(Y &gt; 2) = 1 - P(Y \\leq 2) = 1 - (p(1) + p(2)) = 1 - (p + qp) = q^2\n\\]\nor even more simply as: \\[\nP(Y &gt; 2) = P(\\text{Survive 2 hours}) = P(\\text{No failures in first 2 hours}) = q^2\n\\]\n\n\n\n3.2 mgf of Geometric\n\nTheorem 5 (MGF of Geometric Distribution) \\[\\begin{align*}\nE(e^{Yt}) & = \\sum_{y=1}^\\infty e^{yt} (1 - p)^{y-1}p \\\\\n& = pe^t \\sum_{y = 1}^\\infty e^{(y - 1)t} (1 - p)^{y - 1} \\\\\n& = p e^t \\sum_{y = 1}^\\infty ((1 - p)e^t)^(y - 1) \\\\\n& = \\frac{p e^t}{1 - (1 - p)e^t} \\tag{Sum of geometric series} \\\\\n\\end{align*}\\]",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#hypergeometric-distribution",
    "href": "contents/chapter-03/1rv.html#hypergeometric-distribution",
    "title": "Known Discrete Distributions",
    "section": "4 Hypergeometric Distribution",
    "text": "4 Hypergeometric Distribution\n\nExample 5 The motivation of this hypergeometric distribution has to do with sampling objects from a box, without replacement, and observing how many have a certain characteristic.\nA box has 9 marbles, of which 3 are white and 6 are black. You randomly select 5 marbles from the box (without replacement). Find the pmf of \\(Y\\), the number of white marbles amongst the selected 5.\nNumber the 9 marbles \\(1, 2, \\ldots, 9\\) with the first 3 being white and the last 6 black. Then the sample points may be represented by writing 12345, 12346, ‚Ä¶, 56789.\nNote: We don‚Äôt write 13245, because this represents the same sample point as 12345. In other words, the distinct sample points correspond to strings of numbers in increasing order. Hence the total number of sample points is \\(n_S = \\binom{9}{5}\\).\nThe sample points associated with the event \\(Y = 2\\) are 12456, 12457, ‚Ä¶, 23789, and the number of these is $n_2 = . We require 2 numbers to be from 1,2,3, and the other 3 from 4,5,6,7,8,9.\n\\[\nP(Y = 2) = \\frac{n_2}{n_S} = \\frac{\\binom{3}{2}\\binom{6}{3}}{\\binom{9}{5}} = \\frac{3(20)}{126} = \\frac{10}{21} = 0.4762\n\\]\n\\[\nP(Y=1) = \\frac{n_1}{n_S} = \\frac{\\binom{3}{1} \\binom{6}{4}}{\\binom{9}{5}} = \\frac{3(15)}{126} = \\frac{5}{14} = 0.3571\n\\]\nWe see that \\(Y\\) has pmf \\[\np(y) = \\frac{\\binom{3}{y}\\binom{6}{5-y}}{\\binom{9}{5}}, \\quad y = 0,1,2,3.\n\\]\nWe say that \\(Y\\) has a hypergeometric distribution (with parameters 9, 3, and 5).\n\n\n\nTheorem 6 A random variable \\(Y\\) has the hypergeometric distribution with parameters \\(N\\), \\(r\\) and \\(n\\) if its pmf is of the form \\[\np(y) = \\frac{\\binom{r}{y}\\binom{N - r}{n - y}}{\\binom{N}{n}}, \\quad y = 0,1,2,\\ldots,r,\n\\]\nSubject to \\(0 \\leq n - y \\leq N - r\\) and \\(N = 1,2,3,\\ldots; \\; r = 1,2,\\ldots,N; n = 1,2,\\ldots, N\\).\nThe number of black balls sampled, \\(n-y\\), can‚Äôt be less than 0 or more than the total number of black balls in the box, \\(N - r\\).\n\nWe write \\(Y \\sim \\text{Hyp}(N, r, n)\\). We may call \\(N\\) ‚Äúthe number of balls‚Äù (parameter), \\(r\\) ‚Äúthe number of white balls‚Äù, and \\(n\\) ‚Äúthe number of sampled balls‚Äù.\n\n\nExample 6 There are 10 men and 15 women in a room. 8 people are chosen randomly to form a committee. Find the probability that the committee contains 6 women.\nLet \\(Y = \\text{number of women on the committee}\\). Then \\(Y \\sim \\text{Hyp}(25, 15, 8)\\) and so\n\\[\np(6) = \\frac{\\binom{15}{6}\\binom{10}{2}}{\\binom{25}{8}} = 0.2082\n\\]",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#poisson-distribution",
    "href": "contents/chapter-03/1rv.html#poisson-distribution",
    "title": "Known Discrete Distributions",
    "section": "5 Poisson Distribution",
    "text": "5 Poisson Distribution\nGenerally, one can think of the Poisson distribution being when \\(n \\to \\infty\\) version of the binomial distribution with the expected value being \\(\\lambda\\). The derivation is given in the below.\n\nTheorem 7 Poisson distribution is, in essence, a binomial distribution with \\(n \\to \\infty\\) and \\(p = \\lambda / n\\).\n\n\nProof. Now, suppose \\(X \\sim \\text{Bin}(n, \\lambda / n)\\). Then, the above description in the mathematical notation is,\n\\[\n\\begin{align*}\n\\lim_{n \\to \\infty} p_X(x) & = \\lim_{n \\to \\infty} \\binom{n}{x} \\left( \\frac{\\lambda}{n} \\right)^x \\left(1 - \\frac{\\lambda}{n}\\right)^{n-x} \\\\\n& = \\lim_{n \\to \\infty} \\frac{n!}{x! (n-x)!} \\left( \\frac{\\lambda}{n} \\right)^x \\left(1 - \\frac{\\lambda}{n}\\right)^{n-x} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left( \\frac{n!}{(n - x)!} \\frac{1}{n^x} \\right) \\left(1 - \\frac{\\lambda}{n} \\right)^{n - x} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{n - x} \\tag{First part evaluate to 1 with L'Hopital's} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{n} \\left(1 - \\frac{\\lambda}{n}\\right)^{-x} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{n} \\tag{The second term is one as the power does not depend on $n$} \\\\\n& = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\\end{align*}\n\\]\nThen, we have two ways to go from here, simply declare that this is the pmf for Poisson or we can confirm this with the ‚Äúknown‚Äù poisson pmf which is, I guess for me, from thin air‚Ä¶\n\n\n\nCorollary 1 The pmf of Poisson distribution is \\[\np(x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\\]\n\n\nProof. This is simply a restatement of the results from Theorem¬†7.\n\n\nNow, I guess the remaining part is to show that the expectation is indeed \\(\\lambda\\).\n\nTheorem 8 X () E(X) = \n\n\nProof. \\[\\begin{align*}\nE(X) & = \\sum_{x = 0}^\\infty x \\frac{e^{-\\lambda} \\lambda^x}{x!} \\\\\n& = e^{-\\lambda}\\lambda \\sum_{x=1}^\\infty \\frac{\\lambda^{x-1}}{(y-1)!} \\\\\n& = e^{-\\lambda} \\lambda \\sum_{x=0}^\\infty \\frac{\\lambda^x}{x!} \\\\\n& = e^{-\\lambda}\\lambda e^{\\lambda} = \\lambda \\\\\n\\end{align*}\\]\n\n\nExample 7 \\[\\begin{align*}\nE(Y(Y - 1)) & = \\sum_{y = 0}^\\infty y(y-1) \\frac{\\lambda^y e^{-\\lambda}}{y!} \\\\\n& = \\lambda^2 \\sum_{y = 2}^\\infty \\frac{\\lambda^{y - 2} e^{-\\lambda}}{(y-2)!} \\tag{First two terms are 0} \\\\\n& = \\lambda^2 \\sum_{x=0}^\\infty \\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n& = \\lambda^2 \\tag{The infinite sum is 1 as it is the sum of pmf of $X \\sim Pois(\\lambda)$} \\\\\n\\end{align*}\\]\n\nTherefore, \\(Var(Y) = E(Y(Y-1)) + E(Y) - (E(Y))^2 = \\lambda\\).\n\n\n5.1 Poisson Approximation to the Binomial\nThe Binomial distribution can be approximated by the poisson distribution with \\(\\lambda = np\\) when \\(n\\) is ‚Äúlarge‚Äù and \\(p\\) is ‚Äúsmall‚Äù.\nGenerally, the Poisson approximation should be considered only when the exact binomial probability is hard or impossible to calculate. As a rule of thumb, the Poisson approximation is ‚Äògood‚Äô if \\(n\\) is at least 20 and \\(p\\) is at most 0.05, or if \\(n\\) is at least 100 and \\(np\\) is at most 10.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#negative-binomial-distribution",
    "href": "contents/chapter-03/1rv.html#negative-binomial-distribution",
    "title": "Known Discrete Distributions",
    "section": "6 Negative Binomial Distribution",
    "text": "6 Negative Binomial Distribution\nSimilar to geometric distribution where we have independent and identical trials. We observe either success or fail on each trial. The probability of success on each trial is \\(p\\).\nThe geometric distribution handles the case where we are interested in the number of trial on which the first success occurs. \\(Y = 1,2,3,\\ldots\\) counts the number of trials until the first success.\nWhat if we are interested in knowing the number of the trial on which the second, third, or fourth success occurs? \\(Y = r, r+1, r+2, \\ldots\\) (\\(r = 1, 2, 3, \\ldots\\)). \\(r\\) is a parameter (\\(r =1\\) for geometric).\n\nTheorem 9 The pmf og negative binomial distribution is,\n\\[\np(y) = P(Y = y) = \\binom{y - 1}{r - 1} p^{r-1}q^{y-r}\n\\] , where \\(r\\) is the number of success; \\(p\\) and \\(q\\) defined as usual.\nBy simple counting methods as covered before.\n\n\n\nTheorem 10 (Mean of Negative Binomial) Suppose \\(Y \\sim \\text{NegBin}(r, p)\\), then \\(E(Y) = \\frac{r}{p}\\).\n\n\nProof. The direct proof is extremely hard. However, the trick of recognising that a negative binomial distribution is, in fact, nothing more than \\(r\\) geometric distribution put in sequence. Therefore, suppose \\(Y = Y_1 + Y_2 + \\cdots + Y_r\\), where each \\(Y_i\\) follows \\(\\text{Geo}(p)\\). Then,\n\\[\\begin{align*}\nE(Y) & = E(\\sum_{i = 1}^r Y_i) \\\\\n& = \\sum_{i=1}^r E(Y_i) \\\\\n& = \\sum_{i = 1}^r \\frac{1}{p} = \\frac{r}{p} \\\\\n\\end{align*}\\]\nThe last step relies on mgf and expectation from it as shown in Theorem¬†5.\n\n\nTheorem 11 (Variance of Negative Binomial) If \\(Y \\sim \\text{NegBin}(r, p)\\), then \\(Var(Y) = \\frac{r(1-p)}{p^2}\\).\n\n\nProof. Similar to above by using independency and directly decomposing the variance of a geometric distribution.\n\n\n\nTheorem 12 (MGF of Negative Binomial) Suppose \\(Y \\sim \\text{NegBin}(r, n)\\), then \\[\nm_Y(t) = \\left( \\frac{pe^t}{1 - (1 - p)e^t} \\right)^r\n\\]\n\n\nProof. The direct proof is relatively hard to see. However, using Theorem¬†5 with mgf of independent variable is obvious since negative binomial distribution is really just \\(r\\) independent geometric distribution puts in a series.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#footnotes",
    "href": "contents/chapter-03/1rv.html#footnotes",
    "title": "Known Discrete Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, many people define this first and simply describe the binomial distribution as a repeated bernoulli trial with bernoulli distribution.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-09/1properties.html",
    "href": "contents/chapter-09/1properties.html",
    "title": "Properties of Point Estimators",
    "section": "",
    "text": "Definition 1 The efficiency of \\(A\\) relative \\(B\\) for \\(A\\) and \\(B\\) are two unbiased estimators of a parameter \\(\\theta\\), \\[\n\\Eff{A, B} = \\frac{\\Var{B}}{\\Var{A}}\n\\]\nIn other words, we want to say that \\(A\\) is more efficient than \\(B\\) when \\(\\Var{A} &lt; \\Var{B}\\)\n\n\n\n\nExample 1 Two numbers \\(X\\) and \\(Y\\) are to be randomly and independently chosen from between \\(0\\) and \\(c\\).\nConsider \\(U = X + Y\\) and \\(W = 1.5\\max(X, Y)\\) as two estimators of \\(c\\). Find the efficiency of \\(U\\) relative to \\(W\\)\n\n\nSolution. In Example 2 Chapter 8, we showed that \\(U\\) and \\(W\\) are both unbiased for \\(c\\).\nWe also showed that \\(\\Var{U} = c^2 / 6\\) and \\(\\Var{W} = c^2 / 8\\).\nTherefore \\(\\Eff{U, W} = \\frac{\\Var{W}}{\\Var{U}} = \\frac{c^2 / 8}{c^2 / 6} = 0.75\\)\nThus \\(W\\) is more efficient than \\(U\\). \\(W\\)‚Äôs variance is only \\(3/4\\) the variance of \\(U\\).",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Properties of Point Estimators"
    ]
  },
  {
    "objectID": "contents/chapter-09/1properties.html#efficiency",
    "href": "contents/chapter-09/1properties.html#efficiency",
    "title": "Properties of Point Estimators",
    "section": "",
    "text": "Definition 1 The efficiency of \\(A\\) relative \\(B\\) for \\(A\\) and \\(B\\) are two unbiased estimators of a parameter \\(\\theta\\), \\[\n\\Eff{A, B} = \\frac{\\Var{B}}{\\Var{A}}\n\\]\nIn other words, we want to say that \\(A\\) is more efficient than \\(B\\) when \\(\\Var{A} &lt; \\Var{B}\\)\n\n\n\n\nExample 1 Two numbers \\(X\\) and \\(Y\\) are to be randomly and independently chosen from between \\(0\\) and \\(c\\).\nConsider \\(U = X + Y\\) and \\(W = 1.5\\max(X, Y)\\) as two estimators of \\(c\\). Find the efficiency of \\(U\\) relative to \\(W\\)\n\n\nSolution. In Example 2 Chapter 8, we showed that \\(U\\) and \\(W\\) are both unbiased for \\(c\\).\nWe also showed that \\(\\Var{U} = c^2 / 6\\) and \\(\\Var{W} = c^2 / 8\\).\nTherefore \\(\\Eff{U, W} = \\frac{\\Var{W}}{\\Var{U}} = \\frac{c^2 / 8}{c^2 / 6} = 0.75\\)\nThus \\(W\\) is more efficient than \\(U\\). \\(W\\)‚Äôs variance is only \\(3/4\\) the variance of \\(U\\).",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Properties of Point Estimators"
    ]
  },
  {
    "objectID": "contents/chapter-09/1properties.html#convergence-in-probability",
    "href": "contents/chapter-09/1properties.html#convergence-in-probability",
    "title": "Properties of Point Estimators",
    "section": "2 Convergence in Probability",
    "text": "2 Convergence in Probability\n\nSuppose that \\(X = X_n\\) is a random variable and \\(k\\) is a constant such that, for any \\(\\varepsilon &gt; 0\\): \\[\n\\P{\\lvert X - k \\rvert &gt; \\varepsilon} \\to 0 \\hspace{10pt} \\text{as} \\hspace{10pt} n \\to \\infty.\n\\] Then we say that \\(X\\) converges in probability to \\(k\\), and we write \\(X \\pconv k\\).\n\nNote that the \\(n\\) parameter typically denotes the size of the sample. This parameter can be used as a parameter for the distribution of \\(Y\\).\n\n\nExample 2 (Convergence of Probability) Suppose that \\(X \\sim \\ExponentialDist(1/n)\\).\nShow that \\(X \\pconv 0\\).\n\n\nProof. \\[\n\\P{\\abs{X - 0} &gt; \\varepsilon} = \\P{X &gt; \\varepsilon} = \\int_\\varepsilon^\\infty ne^{-nx}\\, dx = e^{-n\\varepsilon} \\to 0.\n\\]\nTherefore \\(X \\pconv 0\\).\n\n\n\nRemark 1. Note that the above makes sense, since \\(\\E{X} = \\frac{1}{n} \\to 0\\) and \\(\\Var{X} = \\frac{1}{n^2} \\to 0\\).",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Properties of Point Estimators"
    ]
  },
  {
    "objectID": "contents/chapter-09/1properties.html#consistency",
    "href": "contents/chapter-09/1properties.html#consistency",
    "title": "Properties of Point Estimators",
    "section": "3 Consistency",
    "text": "3 Consistency\n\nDefinition 2 Consider an estimator \\(A\\) of \\(\\theta\\) based on a sample of size \\(n\\), and suppose that \\(A \\pconv \\theta\\) as \\(n \\to \\infty\\).\nThen we say that \\(A\\) is a consistent estimator of \\(\\theta\\)\n\n\n\nExample 3 Consider a random sample of \\(n\\) numbers from between \\(0\\) and \\(c\\), and let \\(U = 2 \\mean{Y}\\) (twice the sample mean). Is \\(U\\) a consistent estimator of \\(c\\)?\n\n\nSolution. First, we will show that \\(U\\) is unbiased, \\[\\begin{gather*}\n\\mu = \\E{U} = 2\\E{\\mean{Y}} = 2(c/2) = c \\\\\n\\sigma^2 = \\Var{U} = 2^2 \\Var{\\mean{Y}} = 4 \\frac{\\Var{Y_1}}{n} = 4 \\frac{c^2/12}{n} = \\frac{c^2}{3n}.\n\\end{gather*}\\]\nTherefore, \\[\\begin{align*}\n\\P{\\abs{U - c} &gt; \\varepsilon} & = \\P{\\abs{U - \\mu} &gt; k\\sigma} \\tag{where $k = \\varepsilon / \\sigma$ and unbiased} \\\\\n& = \\P{\\abs{U - \\mu} \\geq k \\sigma} \\tag{since $U$ is a continuous rv} \\\\\n& \\leq \\frac{1}{k^2} \\tag{by Chebyshev's Theorem} \\\\\n& = \\frac{1}{(\\varepsilon / \\sigma)^2} = \\frac{\\sigma^2}{\\varepsilon^2} = \\frac{c^2}{3n\\varepsilon^2} \\to 0 \\; \\text{as} \\; n \\to \\infty\n\\end{align*}\\]\nThus \\(U \\pconv c\\). So yes, \\(U\\) is a consistent estimator of \\(c\\).\n\n\n\n3.1 Formalisation\nThe logic used in Example¬†3 can be generalised, as follows.\n\nTheorem 1 (Consistency) Suppose that \\(A\\) is an unbiased estimator of \\(\\theta\\) such that \\(\\Var{A} \\to 0 \\; \\text{as} \\; n \\to \\infty\\). Then \\(A\\) is also a consistent estimator of \\(\\theta\\).\n\n\nProof. The proof of this theorem is very similar to the working in Example¬†3, \\[\\begin{align*}\n\\P{\\abs{A - \\theta} &gt; \\varepsilon} & = \\P{\\abs{A - \\theta} &gt; k\\sigma} \\tag{where $k = \\varepsilon / \\sigma$ and $\\sigma^2 = \\Var{A}$} \\\\\n& \\leq \\P{\\abs{A - \\theta} \\geq k\\sigma} \\\\\n& \\leq \\frac{1}{k^2} \\tag{by Chebyshev's Theorem} \\\\\n& = \\frac{\\sigma^2}{\\varepsilon^2} \\\\\n& \\to 0 \\; \\text{as} \\; n \\to \\infty \\tag{$\\sigma^2 \\to 0$}\n\\end{align*}\\] So \\(A \\pconv \\theta\\), or in other words, \\(A\\) is a consistent estimator of \\(\\theta\\).\n\n\n\n\n3.2 The (Weak) Law of Large Numbers\nThe most important implication of the above theorem is the following result, which is called the law of large numbers (or more precisely, the weak law of large numbers).\n\nTheorem 2 (Weak Law of Large Numbers) Consider a random sample \\(Y_1, Y_2, \\ldots , Y_n\\) from a distribution with finite mean \\(\\mu\\) and finite variance \\(\\sigma^2\\). Then the sample mean \\(\\mean{Y}\\) is a consistent estimator of \\(\\mu\\).\n\n\n\n\nProof. \\(\\E{\\mean{Y}} = \\mu\\). Thus \\(\\mean{Y}\\) is an unbiased estimator of \\(\\mu\\). Also, \\(\\Var{\\mean{Y}} = \\sigma^2 / n \\to 0 \\; \\text{as} \\; n \\to \\infty\\). It follows by the above theorem that \\(\\mean{Y}\\) is a consistent estimator of \\(\\mu\\).\n\n\n\n\nExample 4 Consider a bent coin, and suppose that we are interested in \\(p\\), the probability of a head coming up on a signle toss. We toss the coin \\(n\\) times and observe \\(\\hat{p}\\), the proportion of heads. Is \\(\\hat{p}\\) is a consistent estimator of \\(p\\)?\n\n\n\n\nSolution. We may also write \\(\\hat{p}\\) as \\(\\mean{Y} = \\frac{1}{n}(Y_1 + Y_2 + \\cdots + Y_n)\\), where \\(Y_1, Y_2, \\ldots ,Y_n \\iidsim \\Bernoulli(p)\\).\n\n\\(\\mu = \\E{Y_i} = p\\)\n\\(\\sigma^2 = \\Var{Y_i} = p(1 - p) &lt; \\infty\\)\n\nSo by the law of large numbers, \\(\\hat{p}\\) is a consistent estimator of \\(p\\) because \\(\\hat{p}\\) is the sample mean of the population mean of \\(\\Bernoulli(p)\\) which is \\(p\\). That is, \\(\\hat{p} \\pconv p\\), or equivalently, \\(\\P{\\abs{\\hat{p} - p} &gt; \\varepsilon} \\to 0\\) as \\(n \\to \\infty\\).\n\n\n\n\n\nRemark 2 (Determining Whether it is Fair Coin). For example, if the coin is fair then \\(\\P{\\abs{\\hat{p} - p} &gt; 0.01} \\to 0\\). This is the same as saying \\(\\P{\\abs{\\hat{p} - 0.5} \\leq 0.01} \\to 1\\). That is, the probability that the proportion of heads will lie between \\(0.49\\) and \\(0.51\\) approaches \\(100\\%\\) as the number of tosses increases indefinitely.\n\n\n\n\n3.3 Some Property of Convergence\n\nTheorem 3 Suppose that \\(A \\pconv a\\) and \\(B \\pconv b\\) as \\(b \\to \\infty\\), where \\(a\\) and \\(b\\) are constants. Then:\n\n\\(A + B \\pconv a + b\\)\n\\(AB \\pconv ab\\)\n\\(A/B \\pconv a/b\\), provided that \\(b \\neq 0\\)\n\\(g(A) \\pconv g(a)\\), provided that \\(g\\) is a real-valued function that is continuous at \\(a\\).",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Properties of Point Estimators"
    ]
  },
  {
    "objectID": "contents/chapter-09/1properties.html#convergence-in-distribution",
    "href": "contents/chapter-09/1properties.html#convergence-in-distribution",
    "title": "Properties of Point Estimators",
    "section": "4 Convergence in Distribution",
    "text": "4 Convergence in Distribution\n\nDefinition 3 Suppose that \\(X = X_n\\) and \\(R\\) are random variables such that \\(F_X(k) \\to F_R(k)\\) as \\(n \\to \\infty\\) for all \\(k \\in \\mathbb{R}\\) at which \\(F_R(k)\\) is continuous. Then we say that \\(X\\) converges in distribution to \\(R\\), and write \\(X \\dconv R\\).\n\nFor example, \\(U = \\frac{\\mean{Y} - \\mu}{\\sigma / \\sqrt{n}} \\dconv Z \\sim \\NormalDist(0, 1)\\) (central limit theorem). Note that the above definition also applies if \\(R\\) has a degenerate distribution at some constant \\(c\\). In that case, \\[\\begin{equation*}\nF_R(k) = \\P{R \\leq k} = \\begin{cases}\n0, & k &lt; c \\\\\n1, & k \\geq c \\\\\n\\end{cases}\n\\end{equation*}\\] Thus, for a constant \\(c\\), \\(X \\dconv c\\) if \\[\\begin{equation*}\n\\P{X \\leq k} \\to \\begin{cases}\n0, & k &lt; c \\\\\n1, & k &gt; c \\\\\n\\end{cases}\n\\end{equation*}\\]\n\n4.1 Three More Theorems\n\nSuppose that \\(A \\dconv \\NormalDist(0, 1)\\) and \\(B \\pconv 1\\). Then \\(A/B \\dconv \\NormalDist(0, 1)\\).\nIf \\(A\\) and \\(B\\) are random variables such that \\(A \\pconv B\\) then \\(A \\dconv B\\).\nIf \\(A\\) is random variable and \\(c\\) is constant such that \\(A \\dconv c\\), then \\(A \\pconv c\\). (This is not generally true if \\(c\\) is a non-degenerate random variable.)\n\n\n\nExample 5 (Sample Variance Consistency with Population Variance) \\[\\begin{equation}\nS^2 \\pconv \\sigma^2 \\; \\text{as} \\; n \\to \\infty\n\\end{equation}\\]\n\n\n\n\nSolution. First, the way to prove this is to apply Theorem¬†1 as we already know that \\(S^2\\) is unbiased. Now, we only need to find the variance and shows that the variance converges to 0 as \\(n\\) go to infinity.\nNow, since \\(\\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2(n-1)\\), then \\[\\begin{align*}\n\\Var{S^2} & = \\frac{\\sigma^4}{(n-1)^2} \\Var{\\frac{(n-1)S^2}{\\sigma^2}} \\\\\n& = \\frac{\\sigma^4}{(n-1)^2} (2(n - 1)) \\\\\n& = \\frac{2\\sigma^4}{n-1}  \\to 0 \\; \\text{as} \\; n \\to \\infty\n\\end{align*}\\]\n\n\n\n\nExample 6 The central limit theorem still holds when we replace the population deviation \\(\\sigma\\) by the sample standard deviation \\(S\\); we used this fact in Chapter 8 to construct large sample confidence intervals for \\(\\mu\\) and \\(p\\)).\n\\[\\begin{equation}\n\\frac{\\mean{Y} - \\mu}{S / \\sqrt{n}} \\dconv \\NormalDist(0, 1)\n\\end{equation}\\]\n\n\n\n\n\nProof. From CLT, we know that \\(\\frac{\\mean{Y} - \\mu}{S / \\sqrt{n}} \\dconv \\NormalDist(0, 1)\\) as \\(n \\to \\infty\\)\nNow, as \\(S^2 \\pconv \\sigma^2\\) by Example¬†5 and \\(\\sigma^2 \\pconv \\sigma^2\\) Therefore, with the first line in Section¬†4.1, we know that \\(S^2 / \\sigma^2 \\pconv 1\\). Therefore, by using the fourth property in Theorem¬†3 and \\(g(x) = \\sqrt{x}\\). Then, we know that \\(S / \\sigma \\pconv 1\\). Hence, \\[\\begin{align*}\n\\frac{\\frac{\\mean{Y} - \\mu}{\\sigma / \\sqrt{n}}}{\\frac{S}{\\sigma}} & \\dconv \\NormalDist(0, 1) \\tag{as $n \\to \\infty$} \\\\\n& \\implies \\frac{\\mean{Y} - \\mu}{S / \\sqrt{n}} \\dconv \\NormalDist(0, 1) \\tag{as $n \\to \\infty$} \\\\\n\\end{align*}\\]",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Properties of Point Estimators"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html",
    "href": "contents/chapter-09/2methods-of-estimations.html",
    "title": "Methods of Estimations",
    "section": "",
    "text": "Now, it is not always obvious as to how the point estimator is derived‚Ä¶\nFor example, using twice the average of the sample to estimate the upper bound of a continuous uniform distribution seem to be out of thin air. And, multiple other estimators.\n\nTherefore, we will look at two general methods for deriving point estimators:\n\nthe method of moments (MOME)\nthe method of maximum likelihood (MLE)",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#learning-goals",
    "href": "contents/chapter-09/2methods-of-estimations.html#learning-goals",
    "title": "Methods of Estimations",
    "section": "",
    "text": "Now, it is not always obvious as to how the point estimator is derived‚Ä¶\nFor example, using twice the average of the sample to estimate the upper bound of a continuous uniform distribution seem to be out of thin air. And, multiple other estimators.\n\nTherefore, we will look at two general methods for deriving point estimators:\n\nthe method of moments (MOME)\nthe method of maximum likelihood (MLE)",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#method-of-moments",
    "href": "contents/chapter-09/2methods-of-estimations.html#method-of-moments",
    "title": "Methods of Estimations",
    "section": "2 Method of Moments",
    "text": "2 Method of Moments\nConsider a random sample \\(Y_1, Y_2, \\ldots , Y_n\\) from some distribution. Thus these random variables are \\(\\iid\\) Recall that \\(Y \\triangleq Y_1\\) has \\(k\\)th raw moment \\(\\mu_k' = \\E{Y^k}\\). We now also, analogous to sample mean, define the \\(k\\)th sample moment as \\(m_k' = \\frac{1}{n} \\sum_{i=1}^n y_i^k\\).\nSuppose that the distribution of \\(Y\\) involves \\(t\\) unknown parameters \\(t = 1, 2, 3, \\ldots\\). Then the method of moments (MOM) involves solving the following system of equations. \\[\\begin{equation}\n\\begin{aligned}\n\\mu_1' &= m_1' \\\\\n\\mu_2' &= m_2' \\\\\n\\vdots &= \\vdots \\\\\n\\mu_t' &= m_t' \\\\\n\\end{aligned}\n\\end{equation}\\]\nThe solution of these \\(t\\) equations leads to the method of moments estimates (MOME‚Äôs) of the \\(t\\) unknown parameters.\n\n2.1 Some Intuitions\n\nThis seems to be a relatively unintuitive thing to do. Or why do we want to match the moment? There are many other things we can match to as well‚Ä¶\n\nThe idea here is that the \\(k\\)th sample moment as a random variable, \\(M_k' = \\frac{1}{n}\\sum_{i=1}^n Y_i^k\\), has mean \\(\\mu_k'\\) and a variance that converges to zero as \\(n\\) to infinity: \\[\\begin{gather*}\n\\E{M_k'} = \\frac{1}{n} \\sum_{i=1}^n \\E{Y_i^k} = \\frac{1}{n} \\sum_{i=1}^n \\mu_k' = \\mu_k' \\\\\n\\Var{M_k'} = \\frac{1}{n^2} \\sum_{i = 1}^n \\Var{Y_i^k} = \\frac{n \\Var{Y_1^k}}{n^2} = \\frac{\\Var{Y_1^k}}{n} \\to 0 \\\\\n\\end{gather*}\\]\nThus, by Theorem 1, (or equivalently by law of large number), \\(M_k'\\) is a consistent estimator of \\(\\mu_k'\\). That is, for each \\(k\\) and any \\(\\varepsilon &gt; 0\\), \\(\\P{\\abs{M_k' - \\mu_k'\n} &gt; \\varepsilon} \\to 0\\) as \\(n \\to \\infty\\). So, if \\(n\\) is large, each \\(m_k'\\) shoud be close to \\(\\mu_k'\\).\nIn some cases the above definition of the MOM may require slight modification because the system of equations as indicated cannot be solved for the \\(t\\) unknown parameters, For example, if \\(\\mu_1' = 0\\), it may be necessary to also equate \\(\\mu_{t+1}' = m_{t+1}'\\).\n\n\n2.1.1 Example\n\nExample 1 Consider a random sample of numbers from between \\(0\\) and \\(c\\). Find the method of moments estimate of \\(c\\).\n\n\n\n\nSolution. Here: \\(t = 1\\), \\(\\mu_1' = \\E{Y} = c / 2, m_1' = \\mean{y}\\). We now equate \\(\\mu_1' = m_1'\\). This implies that \\(c/2 = \\mean{y}\\) and hence \\(c = 2 \\mean{y}\\). Thus the method of moments estimate of \\(c\\) is \\(\\hat{c}  = 2 \\mean{y}\\). In other words, the method of moments estimator of \\(c\\) is \\(\\hat{c} = 2\\mean{Y}\\). Note that this estimator is both unbiased and consistent.\n\n\n\n\n\n\n\n\nEstimate vs Estimator\n\n\n\n\n\nNote that the estimates is a constant while the estimator is a random variable.\n‚Ä¶ BUT, it is common for these two terms to be used interchangeable. Thus, when we say that an estimate is unbiased or consistent, it should be understood that we are saying this about the corresponding estimator.\n\n\n\n\n\nExample 2 Suppose that \\(Y_1, Y_2, \\ldots , Y_n \\iidsim \\GammaDist(a, b)\\). Find the method of moments estimates of \\(a\\) and \\(b\\).\n\n\n\n\nSolution. Here: \\(t = 2\\),\n\n\\(\\mu_1' = \\E{Y} = ab\\),\n\\(\\mu_2' = \\E{Y^2} = \\Var{Y} = (\\E{Y})^2 = ab^2 + (ab)^2\\)\n\nTherefore, equating with \\(\\mu_1' = m_1'\\) and \\(\\mu_2' = m_2'\\). This implies that \\(ab = \\mean{y}\\) and \\(ab^2 + a^2b^2 = m_2'\\). Solving these equations leads to the MOME‚Äôs: \\[\\begin{equation}\n\\hat{a} = \\frac{\\mean{y}^2}{m_2' - \\mean{y}^2} \\qquad , \\qquad \\hat{b} = \\frac{\\mean{y}}{\\hat{a}}\n\\end{equation}\\]\nFor example, suppose that the data values are \\(1.3\\) and \\(2.7\\). Then \\(\\mean{y} = 2\\) and \\(m_2' = 4.49\\). Therefore \\(\\hat{a} = 8.1633\\) and \\(\\hat{b} = 0.245\\).\n\n\n\n\nExample 3 \\(Y_2, Y_2, \\ldots , Y_n \\iidsim \\NormalDist(a, b^2)\\). Find the MOME‚Äôs of \\(a\\) and \\(b^2\\).\n\n\n\n\nSolution. \\(\\mu_1' = a\\), \\(\\mu_2' = \\E{Y^2} = a^2 + b^2\\), \\(m_1' = \\mean{y}\\), \\(m_2' = (1/n) \\sum_{i=1}^n y_i^2\\). Equating with \\(\\mu_t' = m_t'\\), we get \\[\\begin{equation}\n\\hat{a} = \\mean{y} \\qquad , \\qquad \\hat{b}^2 = \\frac{n-1}{n}S^2 = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\mean{y})^2\n\\end{equation}\\] i.e. \\[\\begin{align*}\na^2 + b^2 & = \\frac{1}{n} \\sum_{i=1}^n y_i^2 \\\\\nb^2 & = \\left(\\frac{1}{n} \\sum_{i = 1}^n y_i^2 \\right) - \\mean{y}^2 \\\\\n& = \\frac{1}{n} \\left( \\sum_{i=1}^n {y_i^2} - n\\mean{y}^2 \\right) = \\frac{(n-1)}{n} S^2 \\\\\n\\end{align*}\\]\nNote that therefore \\(\\hat{b}^2\\) is biased in small samples but it is consistent.",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#the-method-of-maximum-likelihood-single-observation",
    "href": "contents/chapter-09/2methods-of-estimations.html#the-method-of-maximum-likelihood-single-observation",
    "title": "Methods of Estimations",
    "section": "3 The Method of Maximum Likelihood (Single Observation‚Ä¶)",
    "text": "3 The Method of Maximum Likelihood (Single Observation‚Ä¶)\n\nExample 4 (Motivation) Suppose that we have a box with two balls in it, each of which is either black or white. But we have no idea how many of these two balls are black. We randomly draw a ball from the box and find tha it is black. Is the other ball also black?\n\n\n\nHere is the analysis:\nIf the other ball is black then the probability of us having drawn a black is \\(100\\%\\). If the other ball is white then the probability of us having drawn a black is only \\(50\\%\\). Because \\(100\\% &gt; 50\\%\\), it‚Äôs reasonable to conclude that the other ball is black, although we can‚Äôt be sure.\nWhat we have done is an example of estimation based on the principle that we should choose the value which maximises the likelihood of what has happened.\n\n\n3.1 Some Definitions\nSuppose that \\(Y\\) is an observation from some probability distribution that depends on an unknown parameter \\(\\theta\\).\nThe likelihood function is defined to be the pdf or pmf of \\(Y\\), \\(f(y)\\) or \\(p(y)\\), but considered as a function of \\(\\theta\\).\nWe denote the likelihood by \\(L(\\theta)\\) or \\(L(\\theta; y)\\).\nThe maximum likelihood estimate (MLE) of \\(\\theta\\) of \\(\\theta\\) is the value of \\(\\theta\\) which maximises the likelihood \\(L(\\theta)\\). Note: The MLE may not be unique.\n\n\n3.2 Example\n\nExample 5 We have a box with 2 balls in it, each of which is either black or white. We randomly draw a ball from the box and find that it is black. What is the MLE of the number of black balls originally in the box?\n\n\nSolution. Let \\(\\theta\\) be the number of black balls originally in the box. Also let \\(Y\\) be the numbr of black balls in our sample of one.\nThen \\(Y \\sim \\Bernoulli(\\theta / 2)\\), and \\[\np(y) = \\begin{cases}\n\\theta/2 , & y = 1 \\\\\n1 - \\theta / 2 , & y = 0 \\\\\n\\end{cases}\n\\] where \\(\\theta = 0, 1, 2\\).\nBut we actually observed \\(y = 1\\) blacks. Thus \\(p(y) = \\theta / 2\\). So the likelihood is \\[\nL(\\theta) = \\theta / 2 = \\begin{cases}\n0, & \\theta = 0 \\\\\n1/2, & \\theta = 1 \\\\\n1, & \\theta = 2 \\\\\n\\end{cases}\n\\]\nBut \\(\\max(0, 1/2 , 1) = 1\\). So the MLE of \\(\\theta\\) is \\(\\hat{\\theta} = 2\\). What if the chosen ball were white? They \\(y = 0\\) and so \\(p(y) = 1 - \\theta / 2\\). So \\[\nL(\\theta) = 1 - \\theta / 2 = \\begin{cases}\n1, & \\theta = 0 \\\\\n1/2, & \\theta = 1 \\\\\n0, & \\theta = 2 \\\\\n\\end{cases}\n\\]\nSo the MLE of \\(\\theta\\) is now \\(0\\).\nIn conclusion we may write the MLE generally as \\(\\hat{\\theta} = 2y\\), \\(y = 0, 1,\\). We may also write the MLE as a random variable: \\(\\hat{\\theta} = 2Y\\).\nNote that the method of moments leads to the same estimate as the method of maximum likelihood: equating \\(\\mu_1' = \\E{Y} = \\theta / 2\\) with \\(m_1' = y\\), we get \\(\\hat{\\theta} = 2y\\).\n\n\n\n\nExample 6 A bent coin is tossed 5 times and heads come up twice. Find the MLE of the probability of heads coming up on a single toss.\n\n\n\n\nSolution. Let \\(Y\\) be the number of heads that come up, and let \\(p\\) be the probability of interest.\nThen \\(Y \\sin \\Binomial(n, p)\\), where \\(n = 5\\), and \\(p(y) = \\binom{n}{y}p^y(1-p)^{n-y}\\), \\(y = 0, 1, \\ldots , n\\) (\\(0 &lt; p &lt; 1\\)).\nSo the likelihood is \\(L(p) = \\binom{n}{y}p^y(1-p)^{n-y}\\), \\(0 &lt; p &lt; 1\\) (\\(y = 0, 1, \\ldots , n\\)).\nWe now calculate \\[\nL'(p) = \\binom{n}{y} \\left( p^y (n - y)(1 - p)^{n-y-1}(-1) + yp^{y-1}(1 - p)^{n-y} \\right)\n\\] Setting this to zero yields \\(\\hat{p} = \\frac{y}{n} = \\frac{2}{5}\\).\n\n\nAlternatively, we can work on the log scale. This is benefitial because we typically work with assumptions of independent samples and this would typically results in a big product in the likelihood function. Applying a log transformation, such would then turn to a summation and would work much better with the differentiation.\n\nDefinition 1 ¬†\n\nThe **log likelihood function$ is \\[\nl(p) = \\log(L(p)) = \\log\\left(\\binom{n}{y}\\right) + y \\log(p) + (n - y) \\log(1 - p).\n\\]\nThen \\[\nl'(p) = 0 + \\frac{y}{p} - \\frac{n - y}{1 - p}\n\\]\nSetting \\(l'(p)\\) to zero yields the MLE, \\(\\hat{p} = \\frac{y}{n} = \\frac{2}{5}\\).\n\n\nRemark 1. Note that this is the same as th MOME. Also note that \\(l''(p) = -\\frac{y}{p^2} - \\frac{n-y}{(1 - p)^2} &lt; 0\\), which confirms that \\(\\hat{p} = y / n\\) maximises \\(L\\).",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#simplification",
    "href": "contents/chapter-09/2methods-of-estimations.html#simplification",
    "title": "Methods of Estimations",
    "section": "4 Simplification",
    "text": "4 Simplification\nObserve that the \\(\\binom{n}{y}\\) term could have been left out, with no change to the resutl.\nThus:\n\n\\(L(p) = p^y (1 - p)^{n - y}\\)\n\\(l(p) = y\\log(p) + (n - y) \\log(1 - p)\\)\n\\(l'(p) = \\frac{y}{p} - \\frac{n - y}{1 - p}\\)\n\netc.\n\nTherefore, we redefine the likelihood as any constant multiple of \\(Y\\)‚Äôs pdf or pmf.\n\nThis means that we can safely ignore multiplicative constants when writing down the likelihood function \\(L(\\theta)\\), and we can ignore any additive constants when writing down the loglikelihood function \\(l(\\theta)\\).",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#mle-for-several-observations",
    "href": "contents/chapter-09/2methods-of-estimations.html#mle-for-several-observations",
    "title": "Methods of Estimations",
    "section": "5 MLE for Several Observations",
    "text": "5 MLE for Several Observations\nThe method of ML can also be used when there are several sample ovservations, say \\(Y_1, Y_2, \\ldots, Y_n\\), whoose distribution depends on \\(\\theta\\).\n\nExample 7 (Example 8) Suppose that 1.2, 2.4, and 1.8 are a random sample from an exponential distribtuion with unknown mean. Find the MLE of that mean.\n\n\n\n\nSolution. The sample observations \\(Y_1, Y_2, \\ldots ,Y_n\\) have joint pdf\n\\[\\begin{align*}\nf(y_1, y_2, \\ldots ,y_n) & = \\prod_{i=1}^n f(y_i) \\tag{by independence} \\\\\n& = \\prod_{i=1}^n \\frac{1}{b} e^{-y_i / b} \\tag{where $b = \\E{Y_i}$ is the unknown mean} \\\\\n& = b^{-n} e^{-\\frac{1}{b}\\sum_{i=1}^n y_i} \\\\\n& = b^{-n} e^{-\\dot{y} / b} \\\\\n\\end{align*}\\] where \\(\\dot{y} = y_1 + y_2 + \\cdots + y_n\\).\nSo the likelihood is \\(L(b) = b^{-n} e^{-\\sum{y}/b}\\), \\(b &gt; 0\\). hence \\[\nl(b) = -n \\log(b) - \\dot{y} / b \\implies l'(b) = -\\frac{n}{b} + \\frac{\\dot{y}}{b^2}\n\\]\nSolving \\(l'(b) = 0\\) leads to the MLE of \\(b\\) as \\(\\hat{b} = \\frac{\\dot{y}}{n} = \\mean{y} = 1.8\\).\nFrom the weak law of large numbers as \\(Y_i \\iidsim \\ExponentialDist(b)\\) hence \\(\\E{Y_i} = b\\) and \\(\\Var{Y_i} = b^2\\) bounded, \\(\\hat{b}\\) is consistent for \\(b\\) (also \\(\\hat{b}\\) is unbaised in small samples, since \\(\\hat{b} = \\mean{Y}\\).)",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#the-case-of-several-parameters",
    "href": "contents/chapter-09/2methods-of-estimations.html#the-case-of-several-parameters",
    "title": "Methods of Estimations",
    "section": "6 The Case of Several Parameters",
    "text": "6 The Case of Several Parameters\nMaximum Likelihood estimation also works when there are two or more unknown parameters.\n\nExample 8 \\(Y_1, Y_2, \\ldots , Y_n \\iidsim \\NormalDist(a, b^2)\\). Find the MLE‚Äôs of \\(a\\) and \\(b^2\\).\n\n\n\n\\[\\begin{align*}\nf(y_1. y_2, \\ldots y_n) &= \\prod_{i=1}^n \\frac{1}{b \\sqrt{2 \\pi}} \\exp\\left\\{ -\\frac{1}{2b^2}(y_i - a)^2 \\right\\} \\\\\n& = b^{-n} (2 \\pi)^{-n/2} \\exp\\left\\{ -\\frac{1}{2b^2} \\sum_{i=1}^n (y_i - a)^2 \\right\\} \\\\\n\\end{align*}\\]\nSo \\(L(a, b^2) = (b^2)^{-n/2} \\exp\\left\\{-\\frac{1}{2b^2}\\sum_{i=1}^n (y_i - a)^2 \\right\\}\\), \\(-\\infty &lt; a &lt; \\infty\\), \\(b^2 &gt; 0\\). \\[\nl(a, b^2) = -\\frac{n}{2} \\log(b^2) - \\frac{1}{2b^2}\\sum_{i=1}^n (y_i - a)^2\n\\]\nTherefore, \\[\\begin{gather}\n\\pdv{l(a, b^2)}{a} = - \\frac{1}{2b^2} \\sum_{i=1}^n 2(y_i - a)^1 (-1) = \\frac{1}{b^2} \\sum_{i=1}^n (y_i - a) = \\frac{1}{b^2}(\\dot{y} - na). \\\\\n\\pdv{l(a, b^2)}{b^2} = - \\frac{n}{2b^2} + \\frac{1}{2b^4} \\sum_{i=1}^n (y_i - a)^2\n\\end{gather}\\]\nSetting (4) to 0 yields the MLE of \\(a\\), namely \\(\\hat{a} = \\dot{y} / n = \\mean{y}\\). Substituting \\(\\mean{y}\\) for \\(a\\) in (5) and then setting (5) to zero yields. \\[\n\\hat{b}^2 = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\mean{y})^2 = \\frac{n-1}{n} \\frac{1}{n-1} \\sum_{i=1}^n (y_i - \\mean{y})^2 = \\frac{n-1}{n} S^2\n\\]\nNote that these MLE‚Äôs are exactly the same as the MOME‚Äôs mentioned earlier.\n\n\n6.1 Example\n\nExample 9 A partly melted die is rolled repeatedly until the first 6 comes up. Then it is rolled again the same number of times. We are interested in \\(p\\), the probability of \\(6\\) coming up on a single roll. Suppose that the first \\(6\\) comes up on the third roll, and the numbers which then come up are 6, 2, 6. Find the MLE of \\(p\\).\n\n\n\n\nSolution. Let \\(X =\\) number of rolls until first \\(6\\), and \\(Y =\\) number of \\(6\\)‚Äôs on last half of rolls.\nThen \\(X \\sin \\Geometric(p)\\) (with \\(x = 3\\)) and \\((Y \\mid X = x) \\sim \\Binomial(x, p)\\) (with \\(y=2\\)).\nSo \\[p(x, y) = p(x) p(y \\mid x) = (1 - p)^{x-1} p \\cdot \\binom{x}{y} p^y(1 - p)^{x - y}\\]; \\(x = 1, 2, \\ldots ; y = 0, \\ldots , x\\).\nSo \\[L(p) = (1 - p)^{a}p^b\\] where \\(a = 2x - y - 1\\) and \\(b= 1 + y\\). Then: \\[\\begin{gather*}\nl(p) = a \\log(1 - p) + b \\log(p) \\\\\nl'(p) = - \\frac{a}{1 - p} + \\frac{b}{p} = 0 \\implies p = \\frac{b}{a + b} \\\\\n\\end{gather*}\\]\nSo the MLE of \\(p\\) is \\[\\begin{equation*}\n\\hat{p} = \\frac{b}{a + b} = \\frac{1 + y}{(2x - y - 1) + (y + 1)} = \\frac{1 + y}{2x} = \\frac{1 + 2}{2(3)} = \\frac{1}{2}\n\\end{equation*}\\] This makes sense, since \\(6\\) came up half the time: \\(1 + 2 = 3\\) times in \\(3 + 3 = 6\\) rolls.\n\n\n\nWe see that ML estimation works when the sample observations are not \\(\\iid\\). The same cannot be said for the MOM. We could not use the MOM directly here.\n\nExample 10 Suppose that 3.6 and 5.4 are two numbers chosen randomly and independently from between \\(0\\) and \\(c\\). Find the MLE of \\(c\\).\n\n\n\nLet \\(X\\) and \\(Y\\) denote the two numbers as random variables. Then \\(X, Y \\iidsim U(0, c)\\). Therefore \\[\np(x, y) = p(x)p(y) = \\frac{1}{c^2}, \\; 0 &lt; x &lt; c, 0 &lt; y &lt; c\n\\] \\(c &gt; 0\\).\nNow,\n\\[\\begin{gather*}\nL(c) = c^{-2}, \\; c &gt; 0 \\\\\nl(c) = \\log\\left\\{ L(c) \\right\\} = -2 \\log(c) \\\\\n\\end{gather*}\\] So \\(l'(c) = -2/c\\). So \\(l'(c) \\to 0 \\impliedby c \\to \\infty\\).\nBut this is wrong. First, it is intuitive that such \\(c \\to \\infty\\) if counter-intuitive1. Note that \\(c\\) needs to be larger than all the observed values. Therefore, obtain the correct domain for the log-likelihood function ‚Äì \\(c \\in (\\max(x, y), \\infty)\\). Also, given that \\(l'(\\cdot)\\) is a decreasing function, the maximum values occur at the minimal \\(c\\) values ‚Äì \\(c = \\max(x, y)\\). Note that this MLE should also be the same with several sample values.",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#the-invariance-property-of-mles",
    "href": "contents/chapter-09/2methods-of-estimations.html#the-invariance-property-of-mles",
    "title": "Methods of Estimations",
    "section": "7 The Invariance Property of MLEs",
    "text": "7 The Invariance Property of MLEs\n\nTheorem 1 If \\(\\hat{\\theta}\\) is an MLE of \\(\\theta\\) and \\(g\\) is a function, then an MLE of \\(\\phi = g(\\theta)\\) is \\(\\hat{\\phi} = g(\\hat{\\theta})\\).\n\n\nExample 11 Suppose that \\(Y \\sin \\Binomial(n, p)\\). What is the MLE of \\(r = p^2\\)? Is this MLE unbiased? If not, find an unbiased estimator of \\(r\\).\n\n\n\n\nSolution. Now, since we know that \\(\\hat{p} \\triangleq Y/n\\) is the MLE of \\(p\\), \\(\\hat{r} = \\hat{p}^2 = Y^2 / n^2\\) is the MLE of \\(r\\). Now \\[\\begin{align*}\n\\E{\\hat{r}} & = \\E{\\hat{p}^2} \\\\\n& = \\Var{\\hat{p}} + \\left( \\E{\\hat{p}} \\right)^2 \\\\\n& = \\frac{p(1 - p)}{n} + p^2 \\\\\n& = \\left( \\frac{n-1}{n} \\right)p^2 + \\frac{p}{n} \\\\\n& = \\left(\\frac{n-1}{n}\\right)r + \\frac{p}{n} \\neq r \\\\\n\\end{align*}\\]\nTherefore, we know that \\(\\hat{r}\\) is biased, in fact we realised, \\[\\begin{align*}\n\\bias{\\hat{r}} & = \\E{\\hat{r}} - r \\\\\n& = \\frac{p - r}{n} \\\\\n& = \\frac{p - p^2}{n} \\\\\n& = \\frac{p(1 - p)}{n} \\\\\n& = \\Var{\\hat{p}} \\\\\n\\end{align*}\\] Next observe that \\[\\begin{equation*}\n\\E{\\left( \\frac{n}{n-1} \\right)\\hat{r}} = r + \\frac{p}{n-1}\n\\end{equation*}\\] Now, \\[\\begin{equation*}\n\\E{\\frac{\\hat{p}}{n-1}} = \\frac{p}{n-1}\n\\end{equation*}\\] So an unbiased estimator of \\(r\\) is \\[\\begin{equation*}\n\\tilde{r} = \\left( \\frac{n}{n-1} \\right)\\hat{r} - \\frac{\\hat{p}}{n-1} = \\frac{n\\hat{p}^2 - \\hat{p}}{n - 1} = \\frac{\\hat{p}(n\\hat{p} - 1)}{n - 1} = \\frac{Y}{n} \\left( \\frac{Y - 1}{n - 1} \\right).\n\\end{equation*}\\]\n\n\n\n\n\nRemark 2 (Unbiased Estimator of \\(r\\)). Now, using the above \\(\\tilde{r}\\),\n\\[\\begin{align*}\n\\E{\\hat{r}} & = \\frac{n - 1}{n}r + \\frac{p}{n} \\\\\n\\frac{n}{n - 1}\\E{\\hat{r}} & = r + \\frac{p}{n - 1} \\\\\nr & = \\frac{n}{n - 1}\\E{\\hat{r}} - \\frac{p}{n - 1} \\\\\n\\end{align*}\\] Therefore, we can let, \\[\\begin{align*}\n\\tilde{r} & = \\frac{n}{n-1}\\hat{r} - \\frac{\\hat{p}}{n - 1} \\\\\n\\E{\\tilde{r}} & = \\frac{n}{n - 1}\\left( \\frac{n-1}{n}r + \\frac{p}{n} \\right) - \\frac{p}{n-1} \\\\\n& = r + \\frac{p}{n-1} - \\frac{p}{n - 1} \\\\\n& = r \\\\\n\\end{align*}\\]\nTherefore \\(\\tilde{r}\\) is unbiased.",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-09/2methods-of-estimations.html#footnotes",
    "href": "contents/chapter-09/2methods-of-estimations.html#footnotes",
    "title": "Methods of Estimations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAlso, not to mention that this would in fact only be a minimal point anyway.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation",
      "Methods of Estimations"
    ]
  },
  {
    "objectID": "contents/chapter-02/index.html",
    "href": "contents/chapter-02/index.html",
    "title": "Probability",
    "section": "",
    "text": "For a given experiement and associated sample space \\(S\\), a probability function \\(P\\) is a real-valued function whose domain is the power set of the sample space, \\(S\\), and satisfies the following:\n\n\\(P(A) \\geq 0\\) for all \\(A \\subset S\\) (probability can‚Äôt be negative)\n\\(P(S) = 1\\) (Something must happen)\nSuppose \\(A_1, A_2, \\ldots\\) is an infinite sequence of disjoint events. Then \\(P(A_1 \\cup A_2 \\cup \\ldots) = P(A_1) + P(A_2) + \\ldots\\)\n\nThese three conditions are known as the three axioms of probabiliyt. They do not completely specify \\(P\\), but merely ensure that \\(P\\) is ‚Äòsensible‚Äô. It remains for \\(P\\) to be precisely defined in any given situation. Typically, \\(P\\) is defined by assigning ‚Äòreasonable‚Äô probabilities to each of the same points (or simple events) in \\(S\\).\n\nIf the die is fair, then all of the possible outcomes 1, 2, 3, 4, 5, 6 are equally likely.\nSo it is reasonable to assign probability function \\(P\\) in case by \\[\nP(\\{1\\}) = P(\\{2\\}) = \\cdots = P(\\{6\\}) = 1 / 6\n\\]\nEquivalently, we may write \\(P(\\{k\\}) = 1/6\\), \\(k=1, \\ldots, 6\\) or \\(P(\\{k\\}) = 1/6 \\; \\forall k = S\\).\n\n\n\nTheorem 1 \\(P(\\emptyset) = 0\\)\n\n\nProof. Apply Axiom 3 with \\(A_i = \\emptyset\\) for all \\(i\\).\n\\(\\emptyset = \\emptyset \\cup \\emptyset \\cup \\ldots\\) Also \\(\\emptyset \\cap \\emptyset = \\emptyset\\) (i.e.¬†\\(\\emptyset\\) and \\(\\emptyset\\) are disjoint). It follows that \\(P(\\emptyset) = P(\\emptyset \\cup \\emptyset \\cup \\ldots) = P(\\emptyset) + P(\\emptyset) + \\cdots\\). We now subtract \\(P(\\emptyset)\\) from both sides. Hence \\(0 = P(\\emptyset) + P(\\emptyset) + \\cdots\\). Therefore, \\(P(\\emptyset) = 0\\).\n\n\n\nTheorem 2 Axiom 3 also holds for finite sequences. Thus if \\(A_1, A_2, \\ldots, A_n\\) are disjoint events, then\n\\[\nP(A_1 \\cup A_2 \\cup \\ldots \\cup A_n) = P(A_1) + P(A_2) + \\cdots + P(A_n)\n\\]\n\n\nProof. Apply Axiom 3 and Theorem¬†1, with \\(A_i = \\emptyset\\) for all \\(i = n + 1, n + 2, \\ldots\\).\n\n\n\nTheorem 3 \\[\nP(\\bar{A}) = 1 - P(A)\n\\]\n\n\nProof. \\[\\begin{align*}\n\n1 & = P(S) \\tag{by Axiom 2} \\\\\n  & = P(A \\cup \\bar{A}) \\tag{by the definition of complementation} \\\\\n  & = P(A) + P(\\bar{A}) \\tag{by Theorem 2 with $n = 2$, since $A$ and $\\bar{A}$ are disjoint.}\n\n\\end{align*}\\]",
    "crumbs": [
      "Home",
      "CH02 : Probability"
    ]
  },
  {
    "objectID": "contents/chapter-02/index.html#probability-functions",
    "href": "contents/chapter-02/index.html#probability-functions",
    "title": "Probability",
    "section": "",
    "text": "For a given experiement and associated sample space \\(S\\), a probability function \\(P\\) is a real-valued function whose domain is the power set of the sample space, \\(S\\), and satisfies the following:\n\n\\(P(A) \\geq 0\\) for all \\(A \\subset S\\) (probability can‚Äôt be negative)\n\\(P(S) = 1\\) (Something must happen)\nSuppose \\(A_1, A_2, \\ldots\\) is an infinite sequence of disjoint events. Then \\(P(A_1 \\cup A_2 \\cup \\ldots) = P(A_1) + P(A_2) + \\ldots\\)\n\nThese three conditions are known as the three axioms of probabiliyt. They do not completely specify \\(P\\), but merely ensure that \\(P\\) is ‚Äòsensible‚Äô. It remains for \\(P\\) to be precisely defined in any given situation. Typically, \\(P\\) is defined by assigning ‚Äòreasonable‚Äô probabilities to each of the same points (or simple events) in \\(S\\).\n\nIf the die is fair, then all of the possible outcomes 1, 2, 3, 4, 5, 6 are equally likely.\nSo it is reasonable to assign probability function \\(P\\) in case by \\[\nP(\\{1\\}) = P(\\{2\\}) = \\cdots = P(\\{6\\}) = 1 / 6\n\\]\nEquivalently, we may write \\(P(\\{k\\}) = 1/6\\), \\(k=1, \\ldots, 6\\) or \\(P(\\{k\\}) = 1/6 \\; \\forall k = S\\).\n\n\n\nTheorem 1 \\(P(\\emptyset) = 0\\)\n\n\nProof. Apply Axiom 3 with \\(A_i = \\emptyset\\) for all \\(i\\).\n\\(\\emptyset = \\emptyset \\cup \\emptyset \\cup \\ldots\\) Also \\(\\emptyset \\cap \\emptyset = \\emptyset\\) (i.e.¬†\\(\\emptyset\\) and \\(\\emptyset\\) are disjoint). It follows that \\(P(\\emptyset) = P(\\emptyset \\cup \\emptyset \\cup \\ldots) = P(\\emptyset) + P(\\emptyset) + \\cdots\\). We now subtract \\(P(\\emptyset)\\) from both sides. Hence \\(0 = P(\\emptyset) + P(\\emptyset) + \\cdots\\). Therefore, \\(P(\\emptyset) = 0\\).\n\n\n\nTheorem 2 Axiom 3 also holds for finite sequences. Thus if \\(A_1, A_2, \\ldots, A_n\\) are disjoint events, then\n\\[\nP(A_1 \\cup A_2 \\cup \\ldots \\cup A_n) = P(A_1) + P(A_2) + \\cdots + P(A_n)\n\\]\n\n\nProof. Apply Axiom 3 and Theorem¬†1, with \\(A_i = \\emptyset\\) for all \\(i = n + 1, n + 2, \\ldots\\).\n\n\n\nTheorem 3 \\[\nP(\\bar{A}) = 1 - P(A)\n\\]\n\n\nProof. \\[\\begin{align*}\n\n1 & = P(S) \\tag{by Axiom 2} \\\\\n  & = P(A \\cup \\bar{A}) \\tag{by the definition of complementation} \\\\\n  & = P(A) + P(\\bar{A}) \\tag{by Theorem 2 with $n = 2$, since $A$ and $\\bar{A}$ are disjoint.}\n\n\\end{align*}\\]",
    "crumbs": [
      "Home",
      "CH02 : Probability"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "",
    "text": "As mentioned in the body content of this chapter, we have come to realisation that sum of random variables can actually be captured using the convolution operation quite nicely. Here, let‚Äôs give take a deeper dive into it.\nThis article is based on this article on wayback machine, reimbursed for mordern website.",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#preamable-disclaimer",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#preamable-disclaimer",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "",
    "text": "As mentioned in the body content of this chapter, we have come to realisation that sum of random variables can actually be captured using the convolution operation quite nicely. Here, let‚Äôs give take a deeper dive into it.\nThis article is based on this article on wayback machine, reimbursed for mordern website.",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#convolution",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#convolution",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "2 Convolution",
    "text": "2 Convolution\nTypically, we define the convolution for continuous function as, \\[\n(f * g)(z) = \\int_{-\\infty}^\\infty f(z - y) g(y) dy = \\int_{-\\infty}^\\infty f(x) g(z - x) dx\n\\] And for discrete case as, \\[\n(f * g)(z) = \\sum_x p_X(x) p_Y(z - x)\n\\]",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#sum-of-two-random-variables",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#sum-of-two-random-variables",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "3 Sum of Two Random Variables",
    "text": "3 Sum of Two Random Variables\nNow, let‚Äôs start with the sum of two random variables as we have already discussed about in chapter 6. However, let‚Äôs change the setting a bit to the discrete uniform case.\n\n\n\n\n\n\nNote¬†1: Motivating Example\n\n\n\nLet \\(X, Y \\sim \\mathrm{Unif}(1, 4)\\) be independent rolls of a fair 4-sided die. What is the PMF of \\(Z = X+Y\\)?\n\nSolution:\nFor current setting, the range of \\(Z\\) is \\[\n\\Omega_Z = \\{2, 3, 4, 5, 6, 7, 8 \\}\n\\]\nNow, if I want to find the probability of certain \\(z\\) happens, we can simply sum over all the possible values for \\(X\\) in particular, and zero-weight the situations with unreachable \\(Y\\) values using the ‚Äúprobability‚Äù of that impossible event of \\(Y\\) (probability = 0). For example, if we want \\(P(Z = 3)\\), we can do, \\[\n\\begin{align}\nP(Z = 3) & = P(X = 1, Y = 2) + P(X = 2, Y = 1) + P(X = 3, Y = 0) + P(X = 4, Y = -1) \\\\\n& = P(X = 1)P( Y = 2) + P(X = 2)P(Y = 1) \\\\\n& \\qquad + P(X = 3)P(Y = 0) + P(X = 4)P(Y = -1) \\\\\n& = \\frac{2}{16}\n\\end{align}\n\\] where the first line is all ways to get a \\(3\\) going over the sample space of \\(X\\), and the second line uses independence. Note that it is not possible that \\(Y = 0\\) or \\(Y = -1\\), but we write this to remind ourselves that we are going over the whole sample space of \\(X\\). More generally, to find \\(p_Z(z) = P(Z = z)\\) for any value of \\(z\\), we can use the similar approach, \\[\n\\begin{align}\np_Z(z) & = P(Z = z) \\\\\n& = \\sum_{x \\in \\Omega_X} P(X = x, Y = z - x) \\\\\n& = \\sum_{x \\in \\Omega_X} P(X = x)P(Y = z - x) \\\\\n& = \\sum_{x \\in \\Omega_X} p_X(x)p_Y(z-x) \\\\\n\\end{align}\n\\]\nThe intuition is that if we want \\(Z = z\\), we sum over all possibilities of \\(X = x\\) but require that \\(Y = z - x\\) so that we get the desired sum of \\(z\\). It is very possible that \\(p_Y(z - x) = 0\\) as above.\n\n\nNow, it turns out that the intuition above is extremely general ‚Äì not only works for discrete, but also continuous.\n\nTheorem 1 (Convolution) Let \\(X, Y\\) be independent RVs, and \\(Z = X + Y\\).\n\nDiscrete version: If \\(X\\) and \\(Y\\) are discrete: \\[p_Z(z) = \\sum_{x \\in \\Omega_X} p_X(x)p_Y(z - x) = (p_X * p_Y)(z)\\]\nContinuous version: If \\(X\\) and \\(Y\\) are continuous: \\[f_Z(z) = \\int_{x\\in\\Omega_X} f_X(x) f_Y(z - x) \\, dx = (f_X * f_Y)(z)\\]\n\nNote: You can swap the roles of \\(X\\) and \\(Y\\). Note the similarity!\n\n\nProof. The proof of the discrete case is essential the same as Note¬†1. Therefore, we will focus on the continuous case here. Let‚Äôs start with the CDF and differentiate: \\[\\begin{align}\nF_Z(z) &= P(Z \\leq z) \\\\\n&= P(X + Y \\leq z) \\\\\n&= \\int_{x \\in \\Omega_X} P(X+Y \\leq z \\mid X = x)f_X(x)\\, dx \\tag{LTP} \\\\\n&= \\int_{x \\in \\Omega_X} P(Y \\leq z - x \\mid) \\, dx \\tag{Algebra} \\\\\n&= \\int_{x \\in \\Omega_X} P(Y \\leq z - x) f_X(x) \\, dx \\tag{$X$ and $Y$ are independent} \\\\\n& = \\int_{x \\in \\Omega_X} F_Y(z - x) f_X(x) \\, dx \\tag{def of CDF of $Y$} \\\\\n\\end{align}\\]\nNow we can take the derivative (with respect to \\(z\\)) of the CDF to get the density (\\(F_Y\\) becomes \\(f_Y\\)):\n\\[\nf_Z(z) = \\frac{d}{dz} F_Z(z) = \\int_{x \\in \\Omega_X} f_X(x)f_Y(z - x) \\, dx\n\\]\n\n\nNow, let‚Äôs work on some other examples.\n\n\nSuppose \\(X\\) and \\(Y\\) are two independent random variables such that \\(X \\sim \\mathrm{Poi}(\\lambda_1)\\) and \\(Y \\sim \\mathrm{Poi}(\\lambda_2)\\), and let \\(Z = X + Y\\). Prove that \\(Z \\sim \\mathrm{Poi}(\\lambda_1 + \\lambda_2)\\).\n\nNow, \\(\\Omega_X = \\Omega_Y = \\{ 0, 1, 2, \\ldots \\}\\) and so \\(\\Omega_Z = \\{ 0, 1, 2, \\ldots \\}\\) as well. For \\(n \\in \\Omega_Z\\): Note that the convolution formula says: \\[\\begin{equation}\np_Z(n) = \\sum_{k \\in \\Omega_X}p_X(k)p_Y(n-k) = \\sum_{k=0}^\\infty p_X(k)p_Y(n-k)\n\\end{equation}\\]\nHowever, if we simply plugin the PMGs, we will get the wrong answer because we need to sum things that are non-zero. This means that we require both \\(k\\) and \\(n-k\\) be in the common sample space. Therefore, we can sum up to at most \\(n\\). \\[\\begin{align*}\np_Z(n) & = \\sum_{k=0}^n p_X(k)p_Y(n-k) \\tag{Convolution Formula} \\\\\n& = \\sum_{k=0}^n e^{-\\lambda_1}\\frac{\\lambda_1^k}{k!} \\cdot e^{-\\lambda_2} \\frac{\\lambda_2^{n-k}}{(n-k)!} \\\\\n& = e^{-(\\lambda_1 + \\lambda_2)} \\sum_{k=0}^n \\frac{1}{k!(n-k)!}\\lambda_1^k(1- \\lambda_2)^{n-k} \\\\\n& = e^{-(\\lambda_1 + \\lambda_2)} \\frac{1}{n!} \\sum_{k=0}^n \\frac{n!}{k!(n-k)!}\\lambda_1^k(1- \\lambda_2)^{n-k} \\\\\n& = e^{-(\\lambda_1 + \\lambda_2)} \\frac{1}{n!} \\sum_{k=0}^n \\binom{n}{k} \\lambda_1^k(1- \\lambda_2)^{n-k} \\\\\n& = e^{-(\\lambda_1 + \\lambda_2)}\\frac{(\\lambda_1 + \\lambda_2)^n}{n!} \\\\\n\\end{align*}\\]\nThus, \\(Z \\sim \\mathrm{Poi}(\\lambda_1 + \\lambda_2)\\), as the PMF above matches that of a Poisson distribution. Note we wouldn‚Äôt have been able to do that last step if our sum as still \\(k = 0\\) to \\(\\infty\\).\n\n\nNow, although we have already used the CDF method in Chapter 6 to derive the results, we can try to see if this method is somewhat easier.\n\n\nExample 1 (Sum of Uniform Variables) Suppose \\(X, Y \\sim^{\\mathrm{iid}}U(0, 1)\\) and \\(Z = X + Y\\). Find \\(f_Z(z)\\).\n\nSolution\nWe always begin by calculating the range: we have \\(\\Omega_Z = [0, 2]\\). Again, we shouldn‚Äôt expect \\(Z\\) to be uniform, since we should expect a number around \\(1\\), but not \\(0\\), or \\(2\\).\nFor a \\(U \\sim U(0, 1)\\), we know \\(\\Omega_U = [0,1]\\) and that \\[\\begin{equation}\nf_U(u) = \\begin{cases}\n1 & 0 \\leq u \\leq 1 \\\\\n0 & \\text{otherwise} \\\\\n\\end{cases}\n\\end{equation}\\]\n\nIf \\(z \\in [0, 1]\\), we already have \\(z - x \\leq 1\\) since \\(z \\leq 1\\) (and \\(x \\in p0, 1]\\)). We also need \\(z - x \\geq 0\\) for the density to be nonzero: \\(x \\leq z\\). Hence our integral becomes: \\[\\begin{align*}\nf_Z(z) & = \\int_0^z f_Y(z - x)\\,dx + \\int_z^1 f_Y(z - x) \\, dx \\\\\n& = \\int_0^z 1 \\, dx + 0 = [x]_0^z = z \\\\\n\\end{align*}\\]\nIf \\(z \\in [1, 2]\\), we already have \\(z - x \\geq 0\\) since \\(z \\geq 1\\) (and \\(x \\in [0, 1]\\)). We now need the other condition \\(z - x \\leq 1\\) for the density to be nonzero: \\(x \\geq z - 1\\). Hence, our integral becomes: \\[\\begin{align*}\nf_Z(z) & = \\int_0^{z-1} f_Y(z-x) \\, dx + \\int_{z-1}^1 f_Y(z - x)\\, dx \\\\\n& = 0 + \\int_{z-1}^1 1 \\, dx = [x]_{z-1}^1 = 2 - z \\\\\n\\end{align*}\\]\n\nThus putting these two cases together gives: \\[\\begin{equation*}\nf_Z(z) = \\begin{cases}\nz & 0 \\leq z \\leq 1 \\\\\n2 - z & 1 \\leq z \\leq 2 \\\\\n0 & \\text{otherwise} \\\\\n\\end{cases}\n\\end{equation*}\\]\nThis result does confirm to our intuitions because there are ‚Äúmore ways‚Äù to get a value of 1 for example than any other point.",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#convolution-in-the-multivariate-setting",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#convolution-in-the-multivariate-setting",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "Convolution in the Multivariate Setting",
    "text": "Convolution in the Multivariate Setting\nWhen the sum involves vectors rather than scalars, the same convolution idea extends component-wise. Let \\[\\begin{equation*}\n\\mathbf X=(X_1,\\ldots,X_d), \\qquad \\mathbf Y=(Y_1,\\ldots,Y_d)\n\\end{equation*}\\] be independent \\(\\mathbb R^d\\)-valued random vectors with joint densities \\(f_{\\mathbf X}\\) and \\(f_{\\mathbf Y}\\). Define their sum \\[\\begin{equation*}\n\\mathbf Z=\\mathbf X+\\mathbf Y\\;:=\\;(X_1+Y_1,\\ldots,X_d+Y_d).\n\\end{equation*}\\] The density of \\(\\mathbf Z\\) is the \\(d\\)-dimensional convolution \\[\\begin{equation*}\nf_{\\mathbf Z}(\\mathbf z)\n=\\int_{\\mathbb R^{d}} f_{\\mathbf X}(\\mathbf t)\\,f_{\\mathbf Y}(\\mathbf z-\\mathbf t)\\,d\\mathbf t\n\\;=\\;(f_{\\mathbf X}*f_{\\mathbf Y})(\\mathbf z).\\tag{C.1}\\label{eq:C1}\n\\end{equation*}\\] For discrete vectors the integral is replaced by a \\(d\\)-fold sum.\n\n3.1 \\(n\\)-fold sums\nBecause convolution is associative, the density of \\(\\mathbf S_n=\\sum_{k=1}^{n}\\mathbf X_k\\) (independent, not necessarily identically distributed) is \\[\\begin{equation*}\nf_{\\mathbf S_n}=f_{\\mathbf X_1}f_{\\mathbf X_2}\\cdots*f_{\\mathbf X_n}.\\tag{C.2}\\label{eq:C2}\n\\end{equation*}\\] If all \\(\\mathbf X_k\\) share a common density \\(f\\) we simply write \\(f^{*n}\\) (the \\(n\\)-fold convolution power).\n\n\n3.2 Characteristic-function shortcut\nFor any vector \\(\\boldsymbol t\\in\\mathbb R^d\\) the characteristic function is \\[\\begin{equation*}\n\\varphi_{\\mathbf X}(\\boldsymbol t)=\\mathbb E\\bigl[e^{i\\langle\\boldsymbol t,\\mathbf X\\rangle}\\bigr]\n\\end{equation*}\\] Independence gives \\[\\begin{equation*}\n\\varphi_{\\mathbf S_n}(\\boldsymbol t)=\\prod_{k=1}^{n}\\varphi_{\\mathbf X_k}(\\boldsymbol t),\n\\end{equation*}\\] whose inverse Fourier transform reproduces \\(\\eqref{eq:C2}\\). This frequency-space view powers the multivariate Central Limit Theorem and stable-law theory.\n\n\n3.3 Example ‚ñ∏ Covariance additivity of Gaussians\nIf \\(\\mathbf X_k\\sim\\mathcal N_d(\\boldsymbol\\mu_k,\\Sigma_k)\\) are independent, then by \\(\\eqref{eq:C2}\\) \\[\\begin{equation*}\n\\mathbf S_n\\sim\\mathcal N_d\\Bigl(\\sum_{k=1}^{n}\\boldsymbol\\mu_k\\,,\\;\\sum_{k=1}^{n}\\Sigma_k\\Bigr).\n\\end{equation*}\\] The mean vectors and covariance matrices simply add.\n\n\n3.4 Further reading\n\nP. Billingsley, Probability & Measure, ¬ß17 ‚Äî product measures & convolution.\nG. Folland, Real Analysis, Ch. 8 ‚Äî Fourier transform on \\(\\mathbb R^d\\).\nGnedenko & Kolmogorov, Limit Distributions for Sums ‚Ä¶, Ch. 3 ‚Äî multivariate limits.\nHall, Philip. ‚ÄúThe Distribution of Means for Samples of Size N Drawn from a Population in Which the Variate Takes Values Between 0 and 1, All Such Values Being Equally Probable.‚Äù Biometrika, vol.¬†19, no. 3/4, 1927, pp.¬†240‚Äì45. JSTOR, https://doi.org/10.2307/2331961. Accessed 4 June 2025.\nBates, Grace E. ‚ÄúJoint Distributions of Time Intervals for the Occurrence of Successive Accidents in a Generalized Polya Scheme.‚Äù The Annals of Mathematical Statistics, vol.¬†26, no. 4, 1955, pp.¬†705‚Äì20. JSTOR, http://www.jstor.org/stable/2236383. Accessed 4 June 2025.",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About This Site",
    "section": "",
    "text": "This website serves as a comprehensive revision resource for students enrolled in STAT2001: Introductory Mathematical Statistics at the Australian National University. It aims to distill complex statistical concepts into digestible summaries and provide practical examples to enhance learning.\n\n\n\n\nTo offer clear and concise summaries of each topic covered in STAT2001.\nTo provide practical examples and exercises that reinforce theoretical concepts.\nTo serve as a supplementary resource alongside official course materials.\n\n\n\n\n\nThis site is created and maintained by a fellow student passionate about statistics and education. The goal is to foster a collaborative learning environment where students can access quality revision materials.\n\n\n\n\nYour feedback is invaluable. If you have suggestions, spot errors, or wish to contribute, please reach out via the contact form on the Contact page.\n\nDisclaimer: This site is independently developed and is not officially endorsed by the Australian National University."
  },
  {
    "objectID": "about.html#‚Ñπ-about-this-site",
    "href": "about.html#‚Ñπ-about-this-site",
    "title": "About This Site",
    "section": "",
    "text": "This website serves as a comprehensive revision resource for students enrolled in STAT2001: Introductory Mathematical Statistics at the Australian National University. It aims to distill complex statistical concepts into digestible summaries and provide practical examples to enhance learning.\n\n\n\n\nTo offer clear and concise summaries of each topic covered in STAT2001.\nTo provide practical examples and exercises that reinforce theoretical concepts.\nTo serve as a supplementary resource alongside official course materials.\n\n\n\n\n\nThis site is created and maintained by a fellow student passionate about statistics and education. The goal is to foster a collaborative learning environment where students can access quality revision materials.\n\n\n\n\nYour feedback is invaluable. If you have suggestions, spot errors, or wish to contribute, please reach out via the contact form on the Contact page.\n\nDisclaimer: This site is independently developed and is not officially endorsed by the Australian National University."
  },
  {
    "objectID": "contents/chapter-07/index.html",
    "href": "contents/chapter-07/index.html",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "",
    "text": "Theorem 1 Suppose that \\(Y_1, Y_2, \\ldots, Y_n \\sim^{\\text{iid}} N(\\mu, \\sigma^2)\\). Let \\[\\bar{Y} = \\frac{1}{n} \\sum_{i = 1}^n y_i \\hspace{20pt} \\text{(the sample mean)}\\]. Then \\[\\bar{Y} \\sim N(\\mu , \\frac{\\sigma^2}{n})\\]\n\n\nProof. In Chapter 6, we showed that linear combinations of normal rv‚Äôs are also normal. So it only remains to find the mean and variance of \\(\\bar{Y}\\).\n\\[\n\\begin{align}\nE[\\bar{Y}] & = E\\left[\\frac{1}{n} \\sum_{i = 1}^n Y_i\\right] \\\\\n& = \\frac{1}{n} \\sum_{i = 1}^n \\mu = \\frac{1}{n}n\\mu = \\mu\nVar(\\bar{Y}) &= \\frac{1}{n^2}\\sum_{i=1}^n Var(Y_i) \\\\\n&= \\frac{1}{n^2} \\sum_{i = 1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2}n\\sigma^2 = \\frac{\\sigma^2}{n} \\\\\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#some-theorems-regarding-the-normal-distribution",
    "href": "contents/chapter-07/index.html#some-theorems-regarding-the-normal-distribution",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "",
    "text": "Theorem 1 Suppose that \\(Y_1, Y_2, \\ldots, Y_n \\sim^{\\text{iid}} N(\\mu, \\sigma^2)\\). Let \\[\\bar{Y} = \\frac{1}{n} \\sum_{i = 1}^n y_i \\hspace{20pt} \\text{(the sample mean)}\\]. Then \\[\\bar{Y} \\sim N(\\mu , \\frac{\\sigma^2}{n})\\]\n\n\nProof. In Chapter 6, we showed that linear combinations of normal rv‚Äôs are also normal. So it only remains to find the mean and variance of \\(\\bar{Y}\\).\n\\[\n\\begin{align}\nE[\\bar{Y}] & = E\\left[\\frac{1}{n} \\sum_{i = 1}^n Y_i\\right] \\\\\n& = \\frac{1}{n} \\sum_{i = 1}^n \\mu = \\frac{1}{n}n\\mu = \\mu\nVar(\\bar{Y}) &= \\frac{1}{n^2}\\sum_{i=1}^n Var(Y_i) \\\\\n&= \\frac{1}{n^2} \\sum_{i = 1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2}n\\sigma^2 = \\frac{\\sigma^2}{n} \\\\\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#sampling-distribution",
    "href": "contents/chapter-07/index.html#sampling-distribution",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "2 Sampling Distribution",
    "text": "2 Sampling Distribution\n\nCorollary 1 (Standardised Sample Mean) \\[\nZ = \\frac{\\bar{Y} - \\mu}{\\sigma / \\sqrt{n}} \\sim N(0, 1)\n\\]\n\n\\(Z\\) may be called the standardised sample mean. The sample mean \\(\\bar{Y}\\) is an example of a statistic\n\nDefinition 1 (Statistic) A statistic is any function of the observable random variables in a sample and known constants.\n\nThe probability distribution of a statistic is sometimes referred to as the sampling distribution of that statistic. For example, \\(\\bar{Y} - \\mu\\) is nto a statistic unless \\(\\mu\\) is known. Similarly, \\(Z\\) in Corollary¬†1 is not a statistic unless both \\(\\mu\\) and \\(\\sigma\\) are known.\n\nExample 1 A bottling machine discharges volumes of drink that are independent and normally distributed with standard deviation 1 ml.\nFind the sampling distribution of the mean volume of 9 randomly selected bottles that are filled by the machine.\nHence find the probability that this sample mean will be within 0.3 ml of the mean volume of all bottles filled by the machine.\n\nLet \\(Y_i\\) be the volume of the \\(i\\) th bottle in the sample, \\(i = 1, \\ldots, n\\) where \\(n = 9\\). Then \\(Y_1, Y_2, \\ldots , Y_n \\sim^{\\text{iid}} N(\\mu, \\sigma^2)\\), where \\(\\sigma^2 = 1\\) and \\(\\mu\\) is unknown. So \\(\\bar{Y} \\sim N(\\mu, 1/9)\\). Hence\n\\[\n\\begin{align}\nP(\\lvert \\bar{Y} - \\mu \\rvert &lt; 0.3) & = P(\\left\\lvert \\frac{\\bar{Y} - \\mu}{\\sigma / \\sqrt{n}} \\right\\rvert &lt; \\frac{0.3}{1/3}) = P(\\lvert Z \\rvert &lt; 0.9) \\\\\n& = 1 - 2P(Z &gt; 0.9) = 0.6318\n\\end{align}\n\\]\nIt is important to note that we do not need any knowledge of \\(\\mu\\). In fact, this is an example of a pivotal statistics.\n\n\n\nTheorem 2 Suppose that \\(Y_1, Y_2, \\ldots , Y_n \\sim^{\\text{iid}} N(\\mu, \\sigma^2)\\). Let \\[\nS^2 = \\frac{1}{n-1}\\sum_{i = 1}^n (Y_i - \\bar{Y})^2\n\\] (The sample variance)\nThen:\n\n\\[ \\frac{(n - 1)S^2}{\\sigma^2} \\sim \\chi^2(n-1) \\]\n\\[ S^2 \\perp \\bar{Y} \\]\n\n\n\n\n\n\n\n\n\nProof for (a)\n\n\n\n\n\n\nProof (a.). Although the proof is not assessable, but let‚Äôs give some intuitions why it works here. Note that this proof take idea from Mike Spivey answer to this question posted on StackExchange. Also, for this proof, let‚Äôs assume b. is true.\nFrom Chapter 6, we know that the square of a normal distribution random variable will follow \\(\\chi^2\\) distribution while sum of \\(\\chi^2\\) distribution is still a \\(\\chi^2\\) distribution but with higher degree of freedom.\nWith this intuition in mind, the only confusing point is why it is of \\(n-1\\) degree-of-freedom rather than \\(n\\). Now, we can first suppose that we know the parameters being \\(\\mathcal{N}(\\mu, \\sigma^2)\\). Then, we can first consider \\(\\sum_{i=1}^n \\left(\\frac{Y_i - \\mu}{\\sigma}\\right)^2\\) \\[\n\\begin{align}\n\\sum_{i=1}^n \\left( \\frac{Y_i - \\mu}{\\sigma} \\right)^2 & = \\sum_{i=1}^n \\left( \\frac{(Y_i - \\bar{Y}) + (\\bar{Y} - \\mu)}{\\sigma} \\right)^2 \\\\\n& = \\sum_{i=1}^n \\left( \\frac{Y_i - \\bar{Y}}{\\sigma} \\right)^2 + \\sum_{i=1}^n \\left( \\frac{\\bar{Y} - \\mu}{\\sigma} \\right)^2 + \\sum_{i=1}^n \\frac{2(Y_i - \\bar{Y})(\\bar{Y} - \\mu)}{\\sigma^2} \\\\\n& = \\frac{n-1}{\\sigma^2} \\left( \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\bar{Y})^2 \\right) + n\\left( \\frac{\\bar{Y} - \\mu}{\\sigma} \\right)^2 + \\frac{2(\\bar{Y} - \\mu)}{\\sigma^2} \\sum_{i=1}^n (Y_i - \\bar{Y}) \\\\\n& = \\frac{n-1}{\\sigma^2}S^2 + n \\left( \\frac{\\bar{Y} - \\mu}{\\sigma} \\right)^2 + \\frac{2(\\bar{Y} - \\mu)(n\\bar{Y} - n\\bar{Y})}{\\sigma^2} \\\\\n& = \\frac{n-1}{\\sigma^2}S^2 + \\left( \\frac{\\bar{Y} - \\mu}{\\sigma / \\sqrt{n}} \\right)^2 \\\\\n\\end{align}\n\\]\nNow, since we assumed b. is true, so \\(\\frac{n-1}{\\sigma^2}S^2\\) and \\(\\left( \\frac{\\bar{Y} - \\mu}{\\sigma / \\sqrt{n}} \\right)^2\\) would be independent. Therefore, if we denote the above as \\(V = U + W\\) so \\(U\\) and \\(W\\) are indpendent, then \\[\nm_V(t) = m_U(t)m_W(t)\n\\]\nNow, then since the \\[\\frac{\\bar{Y} - \\mu}{\\sigma /\\sqrt{n}} \\sim \\mathcal{N}(0, 1) \\implies \\left( \\frac{\\bar{Y} - \\mu}{\\sigma / \\sqrt{n}} \\right)^2 \\sim \\chi^2(1) \\implies W \\sim \\chi^2(1)\\]. Also, since \\[\n\\begin{align}\nY_i \\sim^{\\text{iid}} \\mathcal{N}(\\mu, \\sigma^2) & \\implies \\left( \\frac{Y_i - \\mu}{\\sigma} \\right) \\sim^{\\text{iid}} \\mathcal{N}(0, 1) \\\\\n& \\implies \\left(\\frac{Y_i - \\mu}{\\sigma} \\right)^2 \\sim^{\\text{iid}} \\chi^2(1) \\\\\n& \\implies \\sum_{i=1}^n \\left(\\frac{Y_i - \\mu}{\\sigma} \\right)^2 \\sim \\chi^2(n) \\\\\n& \\implies V \\sim \\chi^2(n) \\\\\n\\end{align}\n\\] Hence, arriving at the mgf of \\(U\\) being, \\[\n\\begin{align}\nm_U(t) & = \\frac{m_V(t)}{m_W(t)} \\\\\n& = \\frac{(1 - 2t)^{-n/2}}{(1 - 2t)^{-1/2}} \\\\\n& = (1 - 2t)^{(-n / 2) + (1/2)} \\\\\n& = (1 - 2t)^{-(n - 1) / 2} \\\\\n\\end{align}\n\\] Hence, we see that this moment generating function is the same as \\(\\chi^2(n - 1)\\). Hence, we know that \\(U \\sim \\chi^2(n-1)\\).\n\n\n\n\n\nIn order to prove (b), we need to first prove the following,\n\nLemma 1 (Independence of Centered Random Variables) Suppose \\(Y_1, Y_2, \\ldots , Y_n\\) is a random sample iid from a normal distribution with mean, \\(\\mu\\) and variance, \\(\\sigma^2\\). It follows that the sample mean \\(\\bar{Y}\\), is independent of \\(Y_i - \\overline{Y}\\), \\(i = 1, 2, \\ldots, n\\).\n\n\n\n\n\n\n\nA Relatively Hard Proof for Lemma¬†11\n\n\n\n\n\nLet‚Äôs first give some intuitions how to even start‚Ä¶\n\nThe idea of the following proof is essentially but using the fact that if the pdf of joint distribution of \\(X_1, \\ldots, X_N\\) can be written as, \\[f(x_1, x_2, \\ldots, x_n) \\propto g(x_1) h(x_2, \\ldots x_n)\\], then we can say that \\(X_1\\) is independent of \\(\\{ X_2, X_3, \\ldots ,X_n\\}\\). Clearly, in this case \\(X_1\\) would be the sample mean, but how do we choose the others?\n\n\nProof (Lemma¬†1). The joint distribution of \\(Y_1, Y_2, \\ldots, Y_n\\) is \\[f_Y(y_1, y_2, \\ldots, y_n) = \\frac{1}{(2\\pi)^{\\frac{n}{2}}\\sigma^n} exp \\left\\{ -\\frac{1}{2} \\sum_{i = 1}^n \\left( \\frac{y_i - \\mu}{\\sigma} \\right)^2 \\right\\}\\] Transform the random variables, \\(Y_i, i = 1,2, \\ldots , n\\) to \\[\n\\begin{align*}\nX_1 &= \\overline{Y}                 & \\quad \\overline{Y} &= X_1 \\\\\nX_2 &= Y_2 - \\overline{Y}           & \\quad Y_2 &= X_2 + X_1 \\\\\nX_3 &= Y_3 - \\overline{Y}           & \\quad Y_3 &= X_3 + X_1 \\\\\n\\vdots &\\;= \\vdots             & \\quad \\vdots &= \\vdots \\\\\nX_n &= Y_n - \\overline{Y}           & \\quad Y_n &= X_n + X_1\n\\end{align*}\n\\]\nThen, the pdf is found through using the Jacobian of the transformation. In this context, the Jacobian (mapping from \\(X\\) to \\(Y\\) as we want to find the joint distribution of \\(X\\) and segregated it as suggested above) is, \\[\n[J_{ij}] = \\left[\\frac{\\partial (Y_1, Y_2, \\ldots Y_n)}{\\partial (X_1, X_2, \\ldots, X_n)}\\right] = \\begin{bmatrix}\n\\frac{\\partial Y_1}{\\partial X_1} & \\frac{\\partial Y_1}{\\partial X_2} & \\cdots & \\frac{\\partial Y_1}{\\partial X_n} \\\\\n\\frac{\\partial Y_2}{\\partial X_1} & \\frac{\\partial Y_2}{\\partial X_2} & \\cdots & \\frac{\\partial Y_2}{\\partial X_n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\frac{\\partial Y_n}{\\partial X_1} & \\frac{\\partial Y_n}{\\partial X_2} & \\cdots & \\frac{\\partial Y_n}{\\partial X_n} \\\\\n\\end{bmatrix} = \\begin{bmatrix}\n1 & -1  & -1 & \\cdots & 1 \\\\\n1 & 1  & 0 & \\cdots & 0 \\\\\n1 & 0  & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & 0  & 0 & \\cdots & 0 \\\\\n\\end{bmatrix}\n\\]\nNow, it only remains to find the determinant of \\(J\\). First, use row operations to achieve the following form, \\[\nJ \\sim \\begin{bmatrix}\n1 & -1 & -1 & \\cdots & -1 \\\\\n0 & 2 & 1 & \\cdots & 1 \\\\\n0 & 1 & 2 & \\cdots & 1 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 1 & 1 & \\cdots & 2 \\\\\n\\end{bmatrix}\n\\]\nTherefore, we only need find the determinant of the bottom right \\((n-1) \\times (n-1)\\) sub-matrix, \\[\n\\lvert B\\rvert \\triangleq\n\\left\\lvert\n\\begin{bmatrix}\n2 & 1 & \\cdots & 1 \\\\\n1 & 2 & \\cdots & 1 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n1 & 1 & \\cdots & 2 \\\\\n\\end{bmatrix}\n\\right\\rvert\n\\]\nNow, the easiest way is to realise the following, \\[\nB = 2I_{n-1} + (\\mathbf{1}\\mathbf{1}^\\top - I_{n-q}) = I_{n-1} + \\mathbf{1}\\mathbf{1}^\\top\n\\] as a special case of the householder matrix.\nThen, we realise the following eigendecompositions,\n\n\\(\\mathbf{1} = \\begin{bmatrix} 1 & 1 & \\cdots & 1 \\end{bmatrix}^\\top\\) is an eigen-vector of \\(\\mathbf{1}\\mathbf{1}^\\top\\) with eigen-value \\(n-1\\).\nOther orthogonal vectors to \\(\\mathbf{1}\\) would also be eigenvectors, but with eigenvalues of 0. We generally have \\(n - 1\\) linearly independent such vectors. One example set is by considering using \\(\\{ \\mathbf{e}_j - \\mathbf{e}_1 \\}\\).\n\nTherefore, \\(B\\) has eigenvalues, \\[\n\\lambda_1 = 1 + (n - 1) = n, \\qquad \\lambda_2 = \\cdots = \\lambda_{n-1} = 1\n\\]\nHence, \\[\n\\det B = n \\cdot 1^{n-2} = n\n\\]\nTherefore, \\(\\lvert J \\rvert = n\\). Now, with a bit of detour, we know the pdf of joint distribution of \\(Y_1, Y_2, \\ldots , Y_n\\) is \\[\n\\begin{align}\nf_{X_1, X_2, \\ldots , X_n}(x_1, x_2, \\ldots , x_n) &= f_Y(y_1, y_2, \\ldots, y_n) \\lvert J \\rvert \\\\\n& = n f_X(y_1, x_1 + x_2, \\ldots, x_1 + x_n) \\\\\n& = \\text{constants} \\cdot \\exp \\left\\{ -\\frac{1}{2} \\sum_{i=1}^n \\left( \\frac{y_i - \\mu}{\\sigma} \\right)^2 \\right\\}\n\\end{align}\n\\] Now, something similar comes up again as above‚Ä¶ \\[\n\\begin{align}\n\\sum_{i=1}^n \\left( \\frac{y_i - \\mu}{\\sigma} \\right)^2 & = \\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2 \\\\\n& = \\frac{1}{\\sigma^2} \\left[ (y_1 - \\overline{y})^2 + \\sum_{i=2}^n (y_i - \\overline{y})^2 + n(\\overline{y} - \\mu)^2 \\right]\n\\end{align}\n\\] Note that since \\(\\sum_{i = 1}^n(y_i - \\overline{y})\\), it follows that \\[\ny_1 - \\overline{y} = - \\sum_{i=2}^n (y_i - \\overline{y})\n\\]\nTherefore, the above simpliifies to\n\\[\n\\begin{align}\n\\sum_{i=1}^n \\left( \\frac{y_i - \\mu}{\\sigma} \\right)^2 & = \\frac{1}{\\sigma^2} \\left[ \\left( \\sum_{i=1}^n (y_i - \\overline{y}) \\right) ^2 + \\sum_{i = 2}^n (y_i - \\overline{y})^2 + n(\\overline{y} - \\mu)^2 \\right] \\\\\n& = \\frac{1}{\\sigma^2} \\left[ \\left( \\sum_{i = 2}^n x_i \\right)^2 + \\sum_{i=2}^n x_i^2 + n(x_1 - \\mu)^2 \\right] \\\\\n\\end{align}\n\\]\nTherefore, the pdf of \\(X_1, X_2, \\ldots, X_n\\), simplifies to \\[\n\\begin{align}\nf_{X_1, X_2, \\ldots, X_n}(x_1, x_2, \\ldots , x_n) & = \\text{constants} \\cdot \\exp \\left\\{ -\\frac{1}{2\\sigma^2} \\left[ \\left( \\sum_{i=2}^n x_i \\right)^2 + \\sum_{i=2}^n x_i^2 + n(x_1 - \\mu)^2 \\right] \\right\\} \\\\\n& \\propto \\exp \\left\\{ \\frac{1}{2\\sigma^2} \\left[ \\left( \\sum_{i=1}^n x_i \\right)^2 + \\sum_{i=2}^n x_i^2 \\right] \\right\\} \\exp \\left\\{ -\\frac{n}{2\\sigma^2} (x_1 - \\mu)^2 \\right\\} \\\\\n& \\propto h(x_2, x_3, \\ldots , x_n) \\cdot g(x_1) \\\\\n\\end{align}\n\\]\nNow, this follows with \\(X_1\\) being independent of \\(X_2, \\ldots, X_n\\) as their joint probability distribution can be factored into a product of functions that depend only their repsectie set of statistics. Therefore, \\(X_1 = \\overline{Y}\\) is independent of \\(X_i = Y_i - \\overline{Y}\\), \\(i = 2, 3, \\ldots, n\\).\nFinally, since \\(Y_1 - \\overline{Y} = -\\sum_{i=2}^n (Y_i - \\overline{Y})^2\\), it follows that \\(Y_1 - \\overline{Y}\\) is a function of random variables that are independent of \\(X_1 = \\overline{Y}\\), and so indpendent to \\(X_1\\).\n\n\n\n\n\nProof (b.). Now, all the hardwork is actually done in the proof of Lemma¬†1. The remaining parts requires to prove b. is essentially recognising that \\(S^2\\) is a function \\(Y_i - \\overline{Y}\\) for \\(i = 1, 2, \\ldots , n\\). Therefore, \\(\\overline{X}\\) and \\(S^2\\) is independent.\n\n\nExample 2 Similar setting as Example¬†1. Find an interval which we can be 90% sure will contain the sample variance of the 9 sampled volumes.\n\nWe will solve \\(P(a &lt; S^2 &lt; b) = 0.9\\) for \\(a\\) and \\(b\\).\n\\[\n0.9 = P\\left(\\frac{(9-1)a}{1} &lt; \\frac{(n-1)S^2}{\\sigma^2} &lt; \\frac{(9-1)b}{1}\\right) = P(8a &lt; U &lt; 8b)\n\\] where \\(U \\sim \\chi^2(8)\\).\nThen, using the \\(\\chi^2\\) table, we obtain, \\[\n0.9 = P(2.73264 &lt; U &lt; 15.5073)\n\\] Therefore, we know that \\(a = 0.34158\\) and \\(b = 1.9384125\\). Hence, the required interval is \\((0.34158, 1.93841)\\).\n\n\nRemark 1 (Is the above really the only solution?). Well, not really, it is relatively easy to find another interval. For example, we can find the interval starting from \\(0\\). In fact, a related problem is: ‚ÄúFind the shortest interval which we can be 90% sure will contain the sample variance of the 9 sampled volumes.‚Äù\nThe solution to this problem is unique and required interval \\((a, b)\\) satisfies two equations: \\(P(a &lt; S^2 &lt; b) = 0.9\\) and \\(f_{S^2}(a) = f_{S^2}(b)\\). This solution will have to be found numerically, e.g.¬†trial and error or the Newton Raphson algorithm. This seemingly difficult problem is caused by the asymmetric of the probability density function.\n\n\n2.1 The \\(T\\) Distribution\n\nDefinition 2 (\\(t\\) Distribution) Suppose that \\(Z \\sim \\mathcal{N}(0, 1)\\), \\(Y \\sim \\chi^2(k)\\) and \\(Z \\perp U\\). We say that the random variable \\[\nY = \\frac{Z}{\\sqrt{U/k}}\n\\] where \\(k\\) being the only parameters has the \\(t\\)-distribution with \\(k\\) degrees of freedom. The pdf of \\(Y\\) is \\[\nf(y) = \\frac{\\Gamma(\\frac{k+1}{2})}{\\sqrt{k\\pi}\\Gamma(k/2)}(1 + \\frac{y^2}{k})^{-\\frac{1}{2}(k+1)} \\hspace{10pt} , \\hspace{10pt} \\infty &lt; y \\infty\n\\]\nWe write \\(Y \\sim t(k)\\) or \\(Y \\sim t_k\\)\n\n\nTheorem 3 (Pdf of \\(t\\) Distribution) \\[\nf(y) = \\frac{\\Gamma(\\frac{k+1}{2})}{\\sqrt{k\\pi}\\Gamma(k/2)}\\left(1 + \\frac{y^2}{k}\\right)^{-\\frac{1}{2}(k+1)} \\hspace{10pt} , \\hspace{10pt} \\infty &lt; y \\infty\n\\]\n\nThe \\(t\\) pdf looks like a standard normal pdf but with ‚Äòfatter‚Äô tails. The \\(t\\) distribution converges to the standard normal distribution as \\(k\\) tends to infinity.\n\nTheorem 4 (Convergence of the \\(t\\) Distribution) \\(t\\) distribution converges to standard normal distributions as degree of freedom tends to infinity.\n\n\nProof (Convergence to Standard Normal). The pdf of \\(Y\\) can be written \\(f(y) = c_k A_k(y) B_k(y)\\), where \\(c_k\\) is a constant (which does not depend on y), \\[\nA_k(y) = \\left[ \\left(1 + \\frac{y^2}{k} \\right)^k \\right]^{-\\frac{1}{2}} \\qquad B_k(y) = \\left( 1 + \\frac{y^2}{k} \\right) ^{-1/2}\n\\] Now, as \\(k \\to \\infty\\), \\(B_k(y) \\to 1\\) and \\(A_k(y) \\to \\left[ e^{y^2} \\right]^{-1/2} = e^{-\\frac{1}{2} y^2}\\). Therefore, as \\(k \\to \\infty\\), the pdf of \\(Y \\sim t(k)\\) converges porportionally to \\(e^{-\\frac{1}{2}y^2}\\), which is the kernel of the \\(\\mathcal{N}(0, 1)\\).\nIn fact it is also possible to show that \\(c_k \\to 1 / \\sqrt{2\\pi}\\). However, I think since we know that the results will be a probability density function, the only plausible \\(c_k\\) really can only be \\(1 / \\sqrt{2\\pi}\\).\n\n\nTheorem 5 (Standardise with Sample Statistic) Suppose that \\(Y_1, Y_2. \\ldots , Y_n \\sim^{\\text{iid}} \\mathcal{N}(\\mu, \\sigma^2)\\). Let \\[\nT = \\frac{\\overline{Y} - \\mu}{S / \\sqrt{n}}\n\\] Then, \\(T \\sim t(n-1)\\).\n\n\nProof. Observe the following facts:\n\nThe standardised random variable with known variance by Corollary¬†1 is, \\[Z = \\frac{\\overline{Y} - \\mu}{\\sigma / \\sqrt{n}}\\]\nThe sampling distribution of the sample variance by Theorem¬†2 is \\[U = \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2(n-1)\\]\n\\(Z \\perp U\\) by Theorem¬†2\n\nIt follows by definition of the \\(t\\) distribution that \\[\nY = \\frac{Z}{\\sqrt{U/(n-1)}} \\sim t(n - 1)\n\\] But \\[\nT = \\frac{\\overline{Y} - \\mu}{S / \\sqrt{n}} = \\frac{\\frac{\\overline{Y} - \\mu}{\\sigma / \\sqrt{n}}}{\\sqrt{\\frac{(n - 1)S^2}{\\sigma^2} / (n - 1)}}  = Y \\sim t(n-1)\n\\]\n\n\n\nExample 3 (T-statistic in action) Setting as Example¬†1. Find the probability that the mean of the \\(9\\) sample volumes will be distant from the population mean by no more than half the sample standard deviation of those \\(9\\) volumes.\n\\[\n\\begin{align}\nP\\left(\\left\\lvert \\overline{Y} - \\mu \\right\\rvert &lt; \\frac{1}{2} S\\right) & = P\\left(-\\frac{1}{2} S &lt; \\overline{Y} - \\mu &lt; \\frac{1}{2} S \\right) \\\\\n& = P\\left(-\\frac{1}{2} &lt; \\frac{\\overline{Y} - \\mu}{S} &lt; \\frac{1}{2} \\right) \\\\\n& = P\\left(-\\frac{3}{2} &lt; \\frac{\\overline{Y} - \\mu}{S / \\sqrt{n}} &lt; \\frac{3}{2} \\right) \\\\\n& = P\\left( -\\frac{3}{2} &lt; T &lt; \\frac{3}{2} \\right) \\\\\n& = 1 - P(T &lt; -1.5)\n\\end{align}\n\\]\nNow, by tables, \\(P(T &lt; -1.397) = 0.1\\) and \\(P(T &lt; -1.860) = 0.05\\). Therefore, \\(P(T &lt; -1.5)\\) is between \\(0.05\\) and \\(0.10\\). So \\(1 - 2P(T &lt; -1.5)\\) is between \\(0.8\\) and \\(0.9\\).\n\n\n\n2.2 The \\(F\\) Distribution\n\nDefinition 3 Suppose that \\(U \\sim \\chi^2(a)\\), \\(V \\sim \\chi^2(b)\\) and \\(U \\perp V\\). We say that the random variable \\(Y = \\frac{U / a}{V / b}\\) ahs the \\(F\\)-distribution with \\(a\\) numerator and \\(b\\) denominator degrees of freedom.\nWe write \\(Y \\sim F(a, b)\\) or \\(Y \\sim F_{a, b}\\).\n\n\nTheorem 6 The pdf of an \\(F\\) distribution is \\[\nf(y) = \\frac{\\Gamma(\\frac{a+b}{2})}{\\Gamma(a/2)\\Gamma(b/2)} a^{\\frac{a}{2}}b^{\\frac{b}{2}} y^{\\frac{a}{2} - 1} (b + ay) ^{-\\frac{1}{2}(a + b)} \\; , \\hspace{20pt} y &gt; 0\n\\]\n\n\n\nTheorem 7 \\[\nY \\sim F(a, b) \\implies 1/Y \\sim F(b, a)\n\\]\n\n\nProof. Easily proved.\n\n\n\nTheorem 8 (Sampling Distribution of Ratio of Sample Variance) Suppose that: \\[\n\\begin{align}\nX_1, X_2, \\ldots, X_n &\\sim^{\\text{iid}} \\mathcal{N}(\\mu_X, \\sigma_X^2) \\\\\nY_1, Y_2, \\ldots, Y_n &\\sim^{\\text{iid}} \\mathcal{N}(\\mu_Y, \\sigma_Y^2) \\\\\n(X_1, X_2, \\ldots, X_n) &\\perp (Y_1, Y_2, \\ldots , Y_m) \\\\\n\\end{align}\n\\]\nThen \\[\nW = \\frac{S_X^2 / \\sigma_X^2}{S_Y^2 / \\sigma_{Y}^2} \\sim F(n-1, ,m-1)\n\\] where \\[\n\\begin{align}\n\\overline{X} & = \\frac{1}{n}\\sum_{i=1}^n X_i \\\\\n\\overline{Y} & = \\frac{1}{m}\\sum_{i=1}^m Y_i \\\\\nS_X^2 & = \\frac{1}{n-1}\\sum_{i=1}^n(X_i - \\overline{X})^2 \\\\\nS_Y^2 & = \\frac{1}{m-1}\\sum_{i=1}^m(Y_i - \\overline{Y})^2 \\\\\n\\end{align}\n\\]\n\n\nProof. By Theorem¬†2, \\[\n\\begin{align}\n\\frac{(n-1)S_X^2}{\\sigma_X^2} & \\sim \\chi^2(n-1) \\\\\n\\frac{(m-1)S_Y^2}{\\sigma_Y^2} & \\sim \\chi^2(m-1) \\\\\n\\end{align}\n\\]\nBoth are indepndent of each other because the two samples are independent. Hence, by definition, \\[\nW = \\frac{\\frac{(n-1)S_X^2}{\\sigma_X^2}}{\\frac{(m-1)S_Y^2}{\\sigma_Y^2}} \\sim F(n-1, m-1)\n\\]\n\n\n\nExample 4 Same setting as Example¬†1. Suppose that another sample of \\(5\\) bottles is to be taken from the outpu of the same bottling machine. Find the probability that the sample variance of the volumes in these \\(5\\) bottles will be at least \\(7\\) times as large as the sample variance of the volumes in the \\(9\\) bottles that were initially sampled.\n\\[\n\\begin{align}\nP(S_X^2 \\geq Y S_Y^2) & = P\\left( \\frac{S_X^2}{S_Y^2} &gt; 7 \\right) \\\\\n& = P\\left( \\frac{S_X^2 / \\sigma_X^2}{S_Y^2 / \\sigma_Y^2} &gt; 7 \\right) \\\\\n& = P(U &gt; 7) \\\\\n& \\approx P(U &gt; 7.01)\n= 0.010\n\\end{align}\n\\]\nNote that we can simply introduce \\(\\sigma_X\\) and \\(\\sigma_Y\\) because the two samples are know to from the same distribution and should, therefore, have the same population variance.",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#the-central-limit-theorem-clt",
    "href": "contents/chapter-07/index.html#the-central-limit-theorem-clt",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "3 The Central Limit Theorem (CLT)",
    "text": "3 The Central Limit Theorem (CLT)\n\nTheorem 9 (Central Limit Theorem) Suppose that \\(Y_i, Y_2, \\ldots , Y_n \\sim^{\\text{iid}} (\\mu, \\sigma^2)\\), where \\(-\\infty &lt; \\mu &lt; \\infty\\) and \\(\\sigma\\) positively bounded. Let \\[\nU_n = \\frac{\\overline{Y} - \\mu}{\\sigma / \\sqrt{n}} \\implies U_n \\xrightarrow{\\text{d}} \\mathcal{N}(0, 1) as n \\to \\infty\n\\]\nNote that we do not need to assume any distribution in this case, making it suitable for any sample without any assumed prior.\n\n\n\nExample 5 200 numbers are randomly (uniformly) chosen from 0 and 1. Find the probability that the average of these number is greater than 0.53.\n\nSolution 1\nLet \\(Y_i\\) be the \\(i\\) th number, \\(i = 1, \\ldots , n\\), where \\(n = 200\\). Then \\(Y_1, Y_2, \\ldots , Y_n \\sim^{\\text{iid}} U(0, 1)\\). Thus \\(\\mu = 1/2\\) and \\(\\sigma^2 = 1/12\\). Since we know the population expectation, we can directly apply the CLT and find that, \\[\nP(\\overline{Y} &gt; 0.53) = P\\left(\\frac{\\overline{Y} - \\mu}{\\sigma / \\sqrt{n}} &gt; \\frac{0.53 - 0.5}{\\sqrt{1/12} \\sqrt{200}}\\right) \\approx P(Z &gt; 1.47) = 0.0708\n\\] using normal tables.\n\n\n\n\n\n\n\nHow good is the normal approximation?\n\n\n\n\n\n\nShow the code\nsource(\"../../scripts/plot_bates.R\")\nprint(bates_plot)\n\n\n\n\n¬†\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\nWe can clearly see that this in fact as \\(n\\) becomes larger, it would become a better and better approximations. This is in fact called the Bates distribution, found by using convolution operator. Essetially, one can show that \\[\nf_{X_1 + X_2}(z) = \\int_0^1 f_{X_1}(x)f_{X_2}(z - x) \\, \\mathrm{dx}\n\\]\n\n\n\n\n3.1 Alternative\nYet another way to think about the CLT is \\(\\sumrv{Y} \\approx \\NormalDist(n\\mu, n\\sigma^2)\\), where \\(\\sumrv{Y} = Y_1 + Y_2 + \\ldots + Y_n\\)\n\nExample 6 A dies is about to be rolled 50 times, and each time you will win as many dollars as the number which comes up. Find the probability that you will win a total of at least $200.\n\nSolution\nlet \\(Y_i\\) be the number of dollars you will win on the \\(i\\)-th roll. Then \\(Y_1, Y_2, \\ldots, Y_n \\; \\iid (\\mu, \\sigma^2)\\), where: \\[\\begin{align}\n\\mu & = \\E{Y_i} = 3.5 \\\\\n\\sigma^2 & = \\Var{Y_i} = 2.9167 \\\\\n\\end{align}\\]\nTherefore, \\(\\P{\\sumrv{Y} \\geq 200} \\approx \\P{U &gt; 200}\\), where \\(U \\sim \\NormalDist(50 (3.5), 50(2.9167)) = \\NormalDist(175, 145.83)\\).\nThen \\(\\P{\\dot{Y} \\geq 200} \\approx \\P{Z &gt; \\frac{200 - 175}{\\sqrt{145.83}}} = \\P{Z &gt; 2.07) = 0.0192\\)\n\n\n\n3.2 Normal Approximation to \\(\\Binomial(n, p)\\)\nSuppose that \\(Y \\sim \\Binomial(n, p)\\), then \\(Y = Y_1 + Y_2 + \\ldots + Y_n\\), where \\(Y_1, \\ldots Y_2 \\sim^\\iid \\Bernoulli(p)\\). So \\(Y_1, Y_2, \\ldots, Y_n \\; \\iid (\\mu, \\sigma^2)\\), where: \\[\\begin{gather*}\n\\mu = \\E{Y_i} = p \\\\\n\\sigma^2 = \\Var{Y_i} = p(1 - p) \\\\\n\\end{gather*}\\] It follows by the CLT that \\(Y \\approx \\NormalDist(np, np(1 - p))\\).\n\n\nExample 7 (Normal Approximation (to everything?)) A die is rolled \\(n = 120\\) times. Find the probability that at least 27 sixes come up.\n\nSolution\nLet \\(Y\\) be the number of \\(6\\)‚Äôs. Then \\(U \\triangleq Y \\sim \\Binomial(120, 1/6)\\). So \\(Y \\approx \\NormalDist(120 (1/6), 120 (1/6)(5/6)\\)\nHence, \\[\\begin{align*}\n\\P{Z \\geq 27} & \\approx \\P{U &gt; 27} \\\\\n& = \\P{Z &gt; \\frac{27 - 20}{\\sqrt{16.67}}} = \\P{Z &gt; 1.71} = 0.0436 \\\\\n\\end{align*}\\]\n\n\n3.2.1 The Continuity Correction\nHowever, we need to take a closer look at the approximation made when we are applying to discrete cases. In Figure¬†1 below, the shaded red area is the area calculated as \\(\\P{U &gt; 27}\\) after normal approximation while the blue boxes underlay is the actual binomial distribution probability. Therefore, we can see that almost half of the column for \\(x = 27\\) is missed when we directly use the \\(\\NormalDist\\). Hence, a better approximation would then be \\[\\begin{equation*}\nP(Y \\geq 27) = P(U &gt; 26.5)\n\\end{equation*}\\]\n\n\nShow the code\nlibrary(ggplot2)\n\n# ÂèÉÊï∏Ë®≠ÂÆö\nn &lt;- 120\np &lt;- 1/6\nmu &lt;- n * p\nsigma &lt;- sqrt(n * p * (1 - p))\n\n# x ÂÄº\nx_binom &lt;- 27:40\nx_norm &lt;- seq(26, 40, length.out = 400)\n\n# ÂàÜÂ∏É\nbinom_probs &lt;- dbinom(x_binom, size = n, prob = p)\nnorm_density &lt;- dnorm(x_norm, mean = mu, sd = sigma)\n\n# Ë≥áÊñôÊ°ÜÔºöÊØèÂÄãÈÉΩÂä†‰∏ä 'type' Ê¨Ñ‰Ωç\ndf_binom &lt;- data.frame(x = x_binom, y = binom_probs, type = \"Binomial PMF\")\ndf_norm &lt;- data.frame(x = x_norm, y = norm_density, type = \"Normal PDF\")\ndf_shade &lt;- data.frame(x = x_norm[x_norm &gt;= 27],\n                       y = norm_density[x_norm &gt;= 27],\n                       type = \"Normal Tail\")\n\n# 1. Exact Binomial tail probability: P(Y ‚â• 27)\np_binom &lt;- sum(dbinom(27:n, size = n, prob = p))\n\n# 2. Normal approximation without continuity correction: P(U ‚â• 27)\np_norm_naive &lt;- pnorm(27, mean = mu, sd = sigma, lower.tail = FALSE)\n\n# 3. Normal approximation with continuity correction: P(U ‚â• 26.5)\np_norm_corrected &lt;- pnorm(26.5, mean = mu, sd = sigma, lower.tail = FALSE)\n\n# Print results\n# cat(sprintf(\"Binomial: P(Y ‚â• 27) ‚âà %.5f\\n\", p_binom))\n# cat(sprintf(\"Normal Approx (naive): P(U ‚â• 27) ‚âà %.5f\\n\", p_norm_naive))\n# cat(sprintf(\"Normal Approx (corrected): P(U ‚â• 26.5) ‚âà %.5f\\n\", p_norm_corrected))\n\n# Áï´Âúñ\nggplot() +\n  geom_col(data = df_binom, aes(x = x, y = y, fill = type), color = \"black\", width = 0.9, alpha=0.5) +\n  geom_line(data = df_norm, aes(x = x, y = y, color = type), linewidth = 1.2) +\n  geom_vline(xintercept = 27, linetype = \"dashed\", color = \"black\") +\n  geom_area(data = df_shade, aes(x = x, y = y, fill = type), alpha = 0.95) +\n  annotate(\"text\", x = 27.5, y = max(df_norm$y)*0.9, label = \"x = 27\", hjust = 0, size = 4) +\n  annotate(\"text\", x = 35, y = 0.03,\n           label = sprintf(\"Binomial: P(Y ‚â• 27) ‚âà %.5f\", p_binom),\n           hjust = 0, size = 4) +\n  annotate(\"text\", x = 35, y = 0.026,\n           label = sprintf(\"Normal: P(U ‚â• 27) ‚âà %.5f\", p_norm_naive),\n           hjust = 0, size = 4) +\n  annotate(\"text\", x = 35, y = 0.022,\n           label = sprintf(\"Normal: P(U ‚â• 26.5) ‚âà %.5f\", p_norm_corrected),\n           hjust = 0, size = 4) + \n  scale_fill_manual(\n    name = \"Distribution\",\n    values = c(\n      \"Binomial PMF\" = \"skyblue\",\n      \"Normal Tail\" = \"pink\"\n    )\n  ) +\n  scale_color_manual(\n    name = \"Distribution\",\n    values = c(\n      \"Normal PDF\" = \"red\"\n    )\n  ) +\n  labs(\n    title = \"Binomial (n = 120, p = 1/6) and Normal Approximation\",\n    x = \"x\", y = \"Probability / Density\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure¬†1: Why we need to have continuity correction?\n\n\n\n\n\n\n\nShow the code\n# Parameters\nn &lt;- 120\np &lt;- 1/6\nmu &lt;- n * p\nsigma &lt;- sqrt(n * p * (1 - p))",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#footnotes",
    "href": "contents/chapter-07/index.html#footnotes",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis proof is in reference to this material published by the Duke University which I found on Google somehow. If this material should not be public, please contact me with details here‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "CH07 : Sampling Distributions and Central Limit Theorem"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html",
    "href": "contents/chapter-06/index.html",
    "title": "Functions of Random Variables",
    "section": "",
    "text": "Transformations of Random Variables\nFind pdf and cdf of functions of randome variables",
    "crumbs": [
      "Home",
      "CH06 : Functions of Random Variables"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#learning-goals",
    "href": "contents/chapter-06/index.html#learning-goals",
    "title": "Functions of Random Variables",
    "section": "",
    "text": "Transformations of Random Variables\nFind pdf and cdf of functions of randome variables",
    "crumbs": [
      "Home",
      "CH06 : Functions of Random Variables"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#discrete-case",
    "href": "contents/chapter-06/index.html#discrete-case",
    "title": "Functions of Random Variables",
    "section": "2 Discrete Case",
    "text": "2 Discrete Case\n\n\n\n\n\n\nMotivating Example\n\n\n\nA coin is tossed twice. Let \\(Y\\) be the number of heads that come up. Find the distribution of \\(X = 3Y - 1\\).\nHere, \\(Y \\sim \\text{Bin}(2, 1/2)\\). So\n\\[\np(y) = \\begin{cases}\n1/4, & y = 0 \\\\\n1/2, & y = 1 \\\\\n1/4, & y = 2 \\\\\n\\end{cases}\n\\]\nIf \\(y=0\\), then \\(x = -1\\). If \\(y=1\\), then \\(x = -5\\). If \\(y=2\\), then \\(x = -2\\).\nThere is a one-to-one correspondence here between \\(x\\) and \\(y\\) values.\n\n\nIn general, we get the following,\n\nTheorem 1 (Transformations on a Discrete Variables) If \\(Y\\) is a discrete random variable, then \\(X = g(Y)\\) has pmf \\[p_X(x) = \\sum_{y: g(y) = x} p_Y(y)\\]\n\n\nExample 1 ¬†\n\nQuestion: For \\(Y \\sim \\text{Bin}(2, 1/2)\\). Find the distribution of \\(U = (Y - 1)^2\\).\nIn this case there are two possible values of \\(u\\): \\(0\\) (if \\(y = 1\\)), and \\(1\\) (if \\(y = 0 \\text{ or } 2\\)).\n\\[\nB_U(0) = \\sum_{y: (y - 1)^2=0} p(y) = p(1) = 1/2\n\\]\n\\[\nB_U(1) = \\sum_{y: (y - 1)^2=1} p(y) = p(0) + p(2) = 1/2\n\\]\nTherefore, \\(U \\sim \\text{Bern}(1/2)\\).\n\n\nExample 2 ¬†\n\nQuestion: If we roll two dice, what is the expected difference between the two numbers that come up?\nLet \\(Y_i\\) be the number on the \\(i\\)th die. We wish to find the expected value of \\(D \\ lvert Y_1 - Y_2 \\rvert\\). We first obtain the pmf of \\(D\\), according to \\[\np(d) = \\sum_{y_1, y_2: \\lvert y_1 - y_2 \\rvert d} p(y_1, y_2).\n\\] This is best done graphically (see Figure¬†1).\n\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\n\n\nTherefore, we can clearly see from the graph that,\\[p(d) = \\begin{cases} 6/36, & d = 0 \\\\ 10/36, & d = 1\\\\ 8 / 36, & d = 2 \\\\ 6 / 36, & d = 3 \\\\ 4/36, & d = 4 \\\\ 2/36, & d =5 \\\\ \\end{cases}\\] (with the sum of these probabilities to 1). It follows that\n\\[\nE(D) = \\sum_{d = 0}^5 d \\cdot p(d) = \\frac{35}{18}\n\\]\nAlternatiely,\n\\[\n\\begin{align}\nE(D) & = \\sum_{y_1, y_2} \\lvert y_1 - y_2 \\rvert f(y_1, y_2) \\\\\n& = \\frac{35}{18}\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "CH06 : Functions of Random Variables"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#continuous-case",
    "href": "contents/chapter-06/index.html#continuous-case",
    "title": "Functions of Random Variables",
    "section": "3 Continuous Case",
    "text": "3 Continuous Case\nThere are three main strategies we will look at:\n\nThe cdf method\nThe transformation method (or rule)\nThe mgf method\n\n\n3.1 The CDF Method\n\n\n\n\n\n\nImportant\n\n\n\nThis consists of two steps:\n\nFind the cdf of the rv of interest\nDifferentiate this CDF to obtain the required pdf\n\n\n\n\n\nExample 3 Suppose that \\(Y \\sim U(0, 2)\\). Find the pdf of \\(X = 3Y - 1\\).\n\n\\(X\\) has cdf\n\n\\[\n\\begin{align}\nF_X(x) & = P(X &lt; x) \\\\\n& = P(XY - 1 &lt; x) \\\\\n& = P\\left( Y &lt; \\frac{x+1}{3} \\right) \\\\\n& = \\int_0^{(x+1)/3} \\frac{1}{2} \\, dy \\\\\n& = \\frac{x + 1}{6}, \\qquad -1 &lt; x &lt; 5 \\hspace{10pt} \\text{(since $3(0) - 1$ = -1 and $3(2) - 1 = 5$)} \\\\\n\\end{align}\n\\]\n\nSo \\(X\\) has pdf \\(f(x) = F'(x) = \\frac{1}{6}\\) for \\(-1 &lt; x &lt; 5\\). In other words, \\(X \\sim U(-1, 5)\\).\n\n\n\nExample 4 Suppose that \\(X, Y \\sim ^{iid} U(0, 1)\\). Find the pdf of \\(U = X + Y\\).\nFirst observe that \\(f(x, y) = 1\\), for \\(0 &lt; x &lt; 1\\), \\(0 &lt; y &lt; 1\\).\n\nShow the code\nimport { slider } from \"@jashkenas/inputs\"\n\nviewof u = Inputs.range([0, 2], {step: 0.01, label: \"u\"})\n\nfunction shadedArea(u) {\n  if (u &lt;= 0) return 0;\n  if (u &lt;= 1) return 0.5 * u * u;\n  if (u &lt;= 2) return 1 - 0.5 * (2 - u) * (2 - u);\n  return 1;\n}\n\nPlot.plot({\n  width: 400,\n  height: 400,\n  marginLeft: 40,\n  marginBottom: 40,\n  caption: \"Shaded region bounded by y = u - x and unit square\",\n  x: {\n    domain: [-0.1, 1.1],\n    label: \"x\",\n    ticks: 6\n  },\n  y: {\n    domain: [-0.1, 1.1],\n    label: \"y\",\n    ticks: 6\n  },\n  marks: [\n    // Shaded area under the line y = u - x, clipped to unit square\n    Plot.areaY(\n      d3.range(0, 1.01, 0.01).map(x =&gt; {\n        const y = Math.min(Math.max(u - x, 0), 1);\n        return { x, y };\n      }),\n      {\n        x: \"x\",\n        y: \"y\",\n        fill: \"steelblue\",\n        opacity: 0.5\n      }\n    ),\n\n    // The line y = u - x\n    Plot.line(\n      d3.range(0, 1.01, 0.01).map(x =&gt; ({ x, y: Math.min(1, Math.max(0, u - x)) })),\n      {\n        x: \"x\",\n        y: \"y\",\n        stroke: \"black\"\n      }\n    ),\n\n    // Draw the unit square as a closed path\n    Plot.line(\n      [\n        { x: 0, y: 0 },\n        { x: 1, y: 0 },\n        { x: 1, y: 1 },\n        { x: 0, y: 1 },\n        { x: 0, y: 0 }\n      ],\n      {\n        x: \"x\",\n        y: \"y\",\n        stroke: \"gray\",\n        strokeWidth: 1.5\n      }\n    )\n  ]\n})\nhtml`\n    &lt;p&gt;&lt;strong&gt;Shaded Area:&lt;/strong&gt; ${(shadedArea(u)).toFixed(4)}&lt;/p&gt;\n`\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\nSo \\(U\\) has cdf Now, from the interactive figure above, we see that what we need is exactly the area bounded by the unit square and the line \\(x + y = u\\). Therefore, first suppose \\(u &lt; 1\\), then \\[\n\\begin{align}\nF(u) & = P(U &lt; u) \\\\\n& = P(X + Y &lt; u) \\\\\n& = P(Y &lt; u - X) \\\\\n& = \\frac{1}{2}u^2 \\hspace{10pt} \\text{for $u \\in [0, 1]$}\n\\end{align}\n\\] Now, suppose \\(u &gt; 1\\), then more than half of the square is filled. Therefore, we can look at the not shaded part. The y-value at \\(x=1\\) is \\(u - 1\\). Since, the side lenght is \\(1\\), the length of the unshaded part is \\(1 - (u - 1) = 2 - u\\). Hence, the final area is \\(1 - \\frac{1}{2}(2-u)^2\\). Therefore, the cdf is, \\[\nF(u) = \\begin{cases}\n\\frac{u^2}{2}, & 0 \\leq u &lt; 1 \\\\\n1 - \\frac{1}{2}(2 - u)^2, & 1 \\leq u &lt; 2 \\\\\n\\end{cases}\n\\]\nTherefore \\(U\\) has pdf \\[\nf(u) = F'(u) = \\begin{cases}\nu, & 0 \\leq u &lt; 1 \\\\\n2 - u, & 1 \\leq y &lt; 2 \\\\\n\\end{cases}\n\\]\n\n\n\nExample 5 (Example: Non-monotonic Transformation) Let \\(Y \\sim U(0, 1)\\). Find the pdf of \\(X = Y(1 - Y)\\). \\[\n\\begin{align}\nF(x) &= P(X &lt; x) \\\\\n&= P(Y(1 - Y) &lt; x) \\\\\n&= P(Y - Y^2 - x &lt; 0) \\\\\n&= P\\left( \\left( Y - \\frac{1 + \\sqrt{1 - 4x}}{2} \\right) \\left( Y - \\frac{1 - \\sqrt{1 - 4x}}{2} \\right) \\right) &lt; 0 \\\\\n&= P(Y &lt; \\frac{1 - \\sqrt{1 - 4x}}{2} \\text{ or } Y &gt; \\frac{1 + \\sqrt{1 - 4x}}{2}) \\\\\n&= \\frac{1 - \\sqrt{1 - 4x}}{2} + (1 - \\frac{1 + \\sqrt{1 - 4x}}{2}) \\\\\n&= 1 - \\sqrt{1 - 4x} \\\\\n\\end{align}\n\\]\nNow, the pdf is \\(f(x) = F'(x) = 2(1 - 4x)^{-1/2}\\).\n\n\n\n3.2 The Transformation Method\nSuppose that \\(Y\\) is a continuous random variable with pdf \\(f(y)\\), and \\(x = g(y)\\) is a function which is strictly monotonic, for all possible values \\(y\\) of \\(Y\\). Then \\(X = g(Y)\\) has pdf\\[f(x) = f(y) \\left\\lvert \\frac{dy}{dx} \\right\\rvert\\] where \\(y = g^{-1}(x)\\). (This is the inverse function of \\(g\\))\n\nExample 6 (Example 6) Suppose that \\(Y \\sim U(0, 2)\\).\nFind the pdf of \\(X = 3Y - 1\\). (The same as Example¬†3.)\nHere \\(x = 3y - 1\\) is strictly increasing. Therefore \\(y = \\frac{x + 1}{3}\\) and \\(\\frac{dy}{dx} = \\frac{1}{3}\\). Therefore, \\(f(x) = f(y) \\left\\lvert \\frac{1}{3} \\right\\rvert = \\frac{1}{6}\\), the range of \\(x\\) is \\([-1, 5]\\).\n\n\nExample 7 (Example 7) \\(Y \\sim \\mathcal{N}(a, b^2)\\). Find the distribution of \\(Z = \\frac{Y - a}{b}\\).\nNote that this transformation is always strictly monotonic because it is clear that \\(b\\) is positive.\nThen, \\(y = a + bz\\) and, hence, \\(\\frac{dy}{dz} = b\\). Therefore \\[\n\\begin{align}\nf(z) = f(y) \\left\\lvert \\frac{dy}{dz} \\right\\rvert & = \\frac{1}{b \\sqrt{2\\pi}} e^{-\\frac{1}{2b^2} (a + bz - a)^2} \\lvert b \\rvert \\\\\n& = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} z^2}, \\hspace{10pt} -\\infty &lt; z &lt; \\infty\n\\end{align}\n\\]\nThus \\(Z \\sim \\mathcal{N}(0, 1)\\).\n\n\n3.2.1 Special Example of Non-monotonic Transformation\nSuppose \\(Z \\sim \\mathcal{N}(0, 1)\\). Find the distribution of \\(X = Z^2\\).\nIn this case, \\(x = z^2\\) is neither strictly increasing nor strictly decreasing. So the transformation method cannot be directly used, but a alternatives can be used. We could find the pdf of \\(X\\) using the cdf method. We can also use the mgf method as shown later. But before that, we need to develop an idea why transformation method even work.\n\nRemark 1 (Why Transformation Work). Now, we can separate this into two cases ‚Äî strictly increasing and strictly decreasing.\nCase 1: x = g(y) is strictly increasing. This, in particular, refers to region with positive \\(z\\) values. \\[\nx = g(y) \\Leftrightarrow y = g^{-1}(x)\n\\]\nTherefore, if we want to know when is \\(g(y) \\leq x\\), we can use \\(y \\leq g^{-1}(x)\\). Therefore,\\[P(g(Y) \\leq x) = P(Y \\leq g^{-1}(x)) = F_Y(g^{-1}(x))\\]\nHence, \\[\n\\begin{align}\nf_X(x) & = \\frac{dF_X(x)}{dx} = \\frac{dF_Y(g^{-1}(x)}{dx} \\\\\n& = f_Y(g^{-1}(x)) \\cdot \\frac{dg^{-1}(x)}{dx} \\\\\n& = f_Y(y) \\frac{dy}{dx} \\\\\n\\end{align}\n\\]\nCase 2: \\(x = g(y)\\) is strictly decreasing. \\[\nx = g(y) \\Leftrightarrow y = g^{-1}(x)\n\\]\nThen similarly, we know that \\(P(g(Y) \\leq x) = P(Y \\geq g^{-1}(x)) = 1 - F_Y(g^{-1}(x))\\)\n\\[\n\\begin{align}\nf_X(x) & = \\frac{dF_X(x)}{dx} = \\frac{d}{dx}(1 - F_Y(g^{-1}(x))) \\\\\n& = -f_Y(g^{-1}(x)) \\cdot \\frac{dg^{-1}(x)}{dx} \\\\\n& = -f_Y(y) \\frac{dy}{dx} = f_Y(y) \\left\\lvert \\frac{dy}{dx} \\right\\rvert\n\\end{align}\n\\]\nNote that \\(\\frac{dy}{dx} &lt; 0\\) as it is decreasing. Now, we have used the CDF method to essentially shows why the transformation should work.\n\n\nExample 8 (The Distribution of The Square of a Standard Normal) Now, we can come back to our original problem of finding the pdf of \\(X = Z^2\\). From Remark¬†1 above and combined with Example¬†5, we may conject the following formula. \\[\nf_X(x) = \\sum_{g(z) = x} f_Z(z) \\left\\lvert \\frac{dz}{dx} \\right\\rvert\n\\] which \\(Z \\sim \\mathcal{N}(0, 1)\\). Find the distribution of \\(X = Z^2\\).\nTwo roots: \\(z = \\sqrt{x}\\) or \\(z = -\\sqrt{x}\\). Therefore, \\(\\left\\lvert \\frac{dz}{dx} \\right\\rvert = \\frac{1}{2\\sqrt{x}}\\). Therefore, \\[\n\\begin{align}\nf_X(x) = \\sum_{z^2 = x} f_Z(z) \\left\\lvert \\frac{dz}{dx} \\right\\rvert & = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x} \\frac{1}{2\\sqrt{x}} + \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x} \\frac{1}{2\\sqrt{x}} \\\\\n& = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x} x^{-\\frac{1}{2}} \\hspace{10pt} \\text{for $0 &lt; x &lt; \\infty$} \\\\\n& = \\frac{1}{\\sqrt{2}\\Gamma(1/2)} e^{-\\frac{1}{2}x} x^{-\\frac{1}{2}} \\hspace{10pt} \\text{for $0 &lt; x \\infty$}\n\\end{align}\n\\]\nThis is the pdf of the gamma distribution with \\(a = 1/2\\), \\(b = 2\\) such that \\(X \\sim Gam(1/2, 2) = \\chi^2(1)\\).\n\n\n\n\n3.3 The Moment Generating Function Method\nRecall that the mgf of a r.v. can uniquely identify the distribution of the random variable \\(X\\). Recall its definition being \\[\nm_X(t) = E\\left( e^{Xt} \\right)\n\\]\n\nExample 9 (The Distribution of The Square of a Standard Normal ‚Äî Revisited) Now, we will try to use the mgf method for the same problem as above.\n\\[\n\\begin{align}\nm_X(t) = E\\left( x^{Xt} \\right) = E\\left( e^{Z^2 t} \\right) & = \\int_{-\\infty}^{\\infty} e^{z^2} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}z^2} \\, dz \\\\\n& = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}z^2(1 - 2t)} \\, dz \\\\\n& = c \\int_{-\\infty}^{\\infty} \\frac{1}{c\\sqrt{2\\pi}} e^{-\\frac{1}{2c^2}z^2} \\, dz \\\\, \\hspace{20pt} \\text{where $c^2 = \\frac{1}{1 - 2t}$} \\\\\n& = c\n\\end{align}\n\\]\nThe last step is true becuase it is the pdf of the random variable with distribution of \\(\\mathcal{N}(0, c^2)\\).\nTherefore, \\(m_X(t) = (1 - 2t)^{-1/2}\\). However, this is the mgf of \\(Gam(1/2, 2)\\). Therefore, it must follows the Chi-Square distribution.\n\nAnother method of working with Example¬†8 and Example¬†9 is by considering the folded normal distribution with \\(Y = \\lvert Z \\rvert\\). Its cdf is relatively easy to obtain by the symmetry of \\(Z\\).\n\nShow the code\nviewof x = Inputs.range([0, 5], {step: 0.0001, label: \"Y\"})\n\nfunction standardNormalPDF(x) {\n  return (1 / Math.sqrt(2 * Math.PI)) * Math.exp(-0.5 * x * x);\n}\n\nfunction normalCDF(y) {\n  return 0.5 * (1 + erf(y / Math.sqrt(2)));\n}\n\n// Approximation of the error function\nfunction erf(x) {\n  // Abramowitz & Stegun formula 7.1.26\n  const sign = x &lt; 0 ? -1 : 1;\n  const a1 =  0.254829592, a2 = -0.284496736, a3 =  1.421413741;\n  const a4 = -1.453152027, a5 =  1.061405429;\n  const p  =  0.3275911;\n  const t = 1 / (1 + p * Math.abs(x));\n  const val = 1 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);\n  return sign * val;\n}\n\nxs = d3.range(-4, 4.01, 0.001);\npdfData = xs.map(x =&gt; ({ x, y: standardNormalPDF(x) }));\nshaded = pdfData.filter(d =&gt; d.x &gt;= -x && d.x &lt;= x);\nexcluded_left = pdfData.filter(d =&gt; d.x &lt;= -x);\nexcluded_right = pdfData.filter(d =&gt; d.x &gt;= x);\n\nPlot.plot({\n  width: 500,\n  height: 300,\n  marginLeft: 40,\n  marginBottom: 40,\n  title: \"P(|Z| ‚â§ y)\",\n  x: {\n    domain: [-4, 4],\n    label: \"x\"\n  },\n  y: {\n    label: \"Density\"\n  },\n  marks: [\n    Plot.areaY(shaded, { x: \"x\", y: \"y\", fill: \"steelblue\", opacity: 0.6 }),\n    Plot.areaY(excluded_left, { x: \"x\", y: \"y\", fill: \"lightcoral\", opacity: 0.6 }),\n    Plot.areaY(excluded_right, { x: \"x\", y: \"y\", fill: \"lightcoral\", opacity: 0.6 }),\n    Plot.line(pdfData, { x: \"x\", y: \"y\", stroke: \"black\" })\n  ]\n})\nhtml`&lt;p&gt;&lt;strong&gt;Area P(-y ‚â§ Z ‚â§ y):&lt;/strong&gt; ${(normalCDF(x) - normalCDF(-x)).toFixed(4)}&lt;/p&gt;`\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\nRemark 2 (Yet Another Method to Arrive to Chi-Square Distribution). Therefore, from the above graph, we can obtain the following,\n\\[\n\\begin{align}\nF_Y(y) = P(Y &lt; y) & = P(\\lvert Z \\rvert &lt; y) \\hspace{20pt} \\text{(The blue region)} \\\\\n& = P(Z &lt; y \\text{ and } Z &gt; -y) \\hspace{20pt} \\text{(The blue region)} \\\\\n& = 1 - 2P(Z &gt; y) \\hspace{20pt} \\text{(Blue = 1 - 2 * Red)} \\\\\n& = 1 - 2 (1 - \\Phi(y)) \\\\\n& = 2 \\Phi(y) - 1 \\\\\nf(y) & = F'(y) = 2\\Phi'(y) = 2\\phi(y) \\\\\n\\end{align}\n\\]\nThen, we can use the basic transformation that \\(X = Z^2 = Y^2\\) which we do not need to deal non-monotonicity as it above. Hence, \\[\n\\left\\lvert \\frac{dy}{dx} \\right\\rvert = \\frac{1}{2\\sqrt{x}}\n\\]\nTherefore, \\[\nf_X(x) = f_Y(y) \\left\\lvert \\frac{dy}{dx} \\right\\rvert = \\frac{2}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x} \\frac{1}{2\\sqrt{x}}, \\qquad x &gt; 0\n\\]\n\n\n3.3.1 Two Useful Results when Applying the MGF Technique\n\nIf \\(X = a + bY\\), then \\[\nm_X(t) = e^{at}m_Y(bt)\n\\]\nIf \\(Y_1, Y_2, \\ldots , Y_n\\) are independent random variables and \\(X = Y_1 + Y_2 + \\cdots + Y_n\\), then \\[\nm_X(t) = m_{Y_1}(t)m_{Y_2}(t) \\ldots m_{Y_n}(t)\n\\]\n\n\nExample 10 \\(Y \\sim N(0, 1)\\). Find the distribution of \\(X = a + bY\\).\n\\[\n\\begin{align}\nm_X(t) &= e^{at} m_Y(bt) \\\\\n& = e^{at} e^{\\frac{1}{2}(bt)^2} \\\\\n& = e^{at + \\frac{1}{2}b^2t^2} \\\\\n\\end{align}\n\\]\nTherefore, \\(X \\sim \\mathcal{N}(a, b^2)\\).\n\n\nExample 11 Suppose that \\(Y_1, Y_2, \\ldots, Y_n\\) are independent gamma rv‚Äôs, such that the \\(i\\)th one has parameters \\(a_i\\) and \\(b\\). Find the distribution of \\(X = Y_1 + Y_2 + \\cdots + Y_n\\).\n\\[\n\\begin{align}\nm_X(t) &= m_{Y_1}(t) m_{Y_2}(t) \\ldots m_{Y_n}(t) \\\\\n& = (1 - bt)^{-a_1} \\cdots (1 - bt)^{-a_n} \\\\\n& = (1 - bt)^{-a}\n\\end{align}\n\\]\nHence \\(X \\sim Gam(a, b)\\) where \\(a = \\sum_i a_i\\).\n\n\nCorollary 1 Since \\(\\chi^2\\) is essentially a gamma distribution, we have \\[\nY_1, \\ldots , Y_n \\sim^{\\text{iid}} \\chi^2(1) \\implies \\sum_i Y_i \\sim \\chi^2(n).\n\\]",
    "crumbs": [
      "Home",
      "CH06 : Functions of Random Variables"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#order-statistics",
    "href": "contents/chapter-06/index.html#order-statistics",
    "title": "Functions of Random Variables",
    "section": "4 Order Statistics",
    "text": "4 Order Statistics\nSuppose that \\(Y_1, Y_2, \\ldots, Y_n\\) are iid rv‚Äôs.\nLet: \\(U_1\\) be the smallest of these, \\(U_2\\) be the second smallest and so on.\n\nExample 12 Suppose that \\(Y_1, Y_2 \\sim^{\\text{iid}} Exp(b)\\). Find the pdf of the second order statistics, \\(U_2 = \\max(Y_1, Y_2)\\). Also, find the expectation.\n\\[\n\\begin{align}\nF_{U_2}(u) = P(U_2 &lt; u) & = P(\\max(Y_1, Y_2) &lt; u) = P(Y_1 &lt; u, Y_2 &lt; u) \\\\\n& = P(Y_1 &lt; u)^2 \\hspace{20pt} \\text{(by independence)} \\\\\n& = (1 - e^{-\\frac{u}{b}})^2 \\\\\nf_U(u) &= F_{U_2}'(u) = \\frac{2}{b}(1 - e^{-\\frac{u}{b}})e^{-\\frac{u}{b}} \\hspace{20pt} u &gt; 0\n\\end{align}\n\\]\n\n\\[\n\\begin{align}\nE(U_2) & = \\int_0^\\infty \\frac{2u}{b} e^{-\\frac{u}{b}}(1 - e^{-\\frac{u}{b}}) \\, du \\\\\n& = \\int_0^\\infty \\frac{2u}{b} e^{-\\frac{u}{b}} \\, du - \\int_0^\\infty \\frac{2u}{b}e^{-\\frac{2u}{b}} \\, du \\\\\n& = 2 \\cdot E[Exp(b)] - E[Exp(b/2)] \\\\\n& = 2b - b/2 = \\frac{3b}{2} \\\\\n\\end{align}\n\\]\n\n\n4.1 General Formula\n\nTheorem 2 (General Formula for Order Statistics) If \\(Y_1, Y_2, \\ldots, Y_n\\) are continuous and iid, then the pdf of the \\(k\\)th order statistic \\(U_k\\) is \\[\nf_{U_k}(u) = \\frac{n!}{(k - 1)!(n-k)!} F(u)^{k - 1} \\left( 1 - F(u) \\right)^{n-k} f(u)\n\\] where \\(f(y)\\) and \\(F(y)\\) are the pdf and cdf of \\(Y_1\\) respectively.\n\n\nProof. First, we will derive the cdf. For \\(P(U_k &lt; u)\\), it requires essentially the \\(k\\)-largest value to be less than \\(u\\). To achieve this, we only need at least \\(k\\) values to be less than \\(u\\) out of all the order statistics. Therefore, \\[\nF_{U_k}(u) = P(U_k &lt; u) = \\sum_{j = k}^n \\binom{n}{j} (F(u))^{j} (1 - F(u))^{n - j}\n\\], where \\(F\\) is the cdf of any \\(Y\\) (as they are all the same).\nNow, we apply the routine algebraic to obtain the pdf. Teh following is a proof provided by Stephen Ge on this blog page hosted on StackExchange. \\[\n\\begin{align}\nf_{U_k}(u) & = \\frac{d}{du}\\left[ \\sum_{j = k}^n \\binom{n}{j} (F(u))^{j} (1 - F(u))^{n - j} \\right] \\\\\n& = \\frac{d}{du}\\left[ \\left( \\sum_{j = k}^{n-1} \\binom{n}{j} (F(u))^{j} (1 - F(u))^{n - j} \\right) + (F(u))^n \\right] \\\\\n& = \\left(\\sum_{j = k}^{n-1} \\binom{n}{j} j f(u) (F(u))^{j-1} (1 - F(u))^{n - j} \\right) \\\\\n& \\qquad - \\left( \\sum_{j = k}^{n-1} \\binom{n}{j} (n - j) f(u) (F(u))^{j} (1 - F(u))^{n - j - 1} \\right) \\\\\n& \\qquad + nf(u)(F(u))^{n-1} \\\\\n& = \\frac{n!}{(k - 1)! (n - k)!}f(u) (F(u))^{k-1} (1 - F(u))^{n - k} \\\\\n& \\qquad + \\left(\\sum_{j = k + 1}^{n-1} \\frac{n!}{(j-1)!(n-j)!} f(u) (F(u))^{j-1} (1 - F(u))^{n - j} \\right) \\\\\n& \\qquad - \\left( \\sum_{j = k}^{n-2} \\frac{n!}{j!(n - j - 1)!} f(u) (F(u))^{j} (1 - F(u))^{n - j - 1} \\right) \\\\\n& \\qquad - n f(u) (F(u))^{n-1} + nf(u)(F(u))^{n-1} \\\\\n& = \\frac{n!}{(k - 1)! (n - k)!}f(u) (F(u))^{k-1} (1 - F(u))^{n - k} \\\\\n\\end{align}\n\\]\nIn the second last step, the two summations would cancel out because they form a telescoping sequence.",
    "crumbs": [
      "Home",
      "CH06 : Functions of Random Variables"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#range-restricted-distribution",
    "href": "contents/chapter-06/index.html#range-restricted-distribution",
    "title": "Functions of Random Variables",
    "section": "5 Range Restricted Distribution",
    "text": "5 Range Restricted Distribution\n\n\n\n\n\n\nMotivating Example\n\n\n\nSuppose that the number of accidents which occur each year at a certain intersection follows a Poisson distribution with mean \\(\\lambda\\). Find the pmf of the number of accidents at this intersection last year if it is known that at least one accident occurred there during that year. What is the expected value for that year?\n\nSuppose \\(X = (Y \\mid Y &gt; 0)\\), then \\(X\\) has pmf for \\(x \\in [1, \\infty)\\) \\[\n\\begin{align}\np_X(x) = P(X = x) & = P(Y = x \\mid Y &gt; 0) \\\\\n& = \\frac{P(Y = x)}{P(Y &gt; 0)} \\\\\n& = \\frac{\\frac{e^{-\\lambda}\\lambda^x}{x!}}{1 - P(Y = 0)} \\\\\n& = \\frac{e^{-\\lambda}\\lambda^x}{x!(1 - e^{-\\lambda})} \\\\\n\\end{align}\n\\]\n\n\\[\n\\begin{align}\nE[X] & = \\sum_x x P(X = x) \\\\\n& = \\sum_x x \\frac{P(Y = x)}{P(Y &gt; 0)} \\\\\n& = \\frac{1}{1 - P(Y = 0)} \\sum_{x=1}^\\infty x P(Y = x) \\\\\n& = \\frac{1}{1 - P(Y = 0)} \\sum_{x=0}^\\infty x P(Y = x) \\\\\n& = \\frac{1}{1 - e^{-\\lambda}} E[Y] \\\\\n& = \\frac{\\lambda}{1 - e^{-\\lambda}}\n\\end{align}\n\\]\nTherefore, it would then be clear that it is always higher than unconditional expectation. This makes sense as we know that it is not possible to not have any and hence increasing our expectation of the number of accidents.",
    "crumbs": [
      "Home",
      "CH06 : Functions of Random Variables"
    ]
  },
  {
    "objectID": "contents/chapter-09/index.html",
    "href": "contents/chapter-09/index.html",
    "title": "Properties of Point Estimators & Methods of Estimation",
    "section": "",
    "text": "consistency\nconvergent\nMLE. Maximise probability of the samples (likelihood)\nMOM. Equate sample moments to population moments",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-09/index.html#learning-goal",
    "href": "contents/chapter-09/index.html#learning-goal",
    "title": "Properties of Point Estimators & Methods of Estimation",
    "section": "",
    "text": "consistency\nconvergent\nMLE. Maximise probability of the samples (likelihood)\nMOM. Equate sample moments to population moments",
    "crumbs": [
      "Home",
      "CH09 : Properties of Point Estimators & Methods of Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html",
    "href": "contents/chapter-03/2measures.html",
    "title": "Measures Related to Distribution",
    "section": "",
    "text": "Now, we want to ask a question about what is the ‚Äúexpected value‚Äù of the outcome of a certain random variable.\n\nDefinition 1 Suppose \\(Y\\) is a discrete random variable with pmf \\(p(y)\\). Then the expected value (or mean) of \\(Y\\) is \\[\n\\mathbb{E}(Y) = \\sum_y y p(y)\n\\]\nThe sum is over all possible values \\(y\\) of the rv \\(Y\\). We may also write \\(Y\\)‚Äôs mean as \\(\\mu_Y\\) or \\(\\mu\\).\n\n\\(\\mu\\) is a measure of central tendency, in the sense that it represents the average of a hypothetically infinite number of independent realisations of \\(Y\\).\n\n\nExample 1 Find the mean of the Bernoulli distribution.\nLet \\(Y \\sim \\text{Bern}(p)\\). Then\n\\[\n\\mu = \\sum_{y=0}^{1} yp(y) = 0p(0) + 1p(1) = 0(1-p) + 1p = p\n\\]\nThus for example, if we toss a fair coin thousands of times, and each time write 1 when a head comes up and 0 otherwise, we will get a sequence like 0,0,1,0,1,1,1,0,‚Ä¶ The average of these 1‚Äôs and 0‚Äôs will be about 1/2, corresponding to the fact that each such number has a Bernoulli distribution with parameter 1/2 and thus a mean of 1/2.\n\n\n\nTheorem 1 If \\(Y \\sim \\text{Bin}(n, p)\\). Then \\(Y\\) has expectation \\(np\\).\n\n\nProof. \\[\\begin{align*}\n\\mu & = \\sum_{y=0}^{n} y \\binom{n}{y} p^y (1- p)^{n-y} \\\\\n& = \\sum_{y=1}^{n} y \\frac{n!}{y! (n-y)!} p^y (1-p)^{n-y} \\tag{the first term is zero} \\\\\n& = np \\sum_{y=1}^{n} \\frac{(n-1)!}{(y-1)!(n-1-(y-1))!}p^{y-1}(1-p)^{n-1-(y-1)} \\\\\n& = np \\sum_{x=0}^{m} \\frac{m!}{x! (m - x)!} p^x (1 - p)^{m-x} \\tag{$x = y - 1$ and $m = n - 1$} \\\\\n& = np \\tag{since the sum equals 1, by the binomial theorem}\n\\end{align*}\\]\nThis makes sense. For example, if we roll a die 60 times, we can expect 60(1/6) = 10 sixes.\n\n\n\n\n\nDefinition 2 Suppose that \\(Y\\) is a discrete random variable with pmf \\(p(y)\\), and \\(g(t)\\) is a function. Then the expected value (or mean) of \\(g(Y)\\) is defined to be \\[\n\\mathbb{E}(g(Y)) = \\sum_y g(y)p(y)\n\\]\n\nHere, we have simply taken this as a definition, so no need for a proof. otherwise, refer to Law of the Unconscious Statistician.\n\n\nExample 2 Suppose that \\(Y \\sim \\text{Bern}(p)\\). Find \\(\\mathbb{E}[Y^2]\\).\n\\[\n\\mathbb{E}\\left[Y^2\\right] = \\sum_y y^2 p(y) = 0^2(1-p) + 1^2p = p\n\\]\n\n\nCorollary 1 It is clear to see that the above procedures can be applied to \\(\\mathbb{E}\\left[Y^k\\right] = p\\).\n\n\n\n\n\n\nIf \\(c\\) is constant, then \\(\\mathbb{E}\\left[c\\right] = c\\)\n\\(\\mathbb{E}\\left[c g(Y) \\right] = c \\mathbb{E}\\left[ g(Y) \\right]\\)\n\\(\\mathbb{E}\\left[ \\sum_{i = 1}^{k} g_i(Y) \\right] = \\sum_{i=1}^k \\mathbb{E}\\left[ g_i(Y) \\right]\\)\n\n\nProof. \\[\n\\mathbb{E}[c] = \\sum_y cp(y) = c \\sum_y p(y) = c \\cdot (1) = c\n\\]\n\n\nProof. \\[\\begin{align*}\n\\mathbb{E}\\left[ cg(Y) \\right] & = \\sum_y cg(y) p(y) \\\\\n& = c \\sum_y g(y) p(y) \\\\\n& = c \\mathbb{E}\\left[ g(Y) \\right] \\\\\n\\end{align*}\\]\n\n\nProof. \\[\n\\mathbb{E} \\left[ \\sum_{i=1}^k g_i(Y) \\right] = \\sum_y \\left( \\sum_{i=1}^k g_i(Y) \\right) p(y) = \\sum_{i=1}^k \\sum_y \\left( g_i(Y) p(Y) \\right) = \\sum_{i=1}^k \\mathbb{E}\\left[g_i(Y)\\right]\n\\]\n\n\n\n\n\nThe \\(k\\)-th raw moment of \\(Y\\) is \\(\\mu_k' = \\mathbb{E}\\left[Y^k\\right]\\)\nThe \\(k\\)-th central moment of \\(Y\\) is \\(\\mu_k = \\mathbb{E} \\left[ (Y - \\mu)^k \\right]\\)\nThe variance of \\(Y\\) is \\(\\text{Var}(Y) = \\sigma^2 = \\mu_2 = \\mathbb{E}\\left[ (Y - \\mu)^2 \\right]\\)\nThe standard deviation of \\(Y\\) is simply the square root of variance.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#expectation",
    "href": "contents/chapter-03/2measures.html#expectation",
    "title": "Measures Related to Distribution",
    "section": "",
    "text": "Now, we want to ask a question about what is the ‚Äúexpected value‚Äù of the outcome of a certain random variable.\n\nDefinition 1 Suppose \\(Y\\) is a discrete random variable with pmf \\(p(y)\\). Then the expected value (or mean) of \\(Y\\) is \\[\n\\mathbb{E}(Y) = \\sum_y y p(y)\n\\]\nThe sum is over all possible values \\(y\\) of the rv \\(Y\\). We may also write \\(Y\\)‚Äôs mean as \\(\\mu_Y\\) or \\(\\mu\\).\n\n\\(\\mu\\) is a measure of central tendency, in the sense that it represents the average of a hypothetically infinite number of independent realisations of \\(Y\\).\n\n\nExample 1 Find the mean of the Bernoulli distribution.\nLet \\(Y \\sim \\text{Bern}(p)\\). Then\n\\[\n\\mu = \\sum_{y=0}^{1} yp(y) = 0p(0) + 1p(1) = 0(1-p) + 1p = p\n\\]\nThus for example, if we toss a fair coin thousands of times, and each time write 1 when a head comes up and 0 otherwise, we will get a sequence like 0,0,1,0,1,1,1,0,‚Ä¶ The average of these 1‚Äôs and 0‚Äôs will be about 1/2, corresponding to the fact that each such number has a Bernoulli distribution with parameter 1/2 and thus a mean of 1/2.\n\n\n\nTheorem 1 If \\(Y \\sim \\text{Bin}(n, p)\\). Then \\(Y\\) has expectation \\(np\\).\n\n\nProof. \\[\\begin{align*}\n\\mu & = \\sum_{y=0}^{n} y \\binom{n}{y} p^y (1- p)^{n-y} \\\\\n& = \\sum_{y=1}^{n} y \\frac{n!}{y! (n-y)!} p^y (1-p)^{n-y} \\tag{the first term is zero} \\\\\n& = np \\sum_{y=1}^{n} \\frac{(n-1)!}{(y-1)!(n-1-(y-1))!}p^{y-1}(1-p)^{n-1-(y-1)} \\\\\n& = np \\sum_{x=0}^{m} \\frac{m!}{x! (m - x)!} p^x (1 - p)^{m-x} \\tag{$x = y - 1$ and $m = n - 1$} \\\\\n& = np \\tag{since the sum equals 1, by the binomial theorem}\n\\end{align*}\\]\nThis makes sense. For example, if we roll a die 60 times, we can expect 60(1/6) = 10 sixes.\n\n\n\n\n\nDefinition 2 Suppose that \\(Y\\) is a discrete random variable with pmf \\(p(y)\\), and \\(g(t)\\) is a function. Then the expected value (or mean) of \\(g(Y)\\) is defined to be \\[\n\\mathbb{E}(g(Y)) = \\sum_y g(y)p(y)\n\\]\n\nHere, we have simply taken this as a definition, so no need for a proof. otherwise, refer to Law of the Unconscious Statistician.\n\n\nExample 2 Suppose that \\(Y \\sim \\text{Bern}(p)\\). Find \\(\\mathbb{E}[Y^2]\\).\n\\[\n\\mathbb{E}\\left[Y^2\\right] = \\sum_y y^2 p(y) = 0^2(1-p) + 1^2p = p\n\\]\n\n\nCorollary 1 It is clear to see that the above procedures can be applied to \\(\\mathbb{E}\\left[Y^k\\right] = p\\).\n\n\n\n\n\n\nIf \\(c\\) is constant, then \\(\\mathbb{E}\\left[c\\right] = c\\)\n\\(\\mathbb{E}\\left[c g(Y) \\right] = c \\mathbb{E}\\left[ g(Y) \\right]\\)\n\\(\\mathbb{E}\\left[ \\sum_{i = 1}^{k} g_i(Y) \\right] = \\sum_{i=1}^k \\mathbb{E}\\left[ g_i(Y) \\right]\\)\n\n\nProof. \\[\n\\mathbb{E}[c] = \\sum_y cp(y) = c \\sum_y p(y) = c \\cdot (1) = c\n\\]\n\n\nProof. \\[\\begin{align*}\n\\mathbb{E}\\left[ cg(Y) \\right] & = \\sum_y cg(y) p(y) \\\\\n& = c \\sum_y g(y) p(y) \\\\\n& = c \\mathbb{E}\\left[ g(Y) \\right] \\\\\n\\end{align*}\\]\n\n\nProof. \\[\n\\mathbb{E} \\left[ \\sum_{i=1}^k g_i(Y) \\right] = \\sum_y \\left( \\sum_{i=1}^k g_i(Y) \\right) p(y) = \\sum_{i=1}^k \\sum_y \\left( g_i(Y) p(Y) \\right) = \\sum_{i=1}^k \\mathbb{E}\\left[g_i(Y)\\right]\n\\]\n\n\n\n\n\nThe \\(k\\)-th raw moment of \\(Y\\) is \\(\\mu_k' = \\mathbb{E}\\left[Y^k\\right]\\)\nThe \\(k\\)-th central moment of \\(Y\\) is \\(\\mu_k = \\mathbb{E} \\left[ (Y - \\mu)^k \\right]\\)\nThe variance of \\(Y\\) is \\(\\text{Var}(Y) = \\sigma^2 = \\mu_2 = \\mathbb{E}\\left[ (Y - \\mu)^2 \\right]\\)\nThe standard deviation of \\(Y\\) is simply the square root of variance.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#variance",
    "href": "contents/chapter-03/2measures.html#variance",
    "title": "Measures Related to Distribution",
    "section": "2 Variance",
    "text": "2 Variance\nAs defined above, this is nothing more than just the second order central moment. However, we don‚Äôt always need to compute the variance from scratch. Most of the times, the following two theorems aid in finding the variance.\n\n2.1 Two Important Results\n\n\\(\\text{Var}(Y) = \\mathbb{E}\\left[ Y^2 \\right] - \\left(\\mathbb{E}[Y]\\right)^2\\)\n\\(\\text{Var}(a + bY) = b^2 \\text{Var}(Y)\\)\n\n\nProof. 1:\n\\[\nVar(Y) = E((Y - \\mu)^2) = E(Y^2) - 2\\mu E(Y) + \\mu^2 = E(Y^2) - \\mu^2\n\\]\n2:\n\\[\nVar(a + bY) = E((a + bY - E(a+ bY))^2) = E(b^2(Y - E(Y))^2) = b^2E((Y - \\mu)^2) = b^2 Var(Y)\n\\]",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#moment-generating-functions",
    "href": "contents/chapter-03/2measures.html#moment-generating-functions",
    "title": "Measures Related to Distribution",
    "section": "3 Moment Generating Functions",
    "text": "3 Moment Generating Functions\nThe moment generating function (mgf) of a random variable \\(Y\\) is defined to be\n\\[\nm(t) = E(e^{tY})\n\\]\n\n3.1 Two Important Application of MGF\n\nto compute raw moments, according to the formula: \\[\n\\mu_k' = m^{(k)}(0)\n\\]\nTo uniquely identify distributions.\n\n\nProof. 1:\n\\[\\begin{align*}\nm^{(k)}(t) & = \\frac{d^k}{dt^k} E(e^{Yt}) \\\\\n& = \\frac{d^k}{dt^k} \\left( \\sum_y e^{yt} p(y) \\right) \\\\\n& = \\sum_y y^k e^{(yt)} p(y) \\\\\n\\end{align*}\\]\nThen, evaluating the above at \\(t = 0\\) indicates, \\[\nm^{(k)}(0) = \\sum_y y^k e^0 p(y) = E(Y^k) = \\mu_k'\n\\]\n\nNote that proof of 2. is actually much harder than I expected so the proof is skipped. For interested reader, refer to this.\n\n\nExample 3 Use the mgf technique to find the mean and variance of the binomial distribution.\nLet \\(Y \\sim \\text{Bin}(n, p)\\). Then \\(Y\\) has mgf,\n\\[\\begin{align*}\nm(t) & = E(e^{Yt}) \\\\\n& = \\sum_{y = 0}^n e^{yt} \\binom{n}{y} p^y (1 - p)^{n-y} \\\\\n& = \\sum_{y = 0}^n \\binom{n}{y} (pe^t) (1 - p)^{n - y} \\\\\n& = \\left( (pe^t) + (1 - p) \\right) ^n \\tag{By the binomial theorem.}\n\\end{align*}\\]\nThus, \\(m(t) = (1 - p + pe^t)^n\\).\nThen, \\(m'(t) = \\frac{dm(t)}{dt} = n(1 - p + pe^t)^{n-1}pe^t\\). Then, \\(m''(t) = n(1 - p + pe^t)pe^t + n(n-1)(1 - p + pe^t)^{n-2}p^2e^2t\\). Hence,\n\\[\\begin{align*}\nE(Y) = m'(0) = n (1 - p + p)^{n-1} p e^0 = np \\\\\nm''(0) = np + n(n-1)p^2 \\\\\nVar(Y) = m''(0) - (m'(0))^2 = np + n(n-1)p^2 - (np)^2 = np - np^2 = np(1-p) \\\\\n\\end{align*}\\]\nThis is the same result as we have derived before.\n\n\n\nExample 4 A random variable \\(Y\\) has the mgf \\(m(t) = \\frac{1}{8}(1 + e^t)^3\\). Find the probability that \\(Y\\) equals three.\n\\[\nm(t) = (1 - \\frac{1}{2} + \\frac{1}{2}e^t)^3 = (1 - p + pe^t)^n, \\quad \\text{where $n = 3$ and $p = 1/2$}\n\\]\nThus \\(m(t)\\) is the mgf of a random variable whose distribution is binomial with parameters 3 and \\(1/2\\). Therefore \\(Y \\sim \\text{Bin}(3, 1/2)\\), and so \\(P(Y = 3) = 1/8\\).\n\n\n\n\n\n\n\nSome of my takeaway\n\n\n\nI think it is somewhat important to recognise the known mgf form and transform it whenever a similar question is give in the exam.\n\n\n\n\nTheorem 2 Suppose \\(Y_1, Y_2, \\ldots, Y_n\\) are independent and \\(Y = \\sum_i Y_i\\). Then,\n\\[\nm_Y(t) = m_{Y_1 + Y_2 + \\cdots + Y_n} (t)\n\\]",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#tchebysheffs-theorem-or-chebyshevs-theorem",
    "href": "contents/chapter-03/2measures.html#tchebysheffs-theorem-or-chebyshevs-theorem",
    "title": "Measures Related to Distribution",
    "section": "4 Tchebysheff‚Äôs theorem (or Chebyshev‚Äôs theorem)",
    "text": "4 Tchebysheff‚Äôs theorem (or Chebyshev‚Äôs theorem)\n\nTheorem 3 Let \\(Y\\) be a rv with mean \\(\\mu\\) and variance \\(\\sigma^2\\) (assumed to be finite). Also, let \\(k\\) be a positive constant. Then \\[\nP(\\lVert Y - \\mu \\rVert &lt; k\\sigma) \\geq 1 - \\frac{1}{k^2}\n\\]\nEquivalently,\n\\[\nP(\\lVert Y - \\mu \\rVert \\geq k\\sigma) \\leq \\frac{1}{k^2}\n\\]\n\n\nProof. \\[\\begin{align*}\n\\sigma^2 = E((Y - \\mu)^2) & = \\sum_y (y - \\mu)^2 p(y) \\\\\n7 = \\sum_{y: \\lvert y -\\mu \\rvert &lt; k\\sigma} (y - \\mu)^2 p(y) + \\sum_{y: \\lvert y - \\mu \\rvert \\geq k\\sigma} (y-\\mu)^2p(y) \\\\\n& \\geq \\sum_{y: \\lvert y - \\mu \\rvert &lt; k\\sigma} 0 p(y) + \\sum_{y: \\lvert y - \\mu \\rvert \\geq k\\sigma} (k\\sigma)^2 p(y) \\\\\n& = 0 + k^2 \\sigma^2 \\sum_{y: \\lvert y - \\mu \\rvert \\geq k\\sigma} p(y) \\\\\n& = k^2 \\sigma^2 P(\\lvert Y - \\mu \\rvert \\geq k\\sigma) \\\\\n\\end{align*}\\]\nHence, by rearranging,\n\\[\nP\\left(\\lvert Y - \\mu \\rvert \\geq k\\sigma\\right) \\leq \\frac{1}{k^2}\n\\]",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#mode-and-median",
    "href": "contents/chapter-03/2measures.html#mode-and-median",
    "title": "Measures Related to Distribution",
    "section": "5 Mode and Median",
    "text": "5 Mode and Median\n\n5.1 Model\nThe mode of a rv \\(Y\\) is any value \\(y\\) at which \\(Y\\)‚Äôs pmg, \\(p(y)\\) is a maximum.\nIt is possible to have multiple modes, and the mode may then also b defined as the set of all such modes.\n\n\n5.2 Median\nThe median of a rv \\(Y\\) is any value \\(y\\) such that \\[\nP(X \\leq Y) \\geq \\frac{1}{2} \\qquad \\text{and} \\qquad P(Y \\geq y) \\geq \\frac{1}{2}\n\\]\nThere may be more than one median, and the median may then also be defined as the set of all such medians.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#some-central-interpretations-of-central-tendency-measure",
    "href": "contents/chapter-03/2measures.html#some-central-interpretations-of-central-tendency-measure",
    "title": "Measures Related to Distribution",
    "section": "6 Some Central Interpretations of Central Tendency Measure",
    "text": "6 Some Central Interpretations of Central Tendency Measure\n\n\n\n\n\n\n\nmean\naverage of a very large number of independent realisations of \\(Y\\)\n\n\nmedian\n‚Äúmiddle value‚Äù, such that \\(Y\\) is at least 50% likely to be above the value and at least 50% likely to be below it.\n\n\nmode\nmost likely value of \\(Y\\)",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V.",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/index.html",
    "href": "contents/chapter-03/index.html",
    "title": "Discrete R.V.",
    "section": "",
    "text": "Definition 1 A random variable (rv) is a numerical variable whose value depends on the outcome of an experiment.\n\nA random variable must be a number; it cannot be a letter, say. More precisely, a random variable is a ‚Äúreal-valued function for which the domain is a sample space‚Äù.\n\nExample 1 A coin is tossed twice and the sequence of \\(H\\)‚Äôs and \\(T\\)‚Äôs is observed. Let \\(Y\\) be the number of \\(H\\)‚Äôs which come up. Show that \\(Y\\) is a random variable. The experiment here has 4 possible outcomes: \\(TT\\), \\(TH\\), \\(HT\\), \\(HH\\).\n\\(Y = 0\\) if the outcome is \\(TT\\)\n\\(Y = 1\\) if the outcome is \\(TH\\) or \\(HT\\)\n\\(Y = 2\\) if the outcome is \\(HH\\)\n\n\n\nThe probability that a discrete random variable \\(Y\\) takes on a particular value \\(y\\) is the sum of the probabilities of all sample points in the sample space \\(S\\) that are associated with \\(y\\).\nWe write this probability \\(P(Y = y)\\).\nThe probability distribution of a discrete random variable \\(Y\\) is any information which provides \\(P(Y = y)\\) for each possible value \\(y\\) of \\(Y\\). This information may take the form of a list, table function (formula) or graph.\n\n\n\nIt is conventional to denote rv‚Äôs by upper case letters (e.g., \\(Y\\), \\(X\\), \\(U\\)) and possible values of those rv‚Äôs by the corrsponding lower case letters (e.g., \\(y\\), \\(x\\), \\(u\\)).\n\\(P(Y = y)\\) is called the probability mass function (pmf) of \\(Y\\) and is often written \\(p(y)\\) or \\(p_Y(y)\\).\n\n\n\n\\(0 \\leq p(y) \\leq 1\\) for all \\(y\\)\n\\(\\sum_y p(y) = 1\\)\n\n\n\nExample 2 A coin is repeatedly tossed until the first head comes up. Let \\(Y\\) be the number of tosses. Derive the pmf of \\(Y\\), and check that it satisfies the two properties of discrete pmf‚Äôs.\nThen \\(Y\\) has pmf, \\[\np(y) = \\left( \\frac{1}{2} \\right)^y\n\\]\nWe should also observe that Property 1 is satisfied, since 1/2, 1/4, 1/8, ‚Ä¶ are all between o and 1. Also,\n\\[\n\\sum_y p(y) = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\cdots = 1\n\\]\nThus Property 2 is also satisfied.\n\\(Y\\) is a discrete rv in this example because \\(\\{1,2,3,\\ldots\\}\\) is a countably infinite set (its elements can be listed). A pmf uniquely defines a rv or pr dsn. Thus a rv can t have 2 or more different pmf‚Äôs. Note that not all functions are valid pmf‚Äôs.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V."
    ]
  },
  {
    "objectID": "contents/chapter-03/index.html#random-variable",
    "href": "contents/chapter-03/index.html#random-variable",
    "title": "Discrete R.V.",
    "section": "",
    "text": "Definition 1 A random variable (rv) is a numerical variable whose value depends on the outcome of an experiment.\n\nA random variable must be a number; it cannot be a letter, say. More precisely, a random variable is a ‚Äúreal-valued function for which the domain is a sample space‚Äù.\n\nExample 1 A coin is tossed twice and the sequence of \\(H\\)‚Äôs and \\(T\\)‚Äôs is observed. Let \\(Y\\) be the number of \\(H\\)‚Äôs which come up. Show that \\(Y\\) is a random variable. The experiment here has 4 possible outcomes: \\(TT\\), \\(TH\\), \\(HT\\), \\(HH\\).\n\\(Y = 0\\) if the outcome is \\(TT\\)\n\\(Y = 1\\) if the outcome is \\(TH\\) or \\(HT\\)\n\\(Y = 2\\) if the outcome is \\(HH\\)\n\n\n\nThe probability that a discrete random variable \\(Y\\) takes on a particular value \\(y\\) is the sum of the probabilities of all sample points in the sample space \\(S\\) that are associated with \\(y\\).\nWe write this probability \\(P(Y = y)\\).\nThe probability distribution of a discrete random variable \\(Y\\) is any information which provides \\(P(Y = y)\\) for each possible value \\(y\\) of \\(Y\\). This information may take the form of a list, table function (formula) or graph.\n\n\n\nIt is conventional to denote rv‚Äôs by upper case letters (e.g., \\(Y\\), \\(X\\), \\(U\\)) and possible values of those rv‚Äôs by the corrsponding lower case letters (e.g., \\(y\\), \\(x\\), \\(u\\)).\n\\(P(Y = y)\\) is called the probability mass function (pmf) of \\(Y\\) and is often written \\(p(y)\\) or \\(p_Y(y)\\).\n\n\n\n\\(0 \\leq p(y) \\leq 1\\) for all \\(y\\)\n\\(\\sum_y p(y) = 1\\)\n\n\n\nExample 2 A coin is repeatedly tossed until the first head comes up. Let \\(Y\\) be the number of tosses. Derive the pmf of \\(Y\\), and check that it satisfies the two properties of discrete pmf‚Äôs.\nThen \\(Y\\) has pmf, \\[\np(y) = \\left( \\frac{1}{2} \\right)^y\n\\]\nWe should also observe that Property 1 is satisfied, since 1/2, 1/4, 1/8, ‚Ä¶ are all between o and 1. Also,\n\\[\n\\sum_y p(y) = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\cdots = 1\n\\]\nThus Property 2 is also satisfied.\n\\(Y\\) is a discrete rv in this example because \\(\\{1,2,3,\\ldots\\}\\) is a countably infinite set (its elements can be listed). A pmf uniquely defines a rv or pr dsn. Thus a rv can t have 2 or more different pmf‚Äôs. Note that not all functions are valid pmf‚Äôs.",
    "crumbs": [
      "Home",
      "CH03 : Discrete R.V."
    ]
  },
  {
    "objectID": "contents/chapter-05/index.html",
    "href": "contents/chapter-05/index.html",
    "title": "Multivariate Distributions",
    "section": "",
    "text": "More than one random variable\nJoint PMF/PDF or CDF\nBoth Discrete and Continuous\nExpectations, Variance, etc.",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-05/index.html#learning-goals",
    "href": "contents/chapter-05/index.html#learning-goals",
    "title": "Multivariate Distributions",
    "section": "",
    "text": "More than one random variable\nJoint PMF/PDF or CDF\nBoth Discrete and Continuous\nExpectations, Variance, etc.",
    "crumbs": [
      "Home",
      "CH05 : Multivariate Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html",
    "href": "contents/chapter-04/2measures.html",
    "title": "Expectations",
    "section": "",
    "text": "As foreshadowed in previous discrete section, it is natural to believe that most of the results can be directly imported. (Otherwise, we wouldn‚Äôt have spend so much time.)",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html#expectations",
    "href": "contents/chapter-04/2measures.html#expectations",
    "title": "Expectations",
    "section": "1 Expectations",
    "text": "1 Expectations\nBasically, all the definition regarding expectation in Chapter 3 hold here also, excpet that sums need to be replaced by integrals and the pmf \\(p(y)\\) is replaced by the pdf \\(f(y)\\).\n\nDefinition 1 If \\(Y\\) is a continuous random variable with pdf \\(f(y)\\), and \\(g(t)\\) is a real-valued function, then the expected value of \\(g(Y)\\) is \\[\nE(g(Y)) = \\int_{-\\infty}^{\\infty} g(y) f(y) \\, dy\n\\]\n\n\n1.1 Results\n\nI will try my best to include all the proofs for the results here. However, these proofs are done by me likely to contain relatively high amounts of mistakes.\n\n\nTheorem 1 (Three Properties) For \\(c \\in \\mathbb{R}\\), and \\(Y\\) continuous r.v.\n\n\\(E(c) = c\\)\n\\(E(cg(Y)) = cE(g(Y))\\)\n\\(E(g_1(Y) + \\cdots + g_k(Y)) = \\sum_{i=1}^k E(g_i(Y))\\)\n\n\n\nProof. \n\n\n\n\\[\\begin{align*}\nE(c) &= \\int_{-\\infty}^\\infty c f(y) \\, dy \\\\\n&= c \\int_{-\\infty}^\\infty f(y) \\, dy \\\\\n&= c\n\\end{align*}\\]\nThe last step is a result of the fact that the pdf also integrate to 1 by definition.\n\n\nProof. \n\n\n\n\\[\\begin{align*}\nE(cg(Y)) &= \\int_{-\\infty}^\\infty c g(y) f(y) \\, dy \\\\\n&= c \\int_{-\\infty}^\\infty g(y)f(y) \\, dy \\\\\n&= c E(g(Y))\n\\end{align*}\\]\n\n\nProof. \n\n\n\n\\[\\begin{align*}\nE(\\sum_{i=1}^k g_i(Y)) &= \\int_{-\\infty}^\\infty \\left( \\sum_{i=1}^k g_i(y) f(y) \\right) \\, dy \\\\\n&= \\sum_{i = 1}^k \\left( \\int_{-\\infty}^\\infty g_i(y) f(y) \\, dy \\right) \\\\\n& = \\sum_{i=1}^k E(g_i(Y)) \\\\\n\\end{align*}\\]\nThe second line is by linearity of the integration operation.\n\n\nAs I have mentioned when we were proving the discrete version of the Chebyshev‚Äôs Theorem, there is a continuous version that is exactly the same. Now, here is the statement and the proof.\n\nTheorem 2 (Continuous Version of Chebyshev‚Äôs) If \\(Y\\) is continuous r.v., then \\[\nP(\\lvert Y - \\mu \\rvert &lt; k\\sigma) \\geq 1 - 1 / k^2\n\\]\n\n\nProof. \\[\\begin{align*}\n\\sigma^2 & = \\int_{-\\infty}^\\infty (Y - \\mu)^2 f(y) \\, dy \\\\\n& = \\int_{-\\infty}^{k\\sigma - \\mu} (y - \\mu)^2f(y) \\, dy + \\int_{k\\sigma + \\mu}^\\infty (y - \\mu)^2 f(y) \\, dy \\\\\n& = \\int_{-\\infty}^{k\\sigma - \\mu} (k\\sigma)^2 f(y) \\, dy + \\int_{k\\sigma + \\mu}^\\infty (k\\sigma)^2 f(y) \\, dy \\\\\n& = (k\\sigma)^2 \\left( \\int_{-\\infty}^{k - \\mu} f(y) \\, dy + \\int_{k + \\mu}^\\infty f(y) \\, dy \\right) \\\\\n& = (k\\sigma)^2 P(Y \\leq k\\sigma - \\mu \\cup Y \\geq k\\sigma + \\mu) \\\\\n& = (k\\sigma)^2 P(\\lvert Y - \\mu \\rvert \\leq k\\sigma)\n\\end{align*}\\]\nTherefore,\n\\[\nP(\\lvert Y - \\mu \\rvert \\leq k\\sigma) \\leq 1 / k^2\n\\]\nTherefore, obtaining the following,\n\\[\nP\\left(\\lvert Y - \\mu \\rvert &gt; k \\sigma \\right) &gt; 1 - \\frac{1}{k^2}\n\\]\n\n\n\n\n1.2 Working Examples\n\nExample 1 Find the mean and variance of the standard uniform distribution\nSuppose that \\(Y \\sim U(0, 1)\\). Then \\(Y\\) has pdf \\(f(y) = 1\\), \\(0 &lt; y &lt; 1\\). Therefore, \\[\n\\mu = \\int_0^1 yf(y) dy = \\int_0^1 y 1 dy = \\left[ \\frac{y^2}{2} \\middle\\vert _{y=0}^1 \\right] = \\frac{1}{2}\n\\]\nAlso, \\[\n\\mu_2' = \\int_0^1 y^2 1 \\, dy = \\left[ \\frac{y^3}{3} \\middle\\vert _{y=0}^1 \\right] = \\frac{1}{3}\n\\]\nTherefore, \\[\n\\sigma^2 = \\frac{1}{3} \\left( \\frac{1}{2} \\right)^2 = \\frac{1}{12}\n\\]\nNote: We could use the mgf method here, but it is problematic in this case. This is because, \\[\nm(t) = \\frac{e^t - 1}{t} \\implies m'(t) = \\frac{e^t(t - 1) + 1}{t^2}\n\\] , which is undefined at \\(t = 0\\). So use L‚ÄôHopital‚Äôs rule (twice) to get \\[\n\\mu = \\lim_{t \\to 0} m'(t) = \\lim_{t \\to 0} \\frac{\\frac{d}{dt}(e^t(t-1) + 1)}{\\frac{d}{dt} t^2} = \\lim_{t \\to 0} \\frac{t e^t}{2t} = \\lim_{t \\to 0} \\frac{\\frac{d}{dt} (t e^t)}{\\frac{d}{dt} (2t)} = \\lim_{t \\to 0} \\frac{e^t(t+1)}{2} = \\frac{1}{2}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think the evaluation can be simpler by using the following\n\\[\n\\mu = \\lim_{t \\to 0} m'(t) = \\lim_{t \\to 0} \\frac{\\frac{d}{dt}(e^t(t-1) + 1)}{\\frac{d}{dt} t^2} = \\lim_{t \\to 0} \\frac{t e^t}{2t} = \\lim_{t \\to 0} \\frac{e^t}{2} = \\frac{1}{2}\n\\]\n\n\n\n\n\n\nExample 2 Find the mean and variance of the exponential distribution.\nIn this case the mgf method works well1.\nBy using the mgf of exponential distribution, we have \\[\nm'(t) = - (1 - bt)^{-2} (-b) = b(1 - bt)^{-2}\n\\]\nAnd \\[\nm''(t) = (-2) b(1-bt)^{-3} (-b) = 2b^2(1- bt)^{-3}\n\\]\nTherefore, \\(\\mu_1' = m'(0) = b\\) and \\(\\mu_2' = m''(0) = 2b^2\\). Hence, variance is \\(2b^2 - b^2 = b^2\\).\n\n\n\n\n\n\n\nAlternative Methods\n\n\n\nNote that it is possible to directly use integration by part to obtain the result, but it is clearly much more tedious.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html#appendix",
    "href": "contents/chapter-04/2measures.html#appendix",
    "title": "Expectations",
    "section": "2 Appendix",
    "text": "2 Appendix\n\nTheorem 3 (mgf of Gamma Distribution) Suppose \\(Y \\sim \\text{Gam}(\\alpha, \\beta)\\) for some \\(\\alpha, \\beta &gt; 0\\), then\n\\[\nm_Y(t) = \\begin{cases}\n\\left(1 - \\beta t \\right)^{-\\alpha} & t &lt; \\beta \\\\\n\\text{does not exist} & t &gt; \\beta \\\\\n\\end{cases}\n\\]\n\n\nProof. \\[\n\\begin{align}\nm_Y(t) = E(e^{Yt}) & = \\int_0^\\infty e^{ty} f_Y(y) \\, dy \\\\\n& = \\int_0^\\infty e^{yt} \\frac{y^{a-1}e^{-y/b}}{b^a \\Gamma(a)} \\, dy \\\\\n& = \\int_0^\\infty \\frac{1}{b^a \\Gamma(a)} y^{a - 1} e^{-(\\frac{1}{b} - t)y} \\, dy \\\\\n& = \\frac{\\left( \\frac{1}{b} - t\\right)^{-a}}{b^a} \\int_0^\\infty \\frac{y^{a-1}e^{-y\\left( \\frac{1}{b} - t\\right)^{-1}}}{\\left( \\frac{1}{b} - t\\right)^{-a} \\Gamma(a)} \\\\\n& = \\frac{b^a (1 - bt)^{-a}}{b^a} \\cdot 1 = (1 - bt)^{-a}\n\\end{align}\n\\]\nThe last line is derived by the fact that the integral in the second last line is simply the probability of a gamma distributed random variable having any value between \\(0\\) and \\(\\infty\\). Therefore, the integral is \\(1\\).\n\n\nTheorem 4 (mgf of Exponential Distribution) \\[\nm_X(t) = (1 - bt)^{-1}\n\\]\n\n\nProof. The proof is clear from the definition of exponential distribution and Theorem¬†3.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html#footnotes",
    "href": "contents/chapter-04/2measures.html#footnotes",
    "title": "Expectations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that we did not really find the mgf before. Therefore, refer to Theorem¬†4 for the proof.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V.",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html",
    "href": "contents/chapter-04/index.html",
    "title": "Continuous R.V.",
    "section": "",
    "text": "Note that we will follow a very similar structure as we have done in the chapter for discrete variable. And, indeed, a lot of the theorems can be directly transported to the continuous case. However, analysis of the continuous variables are slightly harder since, as one might expect, all the summation no becomes integral.\nThis chapter will first goes from the definition of continuous random variable with link established via the cumulative distribution functions. Then, we will go over some of the common continuous distributions.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V."
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html#preamble",
    "href": "contents/chapter-04/index.html#preamble",
    "title": "Continuous R.V.",
    "section": "",
    "text": "Note that we will follow a very similar structure as we have done in the chapter for discrete variable. And, indeed, a lot of the theorems can be directly transported to the continuous case. However, analysis of the continuous variables are slightly harder since, as one might expect, all the summation no becomes integral.\nThis chapter will first goes from the definition of continuous random variable with link established via the cumulative distribution functions. Then, we will go over some of the common continuous distributions.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V."
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html#cumulative-distribution",
    "href": "contents/chapter-04/index.html#cumulative-distribution",
    "title": "Continuous R.V.",
    "section": "2 Cumulative Distribution",
    "text": "2 Cumulative Distribution\n\nDefinition 1 The (cumulative) distribution function (cdf) of a random variable \\(Y\\) is \\[\nF(y) = P(Y \\leq y)\n\\]\n\n\nTheorem 1 if \\(F(y)\\) is a cdf then: 1. \\(F(y) \\to 0\\) as \\(y \\to - \\infty\\) 2. \\(F(y) \\to 1\\) as \\(y \\to \\infty\\) 3. \\(F(y)\\) is nondecreasing.\nNote that we assumes that \\(F(y)\\) is right continuous, meaning that \\(\\lim_{\\delta \\to 0} F(Y + \\delta) = F(y)\\).",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V."
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html#random-variable",
    "href": "contents/chapter-04/index.html#random-variable",
    "title": "Continuous R.V.",
    "section": "3 Random Variable",
    "text": "3 Random Variable\nArmed with cdf, we are now ready to define what continuous random variable is.\n\nDefinition 2 A random variable is said to be continuous if its cdf is continuous (everywhere).\n\n\n\nExample 1 Let \\(Y\\) be a number chosen randomly between 0 and 2. Find \\(Y\\)‚Äôs cdf. Is \\(Y\\) a continuous random variable.\n\\[\nF(y) = \\begin{cases}\n0 & y &lt; 0 \\\\\ny/2 & 0 \\leq y &lt; 2 \\\\\n1 & y \\geq 2\n\\end{cases}\n\\]\n\n\nShow the code\nlibrary(ggplot2)\n\ny &lt;- seq(-1, 3, length.out = 400)\nF &lt;- ifelse(y &lt; 0, 0, ifelse(y &lt; 2, y/2, 1))\n\ndf &lt;- data.frame(y = y, F = F)\n\nggplot(df, aes(x = y, y = F)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(x = expression(y), y = expression(F(y))) +\n  scale_x_continuous(breaks = c(0, 2)) +\n  scale_y_continuous(breaks = c(0, 1)) +\n  theme_minimal() +\n  theme(panel.grid.major = element_line(linetype = \"dashed\", color = \"grey80\"))\n\n\n\n\n\n\n\n\n\nObserve that \\(F(y)\\) is continuous everywhere (i.e.¬†for all \\(y\\) between \\(-\\infty\\) and \\(\\infty\\)). Hence \\(Y\\) is a continuous random variable.",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V."
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html#probability-density-function",
    "href": "contents/chapter-04/index.html#probability-density-function",
    "title": "Continuous R.V.",
    "section": "4 Probability Density Function",
    "text": "4 Probability Density Function\nNote that if \\(Y\\) is continuous, then \\(P(Y = y) = 0 \\; \\forall y\\). Therefore, we need to redefine something instead of the previously defined pmf as it is now useless.\n\nDefinition 3 Suppose that \\(Y\\) is continuous random variable with cdf \\(F(y)\\). Then \\(Y\\)‚Äôs probability density function is \\[\nf(y) = F'(y) = \\frac{dF(y)}{dy}\n\\]\n\n\n\nExample 2 Find \\(Y\\)‚Äôs pdf in Example¬†1.\n\n\nSolution. \\[\nf(y) = \\frac{dF(y)}{dy} = \\begin{cases}\n\\frac{d0}{dy} = 0, & y &lt; 0 \\\\\n\\frac{d(y/2)}{dy} = 1/2, & 0 &lt; y &lt; 2 \\\\\n\\frac{d1}{dy} = 0, & y &gt; 2 \\\\\n\\end{cases}\n\\]\n\n\nShow the code\nlibrary(ggplot2)\n\ny &lt;- seq(-1, 3, length.out = 400)\nf &lt;- ifelse(y &lt; 0, 0, ifelse(y &lt; 2, 0.5, 0))\n\ndf &lt;- data.frame(y = y, f = f)\n\nggplot(df, aes(x = y, y = f)) +\n  geom_line(color = \"blue\", linewidth = 1) +\n  labs(x = expression(y), y = expression(f(y))) +\n  scale_x_continuous(breaks = c(0, 2)) +\n  scale_y_continuous(breaks = c(0, 1)) +\n  theme_minimal() +\n  theme(panel.grid.major = element_line(linetype = \"dashed\", color = \"grey80\"))\n\n\n\n\n\n\n\n\n\nNote that \\(f(y)\\) is undefined at \\(y = 0, 2\\).\n\n\n4.1 Two Properties of a Continuous pdf\n\nTheorem 2 (Two Properties of a Continuous PDF) If \\(f(y)\\) is the pdf of a continuous random variable then:\n\n\\(f(y) \\geq 0\\) for all \\(y\\)\n\\(\\int f(y) \\, dy = 1\\) (By default, the integral is over the whole real line.)\n\n\n\n\n4.2 CDF from PDF\nIn general, the cdf \\(F(y)\\) of a continuous random variable \\(Y\\) can be obtained from its pdf \\(f(y)\\) via the equation\n\\[\nF(y) = \\int_{-\\infty}^{y} f(t) \\, dt\n\\]\n\n\n4.3 Computing Probability using PDF\nIn general, to compute the probability of a given range for a continuous random variable, we can use\n\\[\nP(a &lt; Y &lt; b) = \\int_a^b f(y) \\, dy\n\\]",
    "crumbs": [
      "Home",
      "CH04 : Continuous R.V."
    ]
  },
  {
    "objectID": "contents/chapter-08/5coverage-test.html",
    "href": "contents/chapter-08/5coverage-test.html",
    "title": "Coverage Test (Optional)",
    "section": "",
    "text": "Disclaimer: Taken from response by ChatGPT",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Coverage Test (Optional)"
    ]
  },
  {
    "objectID": "contents/chapter-08/5coverage-test.html#what-is-coverage-probability",
    "href": "contents/chapter-08/5coverage-test.html#what-is-coverage-probability",
    "title": "Coverage Test (Optional)",
    "section": "1 ‚úÖ What is Coverage Probability?",
    "text": "1 ‚úÖ What is Coverage Probability?\nThe coverage probability of a confidence interval method is:\nThe probability that the interval contains the true parameter value, over repeated samples.\nFor a \\(95%\\) confidence interval for a proportion \\(p\\), this means:\n\\[\n\\text{Coverage at } p = \\mathbb{P}_p\\left( \\text{CI contains } p \\right)\n\\]\nIt answers: ‚ÄúIf the true proportion is p, how often does the method capture it?‚Äù",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Coverage Test (Optional)"
    ]
  },
  {
    "objectID": "contents/chapter-08/5coverage-test.html#how-coverage-is-computed-for-binomial-ci",
    "href": "contents/chapter-08/5coverage-test.html#how-coverage-is-computed-for-binomial-ci",
    "title": "Coverage Test (Optional)",
    "section": "2 üéØ How Coverage is Computed (for Binomial CI)",
    "text": "2 üéØ How Coverage is Computed (for Binomial CI)\nWe assume:\n\n\\(Y \\sim \\text{Binomial}(n, p)\\)\nEach possible outcome \\(y = 0, 1, \\dots, n\\) has probability \\(\\binom{n}{y} p^y (1 - p)^{n - y}\\)\n\nWe calculate coverage for each \\(p\\) as:\n\\[\n\\text{Coverage}(p) = \\sum_{y=0}^{n} \\mathbb{P}(Y = y) \\cdot \\mathbf{1}\\left[ p \\in \\text{CI}(y) \\right]\n\\]\nWhere:\n\n\\(\\mathbf{1}[p \\in \\text{CI}(y)] = 1\\) if the interval contains \\(p\\), otherwise \\(0\\)\n\\(\\text{CI}(y)\\) is the confidence interval computed from \\(y\\)",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Coverage Test (Optional)"
    ]
  },
  {
    "objectID": "contents/chapter-08/5coverage-test.html#in-code-terms",
    "href": "contents/chapter-08/5coverage-test.html#in-code-terms",
    "title": "Coverage Test (Optional)",
    "section": "3 In Code Terms",
    "text": "3 In Code Terms\nFor each value of \\(p\\) in the grid:\n\nLoop through all \\(y = 0, 1, \\ldots, n\\)\nFor each \\(y\\):\n\nCompute \\(\\text{CI}(y)\\) using the chosen method (Wald, Wilson, etc.)\nCheck if \\(p \\in \\text{CI}(y)\\)\nWeight that check by the binomial probability \\(P(Y = y)\\)\n\n\nSum those weighted checks ‚Üí coverage probability at that \\(p\\)",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Coverage Test (Optional)"
    ]
  },
  {
    "objectID": "contents/chapter-08/5coverage-test.html#example-manually-say-n-3-p-0.2",
    "href": "contents/chapter-08/5coverage-test.html#example-manually-say-n-3-p-0.2",
    "title": "Coverage Test (Optional)",
    "section": "4 Example (manually, say n = 3, p = 0.2)",
    "text": "4 Example (manually, say n = 3, p = 0.2)\nLet‚Äôs say: - You compute CIs for each \\(y \\in \\{0, 1, 2, 3\\}\\) - You get: - CI(0): \\([0.00, 0.40]\\) - CI(1): \\([0.05, 0.60]\\) - CI(2): \\([0.30, 0.85]\\) - CI(3): \\([0.60, 1.00]\\)\nThen check:\n\nIs 0.2 in CI(0)? ‚úÖ\nIs 0.2 in CI(1)? ‚úÖ\nIs 0.2 in CI(2)? ‚ùå\nIs 0.2 in CI(3)? ‚ùå\n\nGet binomial probabilities:\n\n\\(P(Y = 0) = (1 - 0.2)^3 = 0.512\\)\n\\(P(Y = 1) = 3 \\cdot 0.2 \\cdot (0.8)^2 = 0.3844\\)\n\\(P(Y = 2) = 0.096\\)\n\\(P(Y = 3) = 0.008\\)\n\nThen: \\[\n\\text{Coverage at } p = 0.2 = 0.512 + 0.384 = 0.896\n\\]\n‚∏ª\n‚úÖ Why This Is Accurate\nThis is effectively a theoretical simulation: you compute the expected proportion of times the CI captures the true p using the binomial model ‚Äî without sampling.\nIt reflects exact coverage (not approximate), assuming:\n\nThe distribution of data is exactly binomial\nThe CI method is applied correctly for every possible \\(y\\)",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Coverage Test (Optional)"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html",
    "href": "contents/chapter-08/3interval-estimate.html",
    "title": "Interval Estimation",
    "section": "",
    "text": "There are times when a point estimate is not really helpful simply because it only provides one number. It does not provide any form of statistical confidence to how good the inference is. How wrong might it be if it were to deviate? Also, loosely speaking, the probability that we make a correct guess for the parameters, which would typically be continuous, is \\(0\\). Therefore, we may want an interval on the axis instead.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html#motivation",
    "href": "contents/chapter-08/3interval-estimate.html#motivation",
    "title": "Interval Estimation",
    "section": "",
    "text": "There are times when a point estimate is not really helpful simply because it only provides one number. It does not provide any form of statistical confidence to how good the inference is. How wrong might it be if it were to deviate? Also, loosely speaking, the probability that we make a correct guess for the parameters, which would typically be continuous, is \\(0\\). Therefore, we may want an interval on the axis instead.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html#interval-estimation-and-confidence-intervals",
    "href": "contents/chapter-08/3interval-estimate.html#interval-estimation-and-confidence-intervals",
    "title": "Interval Estimation",
    "section": "2 Interval Estimation and Confidence Intervals",
    "text": "2 Interval Estimation and Confidence Intervals\nConsider a sample \\(Y_1, Y_2, \\ldots, Y_n\\) from a probability distribution which depends on one parameter \\(\\theta\\) (which is fixed but unknown).\nNow, we want to find two function \\(g\\) and \\(h\\) such that \\[\\begin{gather}\nL = g(Y_1, Y_2, \\ldots , Y_n) \\nonumber \\\\\nU = h(Y_1, Y_2, \\ldots , Y_n) \\\\\n\\end{gather}\\] would satisfy the following probability statement1 \\[\\begin{equation}\nP(L \\leq \\theta \\leq U) = 1 - \\alpha\n\\end{equation}\\] Then, \\([L, U]\\) is a \\(100(1 - \\alpha)%\\) confidence interval (CI) for \\(\\theta\\) in which \\(L\\) and \\(U\\) are the lower and upper bound and \\(1 - \\alpha\\) is the coverage coefficient, of the CI.\n\n\nExample 1 (Confidence Interval for Continuous Uniform) Suppose that 6.2 is a number chosen randomly between \\(0\\) and \\(c\\). Find an \\(80\\%\\) confidence interval for \\(c\\).\n\nSolution:\nLet \\(Y \\sim U(0, c)\\). Then, \\(X = Y/c \\sim U(0, 1)\\) by applying the transformation method.\n\nDefinition 1 (Pivotal Quantity) Then, we call \\(X\\) a pivotal quantity. This means that \\(X\\) is a function of \\(Y\\) the observable random variables and \\(c\\), the estimand, whose distribution does not depend on \\(c\\).\nThis quantity is useful for finding the confidence interval.\n\nTherefore, for an \\(80\\%\\) confidence interval for \\(c\\), \\[\\begin{align*}\n0.8 = \\P{0.1 \\leq X \\leq 0.9} & = \\P{0.1 \\leq Y / c \\leq 0.9} \\\\\n& = \\P{10Y/9 \\leq c \\leq 10Y}\n\\end{align*}\\]\nSo \\([10Y/9, 10Y]\\) is an \\(80\\%\\) CI for \\(c\\).\nNow, since the realised value of \\(Y\\) is \\(y = 6.2\\), we have an interval estimation being \\([6.82, 62]\\).\n\nNote that the term ‚Äòconfidence interval‚Äô refers to both \\([10Y/9 , 10Y]\\) and \\([10y / 9, 10y]\\); the former is a random variable and the latter is the realised value of that random variable.\nWe should also note that whether to include the endpoint, even though does not matter for the current case as \\(X\\) is continuous, it can be important in some cases.\n\n\n\n\n\n\nNote¬†1: A smart Alternative to Example¬†1\n\n\n\n\n\n\nSolution. First, notice that in order to obtain the center \\(80\\%\\) of \\(U(0, c)\\), we need the center \\(80\\%\\) of the sample space of the distribution, which is \\([0, c]\\). Therefore, with some attention, such interval in the probability statement would then be \\[\\begin{equation*}\n\\P{0.1c \\leq Y \\leq 0.9c} = 0.8\n\\end{equation*}\\] Then, the following follows.\n\n\n\n\n\n2.1 Interpretation of CI\n\nCan we really say that \\(c\\) lies between \\(6.89\\) and \\(62\\) with probability \\(80\\%\\)?\n\nNo. The event ‚Äú6.89 &lt; c &lt; 62‚Äù does not involve any random variables. It is either true or false, and so its probability must be either \\(1\\) or \\(0\\), respectively, and not \\(0.8\\). Thus the statement \\(\\P{6.89 &lt; c &lt; 62} = 0.8\\) is wrong.\nThe way to interpret ‚Äò\\(80\\%\\) confident‚Äô is as follows. If we were to sample another number, e.g.¬†\\(5.4\\) from the same \\(U(0, c)\\) distribution, then we‚Äôd get another CI, e.g.¬†\\((10(5.4)/9, 10(5.4)) = (6, 54)\\). Now imagine sampling very many such numbers, so as to get the same number of corresponding CIs, e.g.¬†\\((6.89, 62)\\), \\((6, 54)\\), \\((8.89, 80)\\), \\(\\ldots\\). Then close to \\(80\\%\\) of these CIs will contain \\(c\\). This is an expression of the fact that \\(\\P{10Y/9 &lt; c &lt; 10Y} = 0.8\\). But for any particular value \\(y\\) of \\(Y\\), we should never write \\(\\P{10y/9 &lt; 10y} = 0.8\\).\n\n\n2.2 Upper and Lower Range CIs\nThe \\(80\\%\\) CI derived above, \\((10Y/9, 10Y)\\), may also be called a central CI. It is also possible to construct other types of CI. Three major types are defined as follows\nLet \\(I = [L, U] = [g(Y_1, Y_2, \\ldots , Y_n), h(Y_1, Y_2, \\ldots , Y_n)]\\) be a \\(100(1 - \\alpha)\\%\\) confidence interval for \\(\\theta\\). Thus \\(P(L \\leq \\theta \\leq U) = 1 - \\alpha\\) for all \\(\\theta\\).\n\n2.2.1 Upper Range Confidence Interval\nWe say that \\(I\\) is an upper range confidence interval if \\[\\begin{equation}\n\\P{\\theta \\geq L} = 1 - \\alpha \\hspace{10pt} (= \\P{L \\leq \\theta} = \\P{L \\leq \\theta \\leq \\infty})\n\\end{equation}\\]\nThen \\(\\P{\\theta &lt; L} = \\alpha\\), \\(U = \\infty\\) and we call \\(L\\) the \\(1 - \\alpha\\) lower confidence limit for \\(\\theta\\).\n\n\n2.2.2 Lower Range Confidence Interval\nWe say that \\(I\\) is a lower range confidence interval if \\[\\begin{equation}\n\\P{\\theta \\leq L} = 1 - \\alpha \\hspace{10pt} (= \\P{L \\geq \\theta} = \\P{- \\infty \\leq \\theta \\leq U})\n\\end{equation}\\]\nThen \\(\\P{\\theta &gt; U} = \\alpha\\), \\(L = -\\infty\\) and we call \\(U\\) the \\(1 - \\alpha\\) upper confidence limit for \\(\\theta\\).\n\n\n2.2.3 Central Confidence Interval\nWe say that \\(I\\) is a central confidence interval if \\[\\begin{equation}\n\\P{\\theta &lt; L} = \\P{\\theta &gt; U} = \\alpha / 2\n\\end{equation}\\]\n\n\nExample 2 Check that \\([10Y/9, 10Y]\\) is central \\(80\\%\\) CI for \\(c\\).\n\nSolution. \\[\\begin{gather*}\n\\P{\\theta &lt; L} = \\P{c &lt; 10Y/9} = \\P{Y &gt; 0.9c} = 0.1 = \\alpha / 2 \\\\\n\\P{\\theta &gt; U} = \\P{c &gt; 10Y} = \\P{Y &lt; 0.1c} = 0.1 = \\alpha / 2 \\\\\n\\end{gather*}\\]\n\n\n\n\nExample 3 (Example 5) Now, we know that Example¬†2 is the central confidence interval. Therefore, if we can also ask the question about lower and upper confidence interval.\n\nSolution. \\[\\begin{equation*}\n0.8 = \\P{X \\leq 0.8} = \\P{Y/c \\leq 0.8} = \\P{5Y / 4 \\leq c}\n\\end{equation*}\\]\nSo \\(L = 5Y / 4\\), with realised value \\(5(6.2) / 4 = 7.75\\). So an upper range \\(80\\%\\) CI for \\(c\\) is \\([7.75, \\infty)\\).\n\n\n\n\nWhat is a lower range \\(80\\%\\) CI for \\(c\\)?\n\\[\\begin{equation*}\n0.8 = \\P{X \\geq 0.2} = \\P{Y/c \\geq 0.2} = \\P{c \\leq 5Y}\n\\end{equation*}\\]\nSo \\(U = 5Y\\), with realised value \\(5(6.2) = 31\\). So a lower range \\(80\\%\\) CI for \\(c\\) is \\((-\\infty, 31]\\).\n\n\n\n\nHowever, we can actually refine the lower and upper confidence interval‚Ä¶\n\nFirst, observe that \\(c\\) cannot be negative. So a lower range \\(80\\%\\) CI for \\(c\\) is \\([0, 31]\\). Secondly, we also know that \\(0 \\leq y \\leq c\\), and therefore \\(c \\geq y = 6.2\\). So a lower range \\(80\\%\\) CI for \\(c\\) is \\([6.2, 31]\\).\n\nLower range \\(80\\%\\) CI \\(= [6.2, 31]\\)\nUpper range \\(80\\%\\) CI \\(= [7.75, \\infty)\\)\nCentral \\(80\\%\\) CI \\(= [6.89, 62]\\)\n\nNote that the lower range CI is the shortest of the three. This is an attractive property, and sometimes we may choose one CI formula over another because it leads to a shorter CI on average. However, in some cases (not considered here), choosing the shortest of two or more CIs only after observing the data (as is sometimes done) may cause the confidence conefficient to be altered so that it is no longer the nominal \\(1-\\alpha\\).\n\n\n\n\n\n\n\n\nExample 4\n\n\n\n\n\n\nExample 4 Suppose that \\(1.2\\), \\(3.9\\) and \\(2.4\\) are a random sample from a normal distribution with variance \\(7\\). Find a \\(95\\%\\) confidence interval for the normal mean.\n\n\nSolution. We cannot rely on the intelligence of finding a smart alternative as Note¬†1.\nLet \\(Y_1, Y_2, \\ldots , Y_n \\sim^\\iid \\NormalDist(\\mu, \\sigma^2)\\). Let‚Äôs find a \\(100(1 - \\alpha)\\%\\) CI for \\(\\mu\\) generally. Recall that \\(Z = \\frac{\\mean{Y} - \\mu}{\\sigma / \\sqrt{n}} \\sim \\NormalDist(0, 1)\\). Therefore, \\(Z\\) is a pivotal quantity, \\[\\begin{align*}\n1 - \\alpha & = \\P{-z_{\\alpha/2} &lt; Z &lt; z_{\\alpha/2}} \\\\\n& = \\P{-z_{\\alpha/2} &lt; \\frac{\\mean{Y} - \\mu}{\\sigma / \\sqrt{n}} &lt; z_{\\alpha/2}} \\\\\n& = \\P{-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} &lt; \\mean{Y} - \\mu &lt; z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}} \\\\\n& = \\P{\\mean{Y}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} &lt; \\mu &lt; \\mean{Y} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}} \\\\\n\\end{align*}\\]\nSo a \\(100(1 - \\alpha)\\%\\) CI for \\(\\mu\\) is \\((\\mean{Y} - z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} , \\mean{Y} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}})\\). This interval may also be written \\(\\mean{Y} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\).\nIn our case: \\(100(1 - \\alpha) = 95 \\to \\alpha = 0.05\\). Therefore \\(z_{\\alpha/2} = z_{0.025} = 1.96\\)\n\\(n = 3\\)\n\\(\\mean{y} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\frac{1}{3}(1.2 + 3.9 + 2.4) = 2.5\\)\n\\(\\sigma^2 = 7\\)\nSo the \\(95\\%\\) CI for \\(\\mu\\) is \\[\\begin{equation*}\n(\\mean{y} \\pm z_{\\alpha / 2}\\frac{\\sigma}{\\sqrt{n}}) = \\left(2.5 \\pm 1.96 \\frac{\\sqrt{7}}{\\sqrt{3}}\\right) = (2.5 \\pm 3.0) = (-0.5, 5.5)\n\\end{equation*}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nExample 7\n\n\n\n\n\n\nExample 5 Suppose the same sample with Example¬†4 but unknown variance. Find a \\(95\\%\\) confidence interval for the normal mean.\n\n\nSolution. Let \\(Y_1, Y_2, \\ldots ,Y_n \\sim^\\iid \\NormalDist(\\mu , \\sigma^2)\\). Recall that \\[\\begin{equation}\nT = \\frac{\\mean{Y} - \\mu}{S / \\sqrt{n}} \\sim t(n-1)\n\\end{equation}\\] with \\(T\\) being the pivotal quantity.\nTherefore, \\[\\begin{align*}\n1 - \\alpha & = \\P{-t &lt; T &lt; t} \\tag{where $t = t_{\\alpha/2}(n - 1)$} \\\\\n&= \\P{ -t &lt; \\frac{\\mean{Y} - \\mu}{S / \\sqrt{n}} &lt; t } \\\\\n&= \\P{ \\mean{Y} - t\\frac{S}{\\sqrt{n}} &lt; \\mu &lt; \\mean{Y} + t\\frac{S}{\\sqrt{n}} } \\\\\n\\end{align*}\\]\nSo a \\(100(1-\\alpha)\\%\\) CI for \\(\\mu\\) is \\(\\left( \\mean{Y} \\pm t_{\\alpha/2}\\!(n-1) \\frac{S}{\\sqrt{n}} \\right)\\)\nWith some algebraic calculation we have, the \\(95\\%\\) CI is \\[\\begin{gather*}\n100(1 - \\alpha) = 95 \\implies \\alpha = 0.05, \\, n = 3 \\\\\nt_{\\alpha / 2}(n - 1) = t_{0.025}(2) = 4.303 \\\\\n\\mean{y} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\frac{1}{3} (1.2 + 3.9 + 2.4) = 2.5 \\\\\ns^2 = \\frac{1}{n-1} \\left( \\sum_i y_i^2 - 3 * (\\mean{y})^2 \\right) = 1.83 \\\\\n\\end{gather*}\\] So the \\(95\\%\\) CI for \\(\\mu\\) is \\((-0.86k 5.86)\\).\n\n\n\nNote that the interval for Example¬†5 is wider than the CI in Example¬†3, \\((-0.5, 5.5)\\). This corresponds to the fact that \\(\\sigma\\) is now unknown and effectively needs to be estimated from the sample, by \\(s\\). This illustrates the fact that when information is decreased, CI‚Äôs tend to become wider (which makes sense because there is greater uncertainty). However, this is not always the case, and sometimes a decrease in information can, by change, lead to an interval (with the same confidence coefficient) which much narrower.\n\n\n\n\n\n\n\n\n\n\nApproximation with Sample Variance\n\n\n\n\n\n\nExample 6 200 people were randomly sampled from the population of Australia, and their heights were measured. The sample mean was 1.673 and the sample standard deviation was 0.310.\nFind a \\(95\\%\\) confidence interval for the average height of all Australian.\n\nFirst, in summary of the above, we know,\n\n\\(Y_i \\iid (\\mu, \\sigma^2)\\) where \\(\\mu\\) and \\(\\sigma\\) unknown\n\\(\\mean{Y} = 1.673\\)\n\\(S = 0.310\\)\n\n\nSolution. Let \\(Y_i\\) be the \\(i\\)th height and assume that \\(Y_1, Y_2, \\ldots , Y_n \\sim^\\iid (\\mu, \\sigma^2)\\). Now, by central limit theorem, \\(\\frac{\\mean{Y} - \\mu}{\\sigma / \\sqrt{n}} \\approx \\NormalDist(0, 1)\\) as \\(n = 200\\) is large. But \\(\\sigma\\) is unknown, and so we cannot make use of this pivotal quantity.\nHowever, recall that the \\(t = \\frac{\\mean{Y} - \\mu}{S / \\sqrt{n} \\sim t(n-1) \\dconv \\NormalDist(0, 1)}\\). This idea will be more thoroughly explore in Chapter 9. For now, we can approximate with \\[\\begin{equation*}\nZ = \\frac{\\mean{Y} - \\mu}{S / \\sqrt{n}} \\approx \\NormalDist(0, 1)\n\\end{equation*}\\] also. Using the same logic as in the last few examples, we find that \\(100(1 - \\alpha)\\%\\) CI for \\(\\mu\\) is \\(\\left(\\mean{Y} \\pm z_{\\alpha / 2} \\frac{S}{\\sqrt{n}}\\right)\\), which in our case is \\((1.630, 1.716)\\).\nNote that this is only an approximate CI. However, the closeness of the approximation will be very good if \\(n\\) is large. Also, we would definitely replace \\(S\\) with \\(\\sigma\\) if the population standard deviation is known.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html#discrete-cases",
    "href": "contents/chapter-08/3interval-estimate.html#discrete-cases",
    "title": "Interval Estimation",
    "section": "3 Discrete Cases",
    "text": "3 Discrete Cases\n\n\n\n\n\n\nMotivating Example towards Wilson CI\n\n\n\n\n\n\nExample 7 Suppose that we toss a bent coin 100 times and get 72 heads. Find the 95% confidence interval for the probability of a head.\n\n\nSolution. Let \\(Y =\\) number of heads out of the \\(n = 100\\) tosses and \\(p =\\) probability of a head on a single toss.\nThen \\(Y \\sim \\Binomial(n, p)\\), with realised value \\(y = 72\\). Now \\(Y \\approx \\NormalDist(np, np(1 - p))\\) as a result of central limit theorem as \\(n = 100\\) is large. Therefore, applying standardisation, \\[\\begin{equation*}\n\\frac{Y - np}{\\sqrt{np(1-p)}} \\approx \\NormalDist(0, 1)\n\\end{equation*}\\]\n\\[\\begin{align*}\n1 - \\alpha &\\approx \\P{-z_{\\alpha / 2} &lt; \\frac{Y - np}{\\sqrt{np(1 - p)}} &lt; z_{\\alpha/2}} \\\\\n&\\approx \\P{-z_{\\alpha / 2} &lt; \\frac{Y - np}{\\sqrt{n\\hat{p}(1 - \\hat{p})}} &lt; z_{\\alpha/2}} \\\\\n&\\approx \\P{\\frac{Y}{n} - z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} &lt; p &lt; \\frac{Y}{n} + z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}} \\\\\n\\end{align*}\\]\nSo a \\(100(1 - \\alpha)\\%\\) CI for \\(p\\) is \\(\\left( \\hat{p} \\pm z_{\\alpha / 2}\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} \\right)\\).\nIN our case \\(\\hat{p} = y/n = 72/100 = 0.72\\), and so the required \\(95\\%\\) CI is \\(\\left( 0.72 \\pm 1.96\\sqrt{\\frac{0.72(1-0.72)}{100}} \\right) = (0.72 \\pm 0.09) = (0.63, 0.81)\\).\nSince this interval is entirely above \\(0.5\\), we can reasonably suspect that the coin is not fair and that heads are more likely to come up than tails.\n\n\nThe CI above is called the standard CI for a binomial proportion. It is only one amongst many that have been proposed in the statistical literature. The following is another one which is more complicated but arguably better.\n\n\n\n\n3.1 Wilson CI for a Binomial Proportion\nNow, in fact the following is another way of estimation the interval.\n\nTheorem 1 (Wilson CI) Another \\(100(1-\\alpha)\\%\\) CI for \\(p\\) is given by \\[\\begin{equation}\n\\left( \\frac{\\hat{p} + \\frac{z^2_{\\alpha/2}}{2n} \\pm z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n} + \\frac{z^2_{\\alpha/2}}{4n^2}}}{1 + \\frac{z^2_{\\alpha/2}}{n}} \\right)\n\\end{equation}\\]\nThis interval is called the Wilson CI for a binomial proportion. Note that if \\(n\\) is large this CI is approximately the same as the standard CI introduced in Example¬†7.\n\n\nProof. Observe that \\[\\begin{align*}\n1 - \\alpha &\\approx \\P{-z_{\\alpha / 2} &lt; \\frac{Y - np}{\\sqrt{np(1 - p)}} &lt; z_{\\alpha/2}} \\\\\n&= \\P{\\left(\\frac{Y - np}{\\sqrt{np(1 - p)}}\\right)^2 &lt; z^2} \\tag{where $z = z_{\\alpha/2}$} \\\\\n&= \\P{ Y^2 - 2npY + n^2 p^2 &lt; z^2 np - z^2 np^2 } \\\\\n&= \\P{ p^2\\left(1 + \\frac{z^2}{n}\\right) - p\\left(\\frac{2Y}{n} + \\frac{z^2}{n} \\right) + \\frac{Y^2}{n^2} &lt; 0 } \\\\\n&= \\P{ p^2\\left(1 + \\frac{z^2}{n}\\right) - p\\left(2\\hat{p} + \\frac{z^2}{n} \\right) + \\hat{p}^2 &lt; 0 } \\tag{where $\\hat{p} = \\frac{Y}{n}$} \\\\\n&= \\P{ a &lt; p &lt; b }, \\\\\n\\end{align*}\\] where \\(a\\) and \\(b\\) are the roots of quadratic function \\(\\eqref{eq:root-quad-func}\\). \\[\\begin{equation} \\label{eq:root-quad-func}\nf(p) = p^2\\left( 1 + \\frac{z^2}{n} \\right) - p\\left(2\\hat{p} + \\frac{z^2}{n}\\right) + \\hat{p}^2\n\\end{equation}\\] Hence, finding the roots of \\(\\eqref{eq:root-quad-func}\\) yield, \\[\\begin{align*}\n& \\frac{\n  (2\\hat{p} + \\frac{z^2}{n}) \\pm \\sqrt{(2\\hat{p} + \\frac{z^2}{n})^2 - 4\\hat{p}^2(1 + \\frac{z^2}{n})}\n}{\n  2(1 + \\frac{z^2}{n})\n} \\\\\n&= \\frac{\n  \\hat{p} + \\frac{z^2}{2n} \\pm \\frac{1}{2} \\sqrt{\n    4\\hat{p}^2 + \\frac{4\\hat{p} z^2}{n} + \\frac{z^4}{n^2}\n    - 4\\hat{p}^2 - \\frac{4\\hat{p}^2 z^2}{n}\n  }\n}{\n  1 + \\frac{z^2}{n}\n} \\\\\n&= \\frac{\n  \\hat{p} + \\frac{z^2}{2n} \\pm \\sqrt{\n    \\frac{\\hat{p} z^2}{n} + \\frac{z^4}{4n^2} - \\frac{\\hat{p}^2 z^2}{n}\n  }\n}{\n  1 + \\frac{z^2}{n}\n}\\\\\n\\end{align*}\\]\n\n\n\n\n\n\n\n\nExample 9 in Wilson CI\n\n\n\n\nExample 8 Find the Wilson CI for the same setting as Example¬†7.\n\n\n\nSolution. \\[\\begin{equation}\n\\left( \\frac{0.72 + \\frac{1.959964^2}{2\\cdot 100} \\pm 1.959964 \\sqrt{\\frac{0.72(1-0.72)}{100} + \\frac{1.959964^2}{4\\cdot100^2}}}{1 + \\frac{1.959964^2}{100}} \\right) = \\frac{0.739207 \\pm 0.009007}{1.0384} = (0.625, 0.798)\n\\end{equation}\\]\nNote that the above is very similar to the standard CI \\((0.63, 0.81)\\) derived in Example¬†7.\n\n\n\n\n\n3.2 Why is Wilson CI is better?\nThe Wilson CI is considered ‚Äòbetter‚Äô than the standard CI because its coverage probabilities are overall closer to the desired \\(1 - \\alpha\\). For example, if \\(n = 23\\) and \\(p = 0.344\\), the coverage probability of the standard \\(95\\%\\) CI is \\(91.4\\%\\), and the coverage probability of the Wilson \\(95\\%\\) CI is \\(95.5\\%\\). These calculations can be repeated for all values of \\(p\\) on a grid (\\(p = 0.001, 0.002, \\ldots , 1\\)), with \\(n = 23\\) held the same in each case.\nEssentially, this is because the Wald interval uses \\(\\hat{p}\\) to approximate \\(p\\) multiple times to obtain the interval estimation. Particularly, the approximation is used in the ‚Äústandard error‚Äù part for the test statistic. In another perspective, the sample size can be seen as the key factor because it is essentially providing more information to \\(\\hat{p}\\) to approximate \\(p\\) with a more accurate approximation.\nFrom Figure¬†1, it is clear that as \\(p\\) become more ‚Äúextreme‚Äù values, the Wald CI fails quite dramatically. This is because such \\(p\\) values usually result in a asymmetric distribution, particularly with small \\(n\\) like \\(23\\)2.\n\n\nShow the code\n# Set parameters\nn &lt;- 23\nalpha &lt;- 0.05\nz &lt;- qnorm(1 - alpha/2)\np_vals &lt;- seq(0, 1, by = 0.01)\n\n# Function to compute Wald CI\nwald_ci &lt;- function(y, n) {\n  phat &lt;- y / n\n  se &lt;- sqrt(phat * (1 - phat) / n)\n  lower &lt;- phat - z * se\n  upper &lt;- phat + z * se\n  c(lower, upper)\n}\n\n# Function to compute Wilson CI\nwilson_ci &lt;- function(y, n) {\n  phat &lt;- y / n\n  center &lt;- (phat + z^2 / (2 * n)) / (1 + z^2 / n)\n  margin &lt;- z / (1 + z^2 / n) * sqrt(phat * (1 - phat) / n + z^2 / (4 * n^2))\n  lower &lt;- center - margin\n  upper &lt;- center + margin\n  c(lower, upper)\n}\n\n# Compute coverage for each p\nwald_coverage &lt;- numeric(length(p_vals))\nwilson_coverage &lt;- numeric(length(p_vals))\n\nfor (i in seq_along(p_vals)) {\n  p &lt;- p_vals[i]\n  probs &lt;- dbinom(0:n, n, p)\n  \n  wald_hits &lt;- 0\n  wilson_hits &lt;- 0\n  \n  for (y in 0:n) {\n    wald_bounds &lt;- wald_ci(y, n)\n    wilson_bounds &lt;- wilson_ci(y, n)\n    \n    # Count if p is inside the interval\n    if (p &gt;= wald_bounds[1] && p &lt;= wald_bounds[2]) {\n      wald_hits &lt;- wald_hits + probs[y + 1]\n    }\n    if (p &gt;= wilson_bounds[1] && p &lt;= wilson_bounds[2]) {\n      wilson_hits &lt;- wilson_hits + probs[y + 1]\n    }\n  }\n  \n  wald_coverage[i] &lt;- wald_hits\n  wilson_coverage[i] &lt;- wilson_hits\n}\n\n# Plot\nplot(p_vals, wald_coverage, type = \"l\", col = \"red\", lty = 2, ylim = c(0, 1),\n     xlab = \"True Proportion (p)\", ylab = \"Coverage\",\n     main = \"Coverage probabilities of 95% CIs (n = 23)\")\nlines(p_vals, wilson_coverage, col = \"blue\", lty = 1)\nabline(h = 0.95, col = \"gray\", lty = 3)\ntext(-0.01, 0.95, labels = \"0.95\", pos = 3, col = \"gray40\", cex = 0.8)\n\nlegend(\"bottomright\", legend = c(\"Standard (Wald)\", \"Wilson\"),\n       col = c(\"red\", \"blue\"), lty = c(2, 1))\n\n# Highlight example point\np_example &lt;- 0.344\nix &lt;- which.min(abs(p_vals - p_example))\npoints(p_example, wald_coverage[ix], col = \"red\", pch = 16)\npoints(p_example, wilson_coverage[ix], col = \"blue\", pch = 16)\ntext(p_example, wald_coverage[ix], \n     labels = paste0(\"(\", p_example, \", \", round(wald_coverage[ix], 3), \")\"),\n     pos = 1, col = \"red\", cex = 0.8)\ntext(p_example, wilson_coverage[ix], \n     labels = paste0(\"(\", p_example, \", \", round(wilson_coverage[ix], 3), \")\"),\n     pos = 3, col = \"blue\", cex = 0.8)\n\n\n\n\n\n\n\n\nFigure¬†1",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html#difference-of-p-in-binomial",
    "href": "contents/chapter-08/3interval-estimate.html#difference-of-p-in-binomial",
    "title": "Interval Estimation",
    "section": "4 Difference of \\(p\\) in Binomial",
    "text": "4 Difference of \\(p\\) in Binomial\n\nTheorem 2 (Difference in Proportion) Let \\(X \\sim \\Binomial(n, p)\\), and \\(Y \\sim \\Binomial(m, q)\\), where both \\(n\\) and \\(m\\) are large and \\(X \\perp Y\\).\nThen the approximate (Use of CLT and point estimator) \\(100(1 - \\alpha)\\%\\) CI for \\(p - q\\) is \\[\\begin{equation}\n\\left( \\hat{p} - \\hat{q} \\pm z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n} + \\frac{\\hat{q}(1 - \\hat{q})}{m}} \\right)\n\\end{equation}\\]\n\n\nProof. From CLT, we have:\n\n\\(\\hat{p} \\approx \\NormalDist\\left(p, \\dfrac{p(1 - p)}{n} \\right)\\)\n\n\\(\\hat{q} \\approx \\NormalDist\\left(q, \\dfrac{q(1 - q)}{m} \\right)\\)\n\nwhen \\(n\\) and \\(m\\) are large.\nSo:\n\\[\n\\hat{p} - \\hat{q} \\approx \\NormalDist\\left(p - q,\\ \\dfrac{p(1 - p)}{n} + \\dfrac{q(1 - q)}{m} \\right)\n\\]\nSince the sum (or difference) of two normal random variables is also normal, and \\(\\hat{p}\\) and \\(\\hat{q}\\) are independent, this implies:\n\\[\n\\text{Var}(\\hat{p} - \\hat{q}) = \\text{Var}(\\hat{p}) + \\text{Var}(\\hat{q})\n\\]\nThus:\n\\[\n\\frac{\\hat{p} - \\hat{q} - (p - q)}{\n\\sqrt{ \\dfrac{p(1 - p)}{n} + \\dfrac{q(1 - q)}{m} }\n}\n\\approx \\NormalDist(0, 1)\n\\]\nand, by substitution of sample estimates for large \\(n\\) and \\(m\\):\n\\[\n\\frac{\\hat{p} - \\hat{q} - (p - q)}{\n\\sqrt{ \\dfrac{\\hat{p}(1 - \\hat{p})}{n} + \\dfrac{\\hat{q}(1 - \\hat{q})}{m} }\n}\n\\approx \\NormalDist(0, 1) \\quad \\text{if } n \\text{ and } m \\text{ are large}\n\\]\n\n\nRemark 1. Note that this one uses both the CLT and the point estimator to approximate the final solution. Note that for large enough \\(m\\) and \\(n\\), this approximation should converge to something good that is gauranteed by the convergence property that will be discuss in Chapter 9.\n\n\n\n\n\n\n\n\nExample 10\n\n\n\n\n\n\nYou have a bent $1 coin and a bent $2 coin.\nYou toss the $1 coin 200 times and get 108 heads.\nYou toss the $2 coin 300 times and get 141 heads.\nFind a 90% CI for the difference between the probability of a head on the $1 coin and the probability of a head on the $2 coin.\n\n\n\nSolution. In our case:\n\n\\(p\\) = probability of heads on a toss of the $1 coin\n\n\\(q\\) = probability of heads on a toss of the $2 coin\n\n\\[\n\\begin{aligned}\nn &= 200, \\quad x = 108, \\quad \\hat{p} = \\frac{108}{200} = 0.54 \\\\\nm &= 300, \\quad y = 141, \\quad \\hat{q} = \\frac{141}{300} = 0.47 \\\\\n\\alpha &= 0.1, \\quad z_{\\alpha/2} = z_{0.05} = 1.645\n\\end{aligned}\n\\]\nSo a 90% confidence interval for \\(p - q\\) is:\n\\[\n\\left(\n0.54 - 0.47 \\pm 1.645 \\sqrt{\n\\frac{0.54(1 - 0.54)}{200} +\n\\frac{0.47(1 - 0.47)}{300}\n}\n\\right)\n\\]\n\\[\n= (0.07 \\pm 0.075) = (-0.005,\\ 0.145)\n\\]\nSince this CI contains 0, we suspect the chance of heads is the same for both coins, i.e., the difference is not significantly different from zero. Evidence to support true means are the same/similar to the hypothesis test \\(p = q\\) (i.e.¬†\\(p - q = 0\\)).",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html#confidence-for-sample-variance",
    "href": "contents/chapter-08/3interval-estimate.html#confidence-for-sample-variance",
    "title": "Interval Estimation",
    "section": "5 Confidence for Sample Variance",
    "text": "5 Confidence for Sample Variance\n\nExample 9 (Finding the Confidence Interval for Sample Variance) Suppose that \\(Y_1, Y_2, \\ldots Y_n \\sim^\\iid \\NormalDist(\\mu, \\sigma^2)\\). Find a \\(100(1 - \\alpha)\\%\\) CI for \\(\\sigma^2\\).\n\n\nSolution. Recall that \\(\\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2(n-1)\\). Therefore \\[\\begin{align*}\n1 - \\alpha &= P\\left(\n\\chi^2_{1 - \\alpha/2}(n - 1)\n&lt; \\frac{(n - 1)S^2}{\\sigma^2}\n&lt; \\chi^2_{\\alpha/2}(n - 1)\n\\right) \\\\\n&= P\\left(\n\\frac{(n - 1)S^2}{\\chi^2_{\\alpha/2}(n - 1)}\n&lt; \\sigma^2 &lt;\n\\frac{(n - 1)S^2}{\\chi^2_{1 - \\alpha/2}(n - 1)}\n\\right)\n\\end{align*}\\]\n( \\(\\chi^2_p(m)\\) is the upper \\(p\\) quantile of the chi square distribution with \\(m\\) degrees of freedom. )\nSo a \\(100(1 - \\alpha)\\%\\) CI for \\(\\sigma^2\\) is \\(\\left(\\frac{(n - 1)S^2}{\\chi^2_{\\alpha/2}(n - 1)},\\frac{(n - 1)S^2}{\\chi^2_{1 - \\alpha/2}(n - 1)}\\right).\\)",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html#confidence-intervals-for-the-difference-between-two-population-means",
    "href": "contents/chapter-08/3interval-estimate.html#confidence-intervals-for-the-difference-between-two-population-means",
    "title": "Interval Estimation",
    "section": "6 Confidence Intervals for the Difference Between Two Population Means",
    "text": "6 Confidence Intervals for the Difference Between Two Population Means\nLet:\n\n\\(X_1, X_2, \\ldots, X_n \\sim \\text{iid } (\\mu_X, \\sigma_X^2)\\) (first sample)\n\\(Y_1, Y_2, \\ldots, Y_m \\sim \\text{iid } (\\mu_Y, \\sigma_Y^2)\\) (second sample)\n\nAssume:\n\n\\((X_1, X_2, \\ldots, X_n) \\perp (Y_1, Y_2, \\ldots, Y_m)\\) (the two samples are independent)\n\nDefine:\n\n\\(\\bar{X} = \\frac{1}{n} \\sum_{i=1}^n X_i \\quad \\text{(1st sample mean)}\\)\n\\(\\bar{Y} = \\frac{1}{m} \\sum_{i=1}^m Y_i \\quad \\text{(2nd sample mean)}\\)\n\\(S_X^2 = \\frac{1}{n - 1} \\sum_{i=1}^n (X_i - \\bar{X})^2 \\quad \\text{(1st sample variance)}\\)\n\\(S_Y^2 = \\frac{1}{m - 1} \\sum_{i=1}^m (Y_i - \\bar{Y})^2 \\quad \\text{(2nd sample variance)}\\)\n\nWe wish to construct a \\(100(1 - \\alpha)\\%\\) confidence interval for \\(\\mu_X - \\mu_Y\\).\nA suitable CI will depend on:\n\nwhat assumptions we can make regarding the distributions of the \\(X_i\\) and \\(Y_i\\) values\n\nwhat knowledge we have regarding the two population variances, \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\)\n\nwhether the two sample sizes \\(n\\) and \\(m\\) are ‚Äòlarge‚Äô (so that we can apply the CLT)\n\n\n\n\n\n\n\nSome Possible CIs for Difference between two Population Means\n\n\n\n\n\nHere are five different ways‚Ä¶\n\n\n\n\n\n\nIf \\(n\\) and \\(m\\) are large, and \\(\\sigma_x^2\\) and \\(\\sigma_Y^2\\) are known, a suitable approximate CI is\n\\[\\begin{equation} \\label{eq:basic-diff-mean-ci}\n\\left( \\bar{X} - \\bar{Y} \\pm z_{\\alpha/2} \\sqrt{ \\frac{\\sigma_X^2}{n} + \\frac{\\sigma_Y^2}{m} }\\right)\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\nIf \\(n\\) and \\(m\\) are large, and \\(\\sigma_x^2\\) and \\(\\sigma_Y^2\\) are both unknown, a suitable approximate CI is\n\\[\\begin{equation}\n\\left( \\bar{X} - \\bar{Y} \\pm z_{\\alpha/2} \\sqrt{ \\frac{S_X^2}{n} + \\frac{S_Y^2}{m} }\\right)\n\\end{equation}\\]\n\n\n\n\n\n\n\n\n\nIf \\(X_i\\) and \\(Y_i\\) values are normally distributed and \\(\\sigma_x^2\\) and \\(\\sigma_Y^2\\) are both known, a suitable exact CI is \\[\\begin{equation}\n\\left( \\bar{X} - \\bar{Y} \\pm z_{\\alpha/2} \\sqrt{ \\frac{\\sigma_X^2}{n} + \\frac{\\sigma_Y^2}{m} }\\right)\n\\end{equation}\\]\n(Same as \\(\\eqref{eq:basic-diff-mean-ci}\\), but this one does not rely on CLT)\n\n\n\n\n\n\n\n\n\nIf the \\(X_i\\) and \\(Y_i\\) values are normally distributed, \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\) are unknown, and \\(n\\) and \\(m\\) are both large, a suitable approximate CI is, \\[\\begin{equation}\n\\left( \\bar{X} - \\bar{Y} \\pm z_{\\alpha/2} \\sqrt{ \\frac{S_X^2}{n} + \\frac{S_Y^2}{m} }\\right)\n\\end{equation}\\]\n(Relies on the fact that \\(t \\dconv \\NormalDist\\).)\n\n\n\n\n\n\n\n\n\nIf the \\(X_i\\) and \\(Y_i\\) values are normally distributed, all with common population variance \\(\\sigma^2 = \\sigma_X^2 = \\sigma_Y^2\\) which however is unknown, a suitable exact CI is, \\[\\begin{equation*}\n\\left( \\mean{X} - \\mean{Y} \\pm t_{\\alpha/2}(n + m - 2) S_p \\sqrt{\\frac{1}{n} + \\frac{1}{m}} \\right).\n\\end{equation*}\\]\nwhere \\(S_p^2 = \\frac{(n-1)S_X^2 + (m - 1)S_Y^2}{n+m-2}\\) is the pooled sample variance. In fact, \\(S_p^2\\) is unbiased for \\(\\sigma^2\\).\n\n\n\nIf the \\(X_i\\) and \\(Y_i\\) values are normally distributed, nothing at all is known about \\(\\sigma_X^2\\) and \\(\\sigma_Y^2\\), and \\(n\\) and m are not both large, then the construction of a suitable CI is beyond the scope of this course. Interested students can find out more by researching the Behrens-Fisher problem, e.g.¬†on Wikipedia (this topic is non-assessable).",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/3interval-estimate.html#footnotes",
    "href": "contents/chapter-08/3interval-estimate.html#footnotes",
    "title": "Interval Estimation",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that this cannot really be a probability statement in general. At least under the frequentist viewpoint, the distribution parameter is a fixed, constant rather than a radom variable. Therefore, we would have to ‚Äúre-interpret‚Äù such formula as the percentage of such intervals that would capture the real coefficients if we take a large numbers of random samples and calculate such interval.‚Ü©Ô∏é\nThe details of the coverage tests is included in section about coverage test.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Interval Estimation"
    ]
  },
  {
    "objectID": "contents/chapter-08/2evaluation.html",
    "href": "contents/chapter-08/2evaluation.html",
    "title": "Evaluation Metrics",
    "section": "",
    "text": "The question now arises: How good is \\(\\hat{p}\\) as an estimator of \\(p\\)?\nWhat we need are some criteria for assessing the quality of estimators. The bias of an estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) is \\[\\begin{equation}\n\\bias{\\hat{\\theta}} = \\E{\\hat{\\theta}} - \\theta\n\\end{equation}\\]\nIf \\(\\bias{\\hat{\\theta}} = 0\\), we say that \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\).\nIn Example 1, what is the bias of \\(\\hat{p}\\)? \\[\\begin{equation*}\n\\E{\\hat{p}} = \\E{\\frac{Y}{n}} = \\frac{1}{n} \\E{Y} = \\frac{1}{n} np = p\n\\end{equation*}\\] Therefore, \\[\\begin{equation*}\n\\bias{\\hat{p}} = \\E{\\hat{p}} - p = p - p = 0\n\\end{equation*}\\]\nHence, we know that \\(\\hat{p}\\) is an accurate estimator. But, is \\(\\hat{p}\\) also precise?\n\n\n\n\n\n\n‚Ä¶ but wait, what does it mean to be precise?\n\n\n\n\n\nWell, precise means that we don‚Äôt want to have a highly variational estimator. In other words, we would like the estimator to have an estimate to be relatively close to the target on every sample as well.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Evaluation Metrics"
    ]
  },
  {
    "objectID": "contents/chapter-08/2evaluation.html#bias",
    "href": "contents/chapter-08/2evaluation.html#bias",
    "title": "Evaluation Metrics",
    "section": "",
    "text": "The question now arises: How good is \\(\\hat{p}\\) as an estimator of \\(p\\)?\nWhat we need are some criteria for assessing the quality of estimators. The bias of an estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) is \\[\\begin{equation}\n\\bias{\\hat{\\theta}} = \\E{\\hat{\\theta}} - \\theta\n\\end{equation}\\]\nIf \\(\\bias{\\hat{\\theta}} = 0\\), we say that \\(\\hat{\\theta}\\) is unbiased for \\(\\theta\\).\nIn Example 1, what is the bias of \\(\\hat{p}\\)? \\[\\begin{equation*}\n\\E{\\hat{p}} = \\E{\\frac{Y}{n}} = \\frac{1}{n} \\E{Y} = \\frac{1}{n} np = p\n\\end{equation*}\\] Therefore, \\[\\begin{equation*}\n\\bias{\\hat{p}} = \\E{\\hat{p}} - p = p - p = 0\n\\end{equation*}\\]\nHence, we know that \\(\\hat{p}\\) is an accurate estimator. But, is \\(\\hat{p}\\) also precise?\n\n\n\n\n\n\n‚Ä¶ but wait, what does it mean to be precise?\n\n\n\n\n\nWell, precise means that we don‚Äôt want to have a highly variational estimator. In other words, we would like the estimator to have an estimate to be relatively close to the target on every sample as well.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Evaluation Metrics"
    ]
  },
  {
    "objectID": "contents/chapter-08/2evaluation.html#precision",
    "href": "contents/chapter-08/2evaluation.html#precision",
    "title": "Evaluation Metrics",
    "section": "2 Precision",
    "text": "2 Precision\nAnalogy: Target at a firing range:\n\n\nShow the code\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\nmu_accurate &lt;- c(0, 0)\nmu_inaccurate &lt;- c(-3, 3)\nsigma_accurate &lt;- matrix(data = c(.5, 0, 0, .5), nrow = 2, ncol = 2)\nsigma_inaccurate &lt;- matrix(data = c(5, 0, 0, 5), nrow = 2, ncol = 2)\n\nsample_size &lt;- 30\n\npoints1 &lt;- mvrnorm(n = sample_size, mu = mu_accurate, Sigma = sigma_accurate)\npoints2 &lt;- mvrnorm(n = sample_size, mu = mu_accurate, Sigma = sigma_inaccurate)\npoints3 &lt;- mvrnorm(n = sample_size, mu = mu_inaccurate, Sigma = sigma_accurate)\npoints4 &lt;- mvrnorm(n = sample_size, mu = mu_inaccurate, Sigma = sigma_inaccurate)\n\n# Combine into a data frame\ndf &lt;- rbind(\n  data.frame(x = points1[,1], y = points1[,2], group = \"Accurate & Precise\"),\n  data.frame(x = points2[,1], y = points2[,2], group = \"Accurate & Imprecise\"),\n  data.frame(x = points3[,1], y = points3[,2], group = \"Inaccurate & Precise\"),\n  data.frame(x = points4[,1], y = points4[,2], group = \"Inaccurate & Imprecise\")\n)\n\nmv &lt;- 7\n\n# Create one plot per group\np1 &lt;- ggplot(filter(df, group == \"Accurate & Precise\"), aes(x = x, y = y)) +\n  geom_point(size = 2, alpha = 0.8) +\n  coord_fixed() +\n  scale_x_continuous(limits = c(-mv, mv)) +\n  scale_y_continuous(limits = c(-mv, mv)) +\n  theme_minimal() +\n  ggtitle(\"Accurate & Precise\")\n\np2 &lt;- ggplot(filter(df, group == \"Accurate & Imprecise\"), aes(x = x, y = y)) +\n  geom_point(size = 2, alpha = 0.8) +\n  coord_fixed() +\n  scale_x_continuous(limits = c(-mv, mv)) +\n  scale_y_continuous(limits = c(-mv, mv)) +\n  theme_minimal() +\n  ggtitle(\"Accurate & Imprecise\")\n\np3 &lt;- ggplot(filter(df, group == \"Inaccurate & Precise\"), aes(x = x, y = y)) +\n  geom_point(size = 2, alpha = 0.8) +\n  coord_fixed() +\n  scale_x_continuous(limits = c(-mv, mv)) +\n  scale_y_continuous(limits = c(-mv, mv)) +\n  theme_minimal() +\n  ggtitle(\"Inaccurate & Precise\")\n\np4 &lt;- ggplot(filter(df, group == \"Inaccurate & Imprecise\"), aes(x = x, y = y)) +\n  geom_point(size = 2, alpha = 0.8) +\n  coord_fixed() +\n  scale_x_continuous(limits = c(-mv, mv)) +\n  scale_y_continuous(limits = c(-mv, mv)) +\n  theme_minimal() +\n  ggtitle(\"Inaccurate & Imprecise\")\n\np1\np2\np3\np4\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Accurate & Precise\n\n\n\n\n\n\n\n\n\n\n\n(b) Accurate & Imprecise\n\n\n\n\n\n\n\n\n\n\n\n(c) Inaccurate & Precise\n\n\n\n\n\n\n\n\n\n\n\n(d) Inaccurate & Imprecise\n\n\n\n\n\n\n\nFigure¬†1: Accuracy vs.¬†Precision\n\n\n\n\nTherefore, we can clearly see that only Figure¬†1 (a) be the good one. However, which other is the best? Well, this is an unanswered question. However, we can see that maybe a more ‚Äúclustered‚Äù one is better? Therefore, we can define the following variance measure, \\[\\begin{equation*}\n\\Var{\\hat{p}} = \\Var{\\frac{Y}{n}} = \\frac{1}{n^2} \\Var{Y} = \\frac{1}{n^2}np(1 - p) = \\frac{p(1 - p)}{n}\n\\end{equation*}\\]",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Evaluation Metrics"
    ]
  },
  {
    "objectID": "contents/chapter-08/2evaluation.html#mean-square-error",
    "href": "contents/chapter-08/2evaluation.html#mean-square-error",
    "title": "Evaluation Metrics",
    "section": "3 Mean Square Error",
    "text": "3 Mean Square Error\nAnother measure of an estimator‚Äôs quality is the mean square error. The mean square error (MSE) of an estimator \\(\\hat{\\theta}\\) of \\(\\theta\\) is \\[\\begin{equation*}\n\\mse{\\theta} = \\E{\\left( \\hat{\\theta} - \\theta \\right)^2}\n\\end{equation*}\\] Now, that it turns out that \\(\\mse{\\hat{\\theta}} = \\Var{\\hat{\\theta}} + \\left( \\bias{\\hat{\\theta}} \\right)^2\\).\nThus \\(MSE\\) is a combined measure of accuracy and precision. (It will be small only if both the mean and variance are small.)\nIn our example, \\(\\mse{\\hat{p}} = \\Var{\\hat{p}} + (\\bias{\\hat{p}})^2 = \\frac{p(1-p)}{n}\\).\n\n\n\n\n\n\nWhy do we need all this?\n\n\n\n\n\nIn our example, the estimator for \\(p\\) is relatively ‚Äòobvious‚Äô estimator of \\(p\\). However, in many situations, there will be several plausible estimators to consider. One must then decide which one is the ‚Äòbest‚Äô. This will typically be done by comparing the bias, variance, and MSE of the candidate estimators.\nIn fact, this idea of MSE is highly used in machine learning training where the loss of the neural network is directly calculated by using MSE.\n\n\n\n\n\nTheorem 1 (MSE, Variance and Bias) \\[\\begin{equation}\n\\mse{\\hat{p}} = \\Var{\\hat{p}} + (\\bias{\\hat{p}})^2 = \\frac{p(1-p)}{n}\n\\end{equation}\\]\n\n\nProof. The proof requires simply algebraic manipulation.\n\\[\\begin{align*}\n\\mse{\\hat{\\theta}} & = \\E{\\left( \\hat{\\theta} - \\theta \\right)^2} \\\\\n& = \\E{\\left( \\hat{\\theta} - \\E{\\hat{\\theta}} + \\E{\\hat{\\theta}} - \\theta \\right)^2} \\\\\n& = \\E{\\left( \\hat{\\theta} - \\E{\\hat{\\theta}} \\right)^2 + \\left(\\E{\\hat{\\theta}} - \\theta \\right)^2 + 2 \\left( \\hat{\\theta} - \\E{\\hat{\\theta}} \\right) \\left( \\E{\\hat{\\theta}} - \\theta \\right) } \\\\\n& = \\E{\\left( \\hat{\\theta} - \\E{\\hat{\\theta}} \\right)^2 } + \\left(\\E{\\hat{\\theta}} - \\theta \\right)^2 + 2 \\underbrace{\\left( \\E{\\hat{\\theta}} - \\E{\\hat{\\theta}} \\right)}_{=0} \\left( \\E{\\hat{\\theta}} - \\theta \\right) \\\\\n& = \\Var{\\hat{\\theta}} + \\left( \\bias{\\hat{\\theta}} \\right)^2\n\\end{align*}\\]\n\n\n\n\n\n\n\nWorking Example\n\n\n\nTwo numbers are randomly chosen between \\(0\\) and \\(c\\). They are \\(X = 3.6\\) and \\(y = 5.4\\). Consider the following estimates of \\(c\\): \\[\\begin{align*}\nU &= X + Y \\\\\nV &= \\max(X, Y) \\\\\n\\end{align*}\\] Which estimate should we choose, and why?\n\nSolution\nLet \\(X, Y \\sim^\\iid U(0, c)\\). Then, to determine the mean, bias, variance and MSE as the following,\n\\[\\begin{align*}\n\\E{U} & = \\E{X + Y}  = c \\tag{U.mean} \\label{eq:u-mean} \\\\\n\\bias{U} & = c - c = 0 \\tag{U.bias} \\label{eq:u-bias} \\\\\n\\Var{U} & = \\Var{X + Y} = \\Var{X} + \\Var{Y} = \\frac{c^2}{6} \\tag{U.var} \\label{eq:u-var} \\\\\n\\mse{U} & = \\Var{U} + \\left( \\bias{U} \\right)^2 = \\frac{c^2}{6} \\tag{U.mse} \\label{eq:u-mse} \\\\\n\\end{align*}\\]\n\n\n\nTo find out the measures for \\(V\\), we first need to determine the distribution of \\(V\\). Fortunately, we know that it is the order statistics. Recalling from previous chapter, we have discussed that the general formula for order statistic (\\(n = 2\\)) is, \\[\\begin{equation*}\nf_V(v) = f_{U_2}(v) = \\frac{2!}{(2 - 1)!(2-2)!} F(v)^{2 - 1} \\left( 1 - F(v) \\right)^{2-2} f(v) = 2F(v)f(v) = 2 \\left( \\frac{v}{c} \\right) \\frac{1}{c} = \\frac{2v}{c^2} \\; \\text{(for $v \\in [0, c]$)}\n\\end{equation*}\\]\n\\[\\begin{align*}\n\\E{V} & = \\int_0^c \\frac{2v^2}{c^2} \\, dv = \\frac{2}{c^2} \\left[ \\frac{v^3}{3} \\right]_0^c = \\frac{2c}{3} \\tag{V.mean} \\label{eq:v-mean} \\\\\n\\bias{V} & = \\frac{2c}{3} - c = -\\frac{c}{3} \\tag{V.bias} \\label{eq:v-bias} \\\\\n\\E{V^2} & = \\int_0^c \\frac{2v^3}{c^2} \\, dv = \\frac{2}{c^2} \\left[ \\frac{v^4}{4} \\right]_0^c = \\frac{c^2}{2} \\\\\n\\Var{V} & = \\E{V^2} - \\left( \\E{V} \\right)^2 = \\frac{c^2}{2} - \\left( \\frac{2c}{3} \\right)^2 = \\frac{c^2}{18} \\tag{V.var} \\label{eq:v-var} \\\\\n\\mse{V} & = \\Var{V} + \\left( \\bias{V} \\right)^2 = \\frac{c^2}{9} + \\frac{c^2}{18} = \\frac{c^2}{6} \\tag{V.mse} \\label{eq:v-mse} \\\\\n\\end{align*}\\]\nTherefore, we can clearly see that \\(V\\) is biased from \\(\\eqref{eq:v-bias}\\). However, the MSE is actually the same as shown in \\(\\eqref{eq:u-mse}\\) and \\(\\eqref{eq:v-mse}\\). Therefore it is relatively hard to say which one is better. We see that \\(U\\) is:\n\nmore accurate than \\(V\\) (non-bias vs bias)\nless precise than \\(V\\) (since \\(c^2 / 6 &gt; c^2 / 18\\))\noverall about as good as \\(V\\) (since \\(c^2 / 6 = c^2 / 6\\))\n\nSince \\(U\\) is unbiased and \\(V\\) is not, we choose \\(U\\) as the better of the two estimators. Does this mean that the estimate \\(V\\) is useless? No.¬†We can make use of \\(v\\) as a starting point (or basis) for constructing an estimate that is better than \\(U\\). Observe that \\(\\E{V} = 2c/3\\). This implies \\(\\E{3V/2} = c\\). So we define \\(W = 3V / 2.\\) This is another estimator of \\(c\\) to be considered. Now, what is the variance of \\(W\\), \\[\\begin{equation*}\n\\Var{W} = \\left( \\frac{3}{2} \\right)^2 \\Var{V} = \\frac{9}{4} \\cdot \\frac{c^2}{18} = \\frac{c^2}{8}\n\\end{equation*}\\] Therefore, we obtain the MSE as \\[\\begin{equation*}\n\\mse{W} = \\Var{W} = c^2/8\n\\end{equation*}\\]\nNow, we see that \\(W\\) is:\n\njust as accurate as \\(U\\)\nmore precise than \\(U\\)\noverall better than \\(U\\)\n\nWe conclude that \\(W\\) is best of the three estimators. So our best estimate of \\(c\\) is \\(W = 1.5 \\max(X,Y)\\), our second best estimate is \\(U = X + Y\\), and our third choice would be \\(V = \\max(X, Y)\\).\n\n\n\n\n\n\n\n\nSomething to be careful of‚Ä¶\n\n\n\n\n\n\nRemark 1. Ideally, we should choose which estimator to use (\\(U\\), \\(V\\) or \\(W\\)) before observing the data (\\(X\\) and \\(Y\\)).",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Evaluation Metrics"
    ]
  },
  {
    "objectID": "contents/chapter-08/2evaluation.html#two-important-results-for-estimation",
    "href": "contents/chapter-08/2evaluation.html#two-important-results-for-estimation",
    "title": "Evaluation Metrics",
    "section": "4 Two Important Results for Estimation",
    "text": "4 Two Important Results for Estimation\n\nTheorem 2 Suppose that \\(Y_1, Y_2, \\ldots ,Y_n \\sim^\\iid (\\mu, \\sigma^2)\\) and define \\(\\mean{Y} = \\frac{1}{n} \\sum_{i=1}^n Y_i\\) (sample mean) and \\(S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (Y_i - \\mean{Y})^2\\) (sample variance). Then\n\n\\(\\E{\\mean{Y}} = \\mu\\) (population mean)\n\\(\\E{S^2} = \\sigma^2\\) (population variance)\n\n\n\nProof (a). \\[\\begin{equation*}\n\\E{\\mean{Y}} = \\frac{1}{n} \\sum_{i=1}^n \\E{Y_i} = \\frac{1}{n} \\sum_i^n \\mu = \\mu\n\\end{equation*}\\]\n\n\nProof (b). First, realise the following, \\[\\begin{equation*}\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^n D_i^2 \\hspace{10pt} \\text{where $D_i = Y - Y_i$}\n\\end{equation*}\\]\nThen, we can first find the second raw moment of \\(D_i^2\\),\n\\[\\begin{align*}\n\\E{D_i^2} & = \\Var{D_i} \\tag{since $\\E{D_i} = 0$} \\\\\n& = \\Var{Y_i} + \\Var{\\mean{Y}} - 2\\Cov{Y_i, \\mean{Y}} \\\\\n& = \\sigma^2 + \\frac{\\sigma^2}{n} - 2 \\cdot \\frac{\\sigma^2}{n} \\tag{Note 1} \\\\\n& = \\frac{n-1}{n} \\sigma^2 \\\\\n\\end{align*}\\]\nHence, \\[\\begin{equation*}\n\\E{S^2} = \\frac{1}{n-1} \\sum_{i=1}^n \\E{D_i^2} = \\frac{1}{n-1} (n \\cdot \\frac{n-1}{n}\\sigma^2) = \\sigma^2\n\\end{equation*}\\]\n\nNote 1:\nNote that we have previously shown \\(\\mean{Y} \\perp (Y_i - \\mean{Y})\\) for \\(\\iid\\) \\(Y_i\\)‚Äôs in Chpater 7 Section 2. Now, then, we have \\[\\begin{align*}\n0 = \\Cov{Y_i - \\mean{Y}, \\mean{Y}} & = \\Cov{Y_i, \\mean{Y}} - \\Cov{\\mean{Y}, \\mean{Y}} \\\\\n& = \\Cov{Y_i, \\mean{Y}} - \\Var{\\mean{Y}} \\\\\n& = \\Cov{Y_i, \\mean{Y}} - \\frac{\\sigma^2}{n} \\\\\n\\end{align*}\\]\n\n\n\nAlternatively\nIn fact, we will see that \\(\\iid\\) is a relatively strong assumptions.\n\\[\\begin{align*}\n\\Cov{Y_i, \\mean{Y}} &= \\Cov{Y_1, \\mean{Y}} = \\Cov{ Y_1, \\frac{1}{n}(Y_1 + Y_2 + \\dots + Y_n) } \\\\\n&= \\frac{1}{n} \\left( \\Cov{Y_1, Y_1} + \\Cov{Y_1, Y_2} + \\dots + \\Cov{Y_1, Y_n} \\right) \\\\\n&= \\frac{1}{n} \\left\\{ \\Var{Y_1} + 0 + 0 + \\dots + 0 \\right\\} = \\frac{\\sigma^2}{n}. \\\\\n\\end{align*}\\]\nHence, we know that \\(\\Cov{Y_i, \\mean{Y}} = \\frac{\\sigma^2}{n}\\). In fact from the second proof, we also note that we don‚Äôt actually require\n\n\nCorollary 1 (Unbias Estimator) Following directly from Theorem¬†2, we know that both \\(\\mean{Y}\\) and \\(S^2\\) are unbias Estimator.\n\n\n\nTheorem 3 (Sample Variance) \\[\\begin{equation*}\nS^2 = \\frac{1}{n-1}\\sum_{i=1}^n (y_i - \\mean{y})^2 = \\frac{1}{n-1}\\left(\\left(\\sum_{i=1}^n y_i^2\\right) - n\\mean{y}^2 \\right)\n\\end{equation*}\\]\n\n\nProof. The proof is almost identical to the proof for the analogous theorem of the population variance in Chapter 2 Section 2.1. Therefore, I will not restate here.",
    "crumbs": [
      "Home",
      "CH08 : Estimation",
      "Evaluation Metrics"
    ]
  },
  {
    "objectID": "topics.html",
    "href": "topics.html",
    "title": "STAT2001 Weekly Topics",
    "section": "",
    "text": "This page summarizes the weekly structure of STAT2001: Introductory Mathematical Statistics, including chapter coverage and additional notes. Use this as a guide to plan your revision and track key assessments and resources.\n\n\nWeekly Study Plan\n\n\n\n\n\n\n\nWeek\nTopic\nExtra Information\n\n\n\n\n1\nCH1 Statistics; CH2 Probability\nCalculus notes\n\n\n2\nCH2 Probability\nRefresher Quiz 1, Refresher Quiz 2 on combinatorics\n\n\n3\nCH2 Probability\n\n\n\n4\nCH3 Discrete Random Variables\nMakeup Tue 11/3, Formula sheet, Binomial distribution\n\n\n5\nCH4 Continuous Random Variables\nAssessable Quiz due Fri 21/3, Gamma distribution, R and random variables\n\n\n6\nCH5 Multivariate Probability\nAssignment 1 available\n\n\n‚Äî\nTeaching Break\n\n\n\n7\nCH6 Functions of Random Variables\nAssignment 1 due\n\n\n8\nCH7 Sampling Distributions & CLT\nMakeup Tue 22/4\n\n\n9*\nCH8 Estimation\nAssignment 2 available\n\n\n10\nCH9 Point Estimation\n\n\n\n11\nCH16 Bayesian Methods; CH10\nAssignment 2 due\n\n\n12\nCH10 Hypothesis Testing\nNon-exhaustive summary\n\n\n\n\n\n\n\nChapters refer to the textbook used in the course (check Wattle or course outline for details).\nMakeups and assignments are based on 2025 dates; confirm current year‚Äôs schedule on Wattle.\nThis schedule is intended for student revision and is not officially endorsed by ANU."
  },
  {
    "objectID": "topics.html#weekly-topics-overview",
    "href": "topics.html#weekly-topics-overview",
    "title": "STAT2001 Weekly Topics",
    "section": "",
    "text": "This page summarizes the weekly structure of STAT2001: Introductory Mathematical Statistics, including chapter coverage and additional notes. Use this as a guide to plan your revision and track key assessments and resources.\n\n\nWeekly Study Plan\n\n\n\n\n\n\n\nWeek\nTopic\nExtra Information\n\n\n\n\n1\nCH1 Statistics; CH2 Probability\nCalculus notes\n\n\n2\nCH2 Probability\nRefresher Quiz 1, Refresher Quiz 2 on combinatorics\n\n\n3\nCH2 Probability\n\n\n\n4\nCH3 Discrete Random Variables\nMakeup Tue 11/3, Formula sheet, Binomial distribution\n\n\n5\nCH4 Continuous Random Variables\nAssessable Quiz due Fri 21/3, Gamma distribution, R and random variables\n\n\n6\nCH5 Multivariate Probability\nAssignment 1 available\n\n\n‚Äî\nTeaching Break\n\n\n\n7\nCH6 Functions of Random Variables\nAssignment 1 due\n\n\n8\nCH7 Sampling Distributions & CLT\nMakeup Tue 22/4\n\n\n9*\nCH8 Estimation\nAssignment 2 available\n\n\n10\nCH9 Point Estimation\n\n\n\n11\nCH16 Bayesian Methods; CH10\nAssignment 2 due\n\n\n12\nCH10 Hypothesis Testing\nNon-exhaustive summary\n\n\n\n\n\n\n\nChapters refer to the textbook used in the course (check Wattle or course outline for details).\nMakeups and assignments are based on 2025 dates; confirm current year‚Äôs schedule on Wattle.\nThis schedule is intended for student revision and is not officially endorsed by ANU."
  }
]