[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "This site is your companion for revising STAT2001: Introductory Mathematical Statistics at ANU. Whether you‚Äôre preparing for exams or reinforcing weekly concepts, you‚Äôll find concise summaries, worked examples, and practice materials here.\n\n\n\nThe content is structured to mirror the STAT2001 curriculum:\n\nProbability Foundations: Set theory, combinatorics, and Bayes‚Äô theorem.\nRandom Variables: Discrete and continuous distributions, including moment-generating functions and correlation.\nMultivariate Distributions: Joint, marginal, and conditional distributions.\nSampling Distributions: Understanding the central limit theorem and its applications.\nEstimation Techniques: Methods of moments and maximum likelihood estimation.\nHypothesis Testing: Formulating and testing statistical hypotheses.\nBayesian Statistics: Introduction to Bayesian inference and estimators.\n\n\n\n\n\nAll examples and exercises are implemented using R, the primary statistical computing tool for this course. You‚Äôll also find:\n\nInteractive visualizations to aid understanding.\nCheatsheets summarizing key formulas and concepts.\nPractice questions with step-by-step solutions.\n\n\n\n\n\nNavigate to the Topics page to begin exploring specific areas of the course. For more information about this site, visit the About page.\n\nNote: This site is an independent student-led initiative and is not officially affiliated with ANU."
  },
  {
    "objectID": "index.html#topics-covered",
    "href": "index.html#topics-covered",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "The content is structured to mirror the STAT2001 curriculum:\n\nProbability Foundations: Set theory, combinatorics, and Bayes‚Äô theorem.\nRandom Variables: Discrete and continuous distributions, including moment-generating functions and correlation.\nMultivariate Distributions: Joint, marginal, and conditional distributions.\nSampling Distributions: Understanding the central limit theorem and its applications.\nEstimation Techniques: Methods of moments and maximum likelihood estimation.\nHypothesis Testing: Formulating and testing statistical hypotheses.\nBayesian Statistics: Introduction to Bayesian inference and estimators."
  },
  {
    "objectID": "index.html#tools-and-resources",
    "href": "index.html#tools-and-resources",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "All examples and exercises are implemented using R, the primary statistical computing tool for this course. You‚Äôll also find:\n\nInteractive visualizations to aid understanding.\nCheatsheets summarizing key formulas and concepts.\nPractice questions with step-by-step solutions."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "STAT2001 Revision Hub",
    "section": "",
    "text": "Navigate to the Topics page to begin exploring specific areas of the course. For more information about this site, visit the About page.\n\nNote: This site is an independent student-led initiative and is not officially affiliated with ANU."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "1\n\n\n\n\nüìß Email: isaac.leong@example.com\n\nüíº LinkedIn: linkedin.com/in/isaac-leong\n\nüßë‚Äçüíª GitHub: github.com/Isaac7777-cpu\n\nüìç Location: Canberra, Australia"
  },
  {
    "objectID": "contact.html#my-details",
    "href": "contact.html#my-details",
    "title": "Contact",
    "section": "",
    "text": "üìß Email: isaac.leong@example.com\n\nüíº LinkedIn: linkedin.com/in/isaac-leong\n\nüßë‚Äçüíª GitHub: github.com/Isaac7777-cpu\n\nüìç Location: Canberra, Australia"
  },
  {
    "objectID": "contact.html#footnotes",
    "href": "contact.html#footnotes",
    "title": "Contact",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is just an unrelated photo that I think tastes pretty good.‚Ü©Ô∏é"
  },
  {
    "objectID": "contents/chapter-04/1rv.html",
    "href": "contents/chapter-04/1rv.html",
    "title": "Known Continuous Distributions",
    "section": "",
    "text": "Definition 1 Continuous random variable \\(Y \\sim U(a, b)\\) if its pdf is, \\[\nf(y) = \\frac{1}{b - a}, \\qquad a &lt; y &lt; b (a &lt; b)\n\\]\n\n\n\nTheorem 1 Suppose that \\(Y \\sim U(a, b)\\). Find \\(Y\\)‚Äôs cdf.\n\\[\nF(y) = \\int_a^y \\frac{1}{b-a} \\, dt = \\frac{y - a}{b - a}, \\qquad a &lt; y &lt; b\n\\]\n\n\n\n\n\n\nShow the code\nimport { Inputs } from \"@observablehq/inputs\"\nimport { Plot } from \"@observablehq/plot\"\n\nviewof ua = Inputs.range([0, 10], { label: \"Minimum (a)\", step: 0.1, value: 2 })\nviewof ub = Inputs.range([0, 10], { label: \"Maximum (b)\", step: 0.1, value: 8 })\n\nuniform_xs = Array.from({ length: 100 }, (_, i) =&gt; ua - 1 + (i / 99) * (ub - ua + 2))\n\nuniform_pdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &gt;= ua && x &lt;= ub ? 1 / (ub - ua) : 0\n}))\n\nuniform_cdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &lt; ua ? 0 : x &gt; ub ? 1 : (x - ua) / (ub - ua)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistorgram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.max(...uniform_pdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...uniform_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomUniform(ua, ub)})).plot()",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#uniform-distribution",
    "href": "contents/chapter-04/1rv.html#uniform-distribution",
    "title": "Known Continuous Distributions",
    "section": "",
    "text": "Definition 1 Continuous random variable \\(Y \\sim U(a, b)\\) if its pdf is, \\[\nf(y) = \\frac{1}{b - a}, \\qquad a &lt; y &lt; b (a &lt; b)\n\\]\n\n\n\nTheorem 1 Suppose that \\(Y \\sim U(a, b)\\). Find \\(Y\\)‚Äôs cdf.\n\\[\nF(y) = \\int_a^y \\frac{1}{b-a} \\, dt = \\frac{y - a}{b - a}, \\qquad a &lt; y &lt; b\n\\]\n\n\n\n\n\n\nShow the code\nimport { Inputs } from \"@observablehq/inputs\"\nimport { Plot } from \"@observablehq/plot\"\n\nviewof ua = Inputs.range([0, 10], { label: \"Minimum (a)\", step: 0.1, value: 2 })\nviewof ub = Inputs.range([0, 10], { label: \"Maximum (b)\", step: 0.1, value: 8 })\n\nuniform_xs = Array.from({ length: 100 }, (_, i) =&gt; ua - 1 + (i / 99) * (ub - ua + 2))\n\nuniform_pdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &gt;= ua && x &lt;= ub ? 1 / (ub - ua) : 0\n}))\n\nuniform_cdf = uniform_xs.map(x =&gt; ({\n  x,\n  y: x &lt; ua ? 0 : x &gt; ub ? 1 : (x - ua) / (ub - ua)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistorgram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.max(...uniform_pdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Uniform(${ua}, ${ub})`,\n  marks: [\n    Plot.line(uniform_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...uniform_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomUniform(ua, ub)})).plot()",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#normal-distribution",
    "href": "contents/chapter-04/1rv.html#normal-distribution",
    "title": "Known Continuous Distributions",
    "section": "2 Normal Distribution",
    "text": "2 Normal Distribution\n\nDefinition 2 (Normal Distribution) A random variable \\(Y\\) has the normal distribution with parameters \\(a\\) and \\(b^2\\) if its pdf is of the form\n\\[\nf(y) = \\frac{1}{b\\sqrt{2\\pi}} e^{-\\frac{(y - a)^2}{2b^2}}, \\quad -\\infty &lt; y &lt; \\infty \\, (-\\infty &lt; a &lt; \\infty, b &gt; 0)\n\\]\nWe write \\(Y \\sim \\mathcal{N}(a, b^2)\\).\n\n\n\n2.1 Interactive Widget\n\n\nShow the code\nviewof normal_mu = Inputs.range([-10, 10], { label: \"mean\", step: 0.1, value: 0 })\nviewof normal_var = Inputs.range([0, 10], { label: \"variance\", step: 0.1, value: 1 })\n\nnormal_xs = Array.from({ length: 200 }, (_, i) =&gt; \n  - 4 * 4 + (i / 199) * 8 * 4  // from Œº - 4œÉ to Œº + 4œÉ\n)\n\n// PDF of Normal Distribution\nnormal_pdf = normal_xs.map(x =&gt; ({\n  x,\n  y: (1 / (normal_var * Math.sqrt(2 * Math.PI))) * Math.exp(-0.5 * ((x - normal_mu) / normal_var) ** 2)\n}))\n\n// CDF of Normal Distribution using the error function approximation\nnormal_cdf = normal_xs.map(x =&gt; ({\n  x,\n  y: 0.5 * (1 + erf((x - normal_mu) / (normal_var * Math.sqrt(2))))\n}))\n\n// Helper: error function approximation\nfunction erf(x) {\n  // Abramowitz and Stegun formula 7.1.26\n  const sign = x &gt;= 0 ? 1 : -1\n  const a1 = 0.254829592,\n        a2 = -0.284496736,\n        a3 = 1.421413741,\n        a4 = -1.453152027,\n        a5 = 1.061405429,\n        p = 0.3275911\n\n  const t = 1 / (1 + p * Math.abs(x))\n  const y = 1 - (((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t) * Math.exp(-x * x)\n  return sign * y\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Normal(${normal_mu}, ${normal_var})`,\n  marks: [\n    Plot.line(normal_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.max(...normal_pdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Normal(${normal_mu}, ${normal_var})`,\n  marks: [\n    Plot.line(normal_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...normal_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomNormal(normal_mu, normal_var ** (0.5))})).plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2 Standardisation\nWithout a computer, the only way to evaluate the probability is using a normal distribution table. However, such table only provides information about the standard normal distribution. Therefore, it becomes important to use standardisation to change any r.v. following normal distribution to the standard normal distribution.\n\nTheorem 2 (Standardisation Normal Technique) If \\(Y \\sim \\mathcal{N}(a, b^2)\\), then \\(Z = \\frac{Y - a}{b} \\sim \\mathcal{N}(0, 1)\\).\n\nWe say that \\(Y\\) has been standardised, and that \\(Z\\) is the standardised version of \\(Y\\).\nNote that this technique is used not only for finding the probability in the exam with normal table, this can also be used to normalise the training data for a machine learning model1.",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#gamma-distribution",
    "href": "contents/chapter-04/1rv.html#gamma-distribution",
    "title": "Known Continuous Distributions",
    "section": "3 Gamma Distribution",
    "text": "3 Gamma Distribution\n\nDefinition 3 (Gamma Distribution Pdf) A random variable \\(Y\\) has the gamma distribution with parameters \\(a\\) and \\(b\\) if its pdf is of the form \\[\nf(y) = \\frac{y^{a-1}e^{-y/b}}{b^a \\Gamma(a)}, \\quad y &gt; 0 \\quad (a, b &gt; 0)\n\\]\nWe write \\(Y \\sim \\text{Gam}(a, b)\\).\n\n\n3.1 Mysterious \\(\\Gamma(\\cdot)\\)\n\\(\\Gamma(\\cdot)\\) here is the gamma function, defined by \\(\\Gamma(k) = \\int_0^\\infty t^{k-1}e^{-t}\\, dt\\).\nSome properties:\n\n\\(\\Gamma(k) = (k - 1) \\Gamma(k - 1)\\) if \\(k &gt; 1\\)\n\\(\\Gamma(k) = (k - 1)!\\) if \\(k\\) is a positive integer (e.g.¬†\\(\\Gamma (4) = 3! = 6\\))\n\\(\\Gamma(1/2) = \\sqrt{\\pi}\\)\n\n\n\nShow the code\nfunction gamma(z) {\n  const g = 7\n  const p = [\n    0.99999999999980993,\n    676.5203681218851,\n   -1259.1392167224028,\n    771.32342877765313,\n   -176.61502916214059,\n    12.507343278686905,\n   -0.13857109526572012,\n    9.9843695780195716e-6,\n    1.5056327351493116e-7\n  ]\n\n  if (z &lt; 0.5) {\n    return Math.PI / (Math.sin(Math.PI * z) * gamma(1 - z))\n  } else {\n    z -= 1\n    let x = p[0]\n    for (let i = 1; i &lt; g + 2; i++) {\n      x += p[i] / (z + i)\n    }\n    const t = z + g + 0.5\n    return Math.sqrt(2 * Math.PI) * t**(z + 0.5) * Math.exp(-t) * x\n  }\n}\n\n// Generate values for plotting\ngam_xs = Array.from({ length: 200 }, (_, i) =&gt; 0.01 + i / 199 * (8 - 0.01))\ngamma_data = gam_xs.map(x =&gt; ({ x, y: gamma(x) }))\n\n// Plot\nPlot.plot({\n  title: `Gamma Function Œì(x), from x = 0.01 to ${8}`,\n  marks: [\n    Plot.line(gamma_data, { x: \"x\", y: \"y\", stroke: \"purple\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\", domain: [0, 8] },\n  y: { label: \"Œì(x)\" },\n  width: 600,\n  height: 300\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.2 Mode of Gamma Distribution\n\nTheorem 3 (Mode of Gamma Distribution) \\[\nMode(Y) = \\begin{cases}\nb(a-1) & a \\geq 1 \\\\\n0 & a &lt; 1\n\\end{cases}\n\\]\n\n\n\n\n3.3 Interactive Widget\n\n\nShow the code\nviewof gamma_a = Inputs.range([0.4, 5], { label: \"a\", step: 0.1, value: 1 })\nviewof gamma_b = Inputs.range([0.1, 5], { label: \"b\", step: 0.1, value: 1 })\n\nfunction gammainc_lower(x, a) {\n  // Lower regularized incomplete gamma function P(a, x)\n  // using a simple series expansion\n  let sum = 1 / a\n  let value = 1 / a\n  for (let n = 1; n &lt; 100; n++) {\n    value *= x / (a + n)\n    sum += value\n    if (value &lt; 1e-8) break\n  }\n  return sum * Math.exp(-x + a * Math.log(x)) / gamma(a)\n}\n\nfunction gammaCDF(x, alpha, theta) {\n  if (x &lt;= 0) return 0\n  return gammainc_lower(x / theta, alpha)\n}\n\nfunction gammaPDF(x, a, t) {\n  if (x &lt; 1e-6) return a &lt; 1 ? Infinity : 0\n  return (1 / (t ** a * gamma(a))) * x ** (a - 1) * Math.exp(-x / t)\n}\n\ngamma_xs = [\n  ...Array.from({ length: 100 }, (_, i) =&gt;\n    1e-6 + Math.exp(Math.log(1e-6) + (i / 100) * Math.log(0.5 / 1e-6))  // log scale from 1e-6 to ~0.5\n  ),\n  ...Array.from({ length: 100 }, (_, i) =&gt; 0.5 + i * 0.1)  // linear from 0.5 to 10.4\n]\n\n\n// PDF of Normal Distribution\ngamma_pdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaPDF(x, gamma_a, gamma_b)\n}))\n\n// CDF of Normal Distribution using the error function approximation\ngamma_cdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaCDF(x, gamma_a, gamma_b)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Gamma(${gamma_a}, ${gamma_b})`,\n  marks: [\n    Plot.line(gamma_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...gamma_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Gamma(${gamma_a}, ${gamma_b})`,\n  marks: [\n    Plot.line(gamma_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...gamma_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n// import { Plot, binX, ruleY, line } from \"@observablehq/plot\"\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomGamma(gamma_a, gamma_b)})).plot()\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.4 Conclusion on the Gamma Distribution\nNow, it is clear that the gamma distribution is very expressive with two model parameters. In fact, we can define many specific distribution by using this gamma distribution by fixing some of the model parameters.",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#the-chi2-distribution",
    "href": "contents/chapter-04/1rv.html#the-chi2-distribution",
    "title": "Known Continuous Distributions",
    "section": "4 The Chi2 Distribution",
    "text": "4 The Chi2 Distribution\nBeing a special case of the gamma distribution.\n\nDefinition 4 (Chi-Square Distribution) If \\(Y \\sim \\text{Gam}(n/2, 2)\\), we say that \\(Y\\) has the chi-square distribution with parameter \\(n\\).\nDenote as \\(Y \\sim \\chi^2(n)\\).\n\n\nDefinition 5 (Chi-Square Degree of Freedom) \\(n\\) in the above formulation is the degrees of freedom (DOF).\n\n\nTheorem 4 (Mode of Chi-Square Distribution) The mode of \\(Y\\) is \\(n - 2\\) if \\(n \\geq 2\\), and it is 0 if \\(n \\leq 2\\).\n\n\n\n4.1 Interactive Widget\n\n\nShow the code\nviewof chi_dof = Inputs.range([1, 5], { label: \"dof\", step: 1, value: 1 })\n\n// PDF of Normal Distribution\nchi_pdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaPDF(x, chi_dof / 2, 2)\n}))\n\n// CDF of Normal Distribution using the error function approximation\nchi_cdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaCDF(x, chi_dof / 2, 2)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\n// @title: Gamma PDF \n\nPlot.plot({\n  title: `PDF of Chi(${chi_dof})`,\n  marks: [\n    Plot.line(chi_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...chi_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Normal CDF\n\nPlot.plot({\n  title:  `CDF of Chi(${chi_dof})`,\n  marks: [\n    Plot.line(chi_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...chi_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomGamma(chi_dof / 2, 2)})).plot()",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#exponential-distribution",
    "href": "contents/chapter-04/1rv.html#exponential-distribution",
    "title": "Known Continuous Distributions",
    "section": "5 Exponential Distribution",
    "text": "5 Exponential Distribution\nAnother special case of the gamma distribution\n\nDefinition 6 (Exponential Distribution PDF) If \\(Y \\sim \\text{Gam}(1, b)\\), then \\(Y\\) has the exponential distribution with parameter \\(b\\).\nWe write \\(Y \\sim \\text{Exp}(b)\\) with the corresponding pdf being, \\[\nf(y) = \\frac{1}{b}e^{-y/b}, \\quad y &gt; 0\n\\]\n\nBy using Theorem¬†3, we obtain the following corollary.\n\nCorollary 1 (Mode of Exponential Distribution) \\[\nMode(Y) = 0\n\\]\n\n\nNow, we can establish the following connection with all the other ones have discovered. \\[\n\\text{Exp}(2) = \\text{Gam}(2/2, 2) = \\chi^2(2)\n\\]\n\nThis distribution is useful for modelling times until failure of components and times between successive arrivals in a queue.\n\n\n5.1 Interactive Widget\n\n\nShow the code\nviewof exp_b = Inputs.range([0.1, 5], { label: \"n\", step: 0.1, value: 1 })\n\n// PDF of Normal Distribution\nexp_pdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaPDF(x, 1, exp_b)\n}))\n\n// CDF of Normal Distribution using the error function approximation\nexp_cdf = gamma_xs.map(x =&gt; ({\n  x,\n  y: gammaCDF(x, 1, exp_b)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Exp(${exp_b})`,\n  marks: [\n    Plot.line(exp_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...exp_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title:  `CDF of Exp(${exp_b})`,\n  marks: [\n    Plot.line(exp_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...exp_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomGamma(1, exp_b)})).plot()\n\n\n\n\n\n\n\n\n\n\n\n\n5.2 Standard Exponential Distribution\n\nDefinition 7 (Standard Exponential Distribution) A special case of the exponential distribution.\nIf \\(Y \\sim \\text{Exp}(1)\\), we say that \\(Y\\) has the standard exponential distribution.",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#beta-distribution",
    "href": "contents/chapter-04/1rv.html#beta-distribution",
    "title": "Known Continuous Distributions",
    "section": "6 Beta Distribution",
    "text": "6 Beta Distribution\n\nDefinition 8 (Beta Distribution) A random variable \\(Y\\) has the beta distribution with parameters \\(a\\) and \\(b\\) if its pdf is of the form \\[\nf(y) = \\frac{y^{a-1}(1-y)^{b-1}}{B(a, b)}, \\quad o &lt; y &lt; 1 \\; (a, b &gt; 0)\n\\]\nWe write \\(Y \\sim \\text{Beta}(a, b)\\).\n\nHere, \\(B(a, b) = \\frac{\\Gamma(a) \\Gamma(b)}{\\Gamma(a + b)}\\) is the beta function.\n\n6.1 Connection with Uniform Distribution\nIf \\(a = b = 1\\), then \\(f(y) = 1\\), \\(0 &lt; y &lt; 1\\). Thus \\(\\text{Beta}(1, 1) = U(0, 1)\\).\nIt can be shown that \\(Mode(Y) = (a - 1)/(a + b -2)\\) if \\(a &gt; 1\\) and \\(b &gt; 1\\).\n\n\n\n6.2 Interactive Widget\n\n\nShow the code\nviewof beta_alpha = Inputs.range([0.1, 10], { label: \"alpha\", step: 0.01, value: 1 })\nviewof beta_beta = Inputs.range([0.1, 10], { label: \"beta\", step: 0.01, value: 1 })\n\n// --- More points near edges ---\nbeta_xs = [\n  ...Array.from({ length: 201 }, (_, i) =&gt; i / 200)\n].filter(x =&gt; x &lt;= 1)\n\n// --- Beta PDF ---\nfunction betaPDF(x, a, b) {\n  if (x &lt;= 0 || x &gt;= 1) return 0\n  const numerator = x ** (a - 1) * (1 - x) ** (b - 1)\n  const denominator = gamma(a) * gamma(b) / gamma(a + b)\n  return numerator / denominator\n}\n\n// Regularized incomplete beta function I_x(a, b)\n// This is a simple continued fraction approximation for 0 &lt; x &lt; 1\n// Based on the continued fraction form in NR, adapted for moderate values\n\nfunction betainc(x, a, b) {\n  if (x &lt;= 0) return 0\n  if (x &gt;= 1) return 1\n\n  const lnBeta = Math.log(gamma(a)) + Math.log(gamma(b)) - Math.log(gamma(a + b))\n  const front = Math.exp(\n    a * Math.log(x) + b * Math.log(1 - x) - lnBeta\n  ) / a\n\n  let f = 1, c = 1, d = 0\n  for (let i = 1; i &lt; 100; i++) {\n    const m = i / 2\n    const numerator = (i % 2 === 1)\n      ? (b - m) * x / (a + 2 * m - 1)\n      : -((a + m - 1) * (a + b + m - 1) * x) / ((a + 2 * m - 2) * (a + 2 * m - 1))\n    d = 1 + numerator * d\n    if (Math.abs(d) &lt; 1e-30) d = 1e-30\n    d = 1 / d\n    c = 1 + numerator / c\n    if (Math.abs(c) &lt; 1e-30) c = 1e-30\n    const delta = c * d\n    f *= delta\n    if (Math.abs(delta - 1) &lt; 1e-8) break\n  }\n\n  return front * f\n}\n\n// --- PDF values ---\nbeta_pdf = beta_xs.map(x =&gt; ({\n  x,\n  y: betaPDF(x, beta_alpha, beta_beta)\n}))\n\n// Compute the CDF points using the approximation\nbeta_cdf = beta_xs.map(x =&gt; ({\n  x,\n  y: betainc(x, beta_alpha, beta_beta)\n}))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPDFCDFHistogram (Interactive)\n\n\n\n\nShow the code\nPlot.plot({\n  title: `PDF of Beta(${beta_alpha}, ${beta_beta})`,\n  marks: [\n    Plot.line(beta_pdf, { x: \"x\", y: \"y\" }),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"f(x)\", domain: [0, Math.min(5, Math.max(...beta_pdf.map(d =&gt; d.y)) * 1.2)] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  title: `CDF of Beta(${beta_alpha}, ${beta_beta})`,\n  marks: [\n    Plot.line(beta_cdf, {x: \"x\", y: \"y\"}),\n    Plot.ruleY([0])\n  ],\n  x: { label: \"x\" },\n  y: { label: \"F(x)\", domain: [0, Math.max(...beta_cdf.map(d =&gt; d.y)) * 1.2] },\n  width: 600,\n  height: 250\n})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n// @title: Histogram of Samples\n\nPlot.rectY({length: 10000}, Plot.binX({y: \"count\"}, {x: d3.randomBeta(beta_alpha, beta_beta)})).plot()",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-04/1rv.html#footnotes",
    "href": "contents/chapter-04/1rv.html#footnotes",
    "title": "Known Continuous Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHowever, it is more common to use min-max normalisation.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "chapter-04",
      "Known Continuous Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "",
    "text": "Motivating Example 2\n\n\n\nA committee of two is randomly selected from three teachers, two students, and one parent.\nLet \\(X\\) be the number of teachers on the committe, and \\(Y\\) the number of students.\nFind:\n\n\nthe marginal pmf of \\(Y\\)\n\n\nthe conditional pmf of \\(Y\\) given that \\(X = 0\\)\n\n\nthe correlation between \\(X\\) and \\(Y\\)\n\n\n\n\n\n\n\\(X\\) and \\(Y\\) have joint probability mass function \\(p(x, y)\\) given by\n\\[\np(x, y) = \\frac{\\binom{3}{x} \\binom{2}{x} \\binom{1}{2 - x - y}}{\\binom{6}{2}}\n\\]\nFor \\(x \\in [0, 2]\\) and \\(y \\in [0, 2]\\) with constraint \\(1 \\leq x + y \\leq 2\\)\nHence, we can fill in the following table remembering that it needs two people for the committee.\n\n\n\nX \\ Y\n0\n1\n2\n\n\n\n\n0\n\\\n2/15 = 0.13\n1 / 15 = 0.07\n\n\n1\n3 / 15 = 0.2\n6/15 = 0.4\n\\\n\n\n2\n3 / 15 = 0.2\n\\\n\\\n\n\n\nTherefore, we get that the marginal probability of \\(Y\\) is\n\\[\np_Y(y) = \\begin{cases}\n6/15, & y = 0 \\\\\n8/15, & y = 1 \\\\\n1/15, & y = 2 \\\\\n\\end{cases}\n\\]\n\n\n\n\nThe conditional pmf of \\(Y\\) given that \\(X = 0\\) is trivial from the above as,\n\\[\np_{Y\\mid X}(y|0) = \\begin{cases}\n0, & y = 0 \\\\\n2/3, & y = 1 \\\\\n1/3, & y = 2 \\\\\n\\end{cases}\n\\]\n\n\nThe Correlation between \\(X\\) and \\(Y\\)\n\nFirst, find the expectations of \\(X\\) and \\(Y\\) first as,\n\\[\n\\begin{align}\nE(X) &= 1 \\times 0.6 + 2 \\times 0.2 = 1 \\\\\nE(Y) &= 1 \\times \\frac{8}{15} + 2 \\times \\frac{1}{15} = 0.67 \\\\\n\\end{align}\n\\]\nHence,\n\\[\n\\begin{align}\nCov(X, Y) &= E(XY) - \\frac{2}{3} \\\\\n&= \\frac{6}{15} - \\frac{2}{3} \\\\\n&= -\\frac{4}{15} = -0.27\n\\end{align}\n\\]\nNow, in order to find the correlation, we also need to find the standard deviation of the two random variables.\n\\[\n\\begin{align}\nVar(X) & = E(X^2) - \\mu_X^2 = \\frac{9}{15} + 2^2 \\frac{3}{15} - 1 = \\frac{9 + 12 - 15}{15} = \\frac{6}{15} \\\\\nVar(Y) & = E(Y^2) - \\mu_Y^2 = \\frac{8}{15} + 2^2 \\frac{1}{15} - \\frac{4}{9} = \\frac{12 * 15 - 100}{225} = \\frac{80}{225} = \\frac{16}{45} = 0.36 \\\\\n\\end{align}\n\\]\nTherefore, the correlation is,\n\\[\nCor(X, Y) = \\frac{Cov(X, Y)}{\\sqrt{6/15}\\sqrt{16/45}} = -\\frac{1}{\\sqrt{2}} = -0.7071\n\\]",
    "crumbs": [
      "Home",
      "chapter-05",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#multinomial-cefficients",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#multinomial-cefficients",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "3.1 Multinomial Cefficients",
    "text": "3.1 Multinomial Cefficients\nThe number of ways of partitioning \\(n\\) distinct objects into \\(k\\) distinct groups is\n\\[\n\\binom{n}{y_1 \\ldots y_k} = \\frac{n!}{y_1 ! y_2 ! \\ldots y_k !}, \\qquad y_i = \\text{count in $i$-th group}\n\\]\n\n\n\nTable¬†1: An Example Sequence\n\n\n\n\n\nTrial\n1\n2\n3\n4\n5\n\nn\n\n\n\n\nGroup\n1\n3\n5\n1\n1\n\n2\n\n\n\n\n\n\nGiven the sequence in Table¬†1, we can state the probability as \\[\n\\begin{align}\nP(sequence) &= p_1p_3p_5p_1p_1\\cdots p_2 \\\\\n&= p_1^{y_1} \\ldots p_k^{y_k}\n\\end{align}\n\\]\nThe probability of obtaining a distinct sequene where we observe \\(y_1, y_2, \\ldots y_k\\) is given by \\[\nP(y_1, y_2, \\ldots , y_k) = \\binom{n}{y_1 \\ldots y_k} p_1^{y_1}p_2^{y_2} \\ldots p_k^{y_k}\n\\]",
    "crumbs": [
      "Home",
      "chapter-05",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#example",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#example",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "3.2 Example",
    "text": "3.2 Example\nOn 10 rolls of a die, what‚Äôs the pr there will result 3 even numbers and 2 ones?\nLet \\(Y_1\\) be the number of even numbers, \\(Y_2\\) be number of ones, and \\(Y_3\\) be number of threes and fives (non-evens and non-ones).\nThen \\(Y_1, Y_2, Y_3 \\sim \\text{Multi}(10; 1/2, 1/6, 1/3)\\) with pmf \\[\np(y_1, y_2, y_3) = \\frac{10!}{y_1 ! y_2 ! y_3 !} \\left( \\frac{1}{2} \\right)^{y_1} \\left( \\frac{1}{6} \\right)^{y_2} \\left( \\frac{1}{3} \\right)^{y_3}\n\\] So, \\[\np(3, 2, 5) =\\frac{10!}{3! 2! 5!} \\left( \\frac{1}{2} \\right)^3 \\left( \\frac{1}{6} \\right)^2 \\left( \\frac{1}{3} \\right)^5 = 0.03601\n\\]",
    "crumbs": [
      "Home",
      "chapter-05",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#random-expectations",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#random-expectations",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "6.1 Random Expectations",
    "text": "6.1 Random Expectations\n\nDefinition 1 (Random Expectations) By \\(E(X\\mid Y)\\), we denote the function \\(E(X\\mid Y = y)\\) with \\(y\\) replaced by \\(Y\\). This would then makes \\(E(X \\mid Y)\\) also be a random variable for which we can also apply expectations.\n\nFor example, the above would have the random expectations fo \\(X|Y\\) as \\[\nE(X \\mid Y) = \\frac{4}{3} Y\n\\]. Note that \\(E(X \\mid Y)\\) would be a random variable about \\(Y\\) rather than \\(X\\) as we have already taken the expectation over \\(X\\).",
    "crumbs": [
      "Home",
      "chapter-05",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#the-law-of-iterated-expectation",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#the-law-of-iterated-expectation",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "6.2 The Law of Iterated Expectation",
    "text": "6.2 The Law of Iterated Expectation\n\n\n\n\n\n\nApplications\n\n\n\nThis theorem is commonly used in Bayesian Inference as we will discuss in CH16.\n\n\n\nTheorem 4 (Law of Iterated Expectation) \\[\nE(X) = E(E(X \\mid Y))\n\\]\n\n\nProof. \\[\n\\begin{align}\nE(E(X\\mid Y)) & = \\int E(X | Y = y) f(y) \\, dy = \\int \\left( \\int x f(x \\mid y) \\, dx \\right) f(y) \\, dy \\\\\n& = \\iint x f(x, y) \\, dxdy = E(X)\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "chapter-05",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#related-definitions-and-results",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#related-definitions-and-results",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "6.3 Related Definitions and Results",
    "text": "6.3 Related Definitions and Results\n\nDefinition 2 (Conditional Expectation on Function of Random Variable) \\[\nE(g(X) \\mid Y = y) = \\begin{cases}\n\\sum_x g(x) p(x\\mid y), & \\text{if $X$ is discrete} \\\\\n\\int g(x) f(x \\mid y), & \\text{if $X$ is continuous} \\\\\n\\end{cases}\n\\]\n\\[\nE(g(X) \\mid Y) = E(g(X) \\mid Y)\n\\]\n\n\nDefinition 3 (Variance on Conditional Variable) As before, since we have obtained the expectation, we can also in a similar fashion define the variance with the expectation.\n\\[\nVar(X \\mid Y = y) = E \\left[ \\left( X - E(X \\mid Y = y) \\right)^2 \\middle\\vert Y = y \\right]\n\\]\n\n\nDefinition 4 (Conditional Covariance) \\[\nCov(X,Z) = E \\left[ (X - E(X \\mid Y = y))(Z - E(Z \\mid Y = y)) \\middle \\vert Y =y  \\right]\n\\]\n\n\nEquipped with the three definitions above, we can derivce the following alternative expression of the unconditional variables.\n\nTheorem 5 (Law of Iterated Expectation (Function of R.V.)) \\[\nE(g(X)) = E(E(g(X) \\mid Y))\n\\]\n\n\nTheorem 6 (Iterated Variance) Similar to Theorem¬†5, we can use that to derive a ‚Äúiterated‚Äù variance.\n\\[\nVar(X) = E(Var(X \\mid Y)) + Var(E(X \\mid Y))\n\\]\n\n\nTheorem 7 (Iterated Covariance) \\[\nCov(X, Z) = E(Cov(X, Z \\mid Y)) + Cov(E(X \\mid Y), E(Z \\mid Y))\n\\]\n\n\n\n6.3.1 Proofs‚Ä¶?\nThe proof of Theorem¬†5 is almost equivalent as the proof that is required for Theorem¬†4. The following will present the proof of Theorem¬†6 and Theorem¬†7.\n\n6.3.1.1 Proof of Theorem¬†6\n\nProof (Proof of Theorem¬†6). \\[\n\\begin{align}\n\\text{RHS} &= E\\left[ E\\left[ \\left( X - E\\left[X \\middle \\vert Y\\right] \\right)^2 \\middle \\vert Y \\right] \\right] + E\\left[ \\left(E\\left[X \\mid Y\\right] - E\\left[E\\left[X \\middle \\vert Y\\right]\\right]\\right)^2 \\right] \\\\\n& = E\\left[ (X - E(X \\mid Y))^2 \\right] + E\\left[ (E(X \\mid Y) - E(X))^2 \\right] \\\\\n& = E \\left[ (X-E[X \\mid Y])^2 + (E(X \\mid Y) - E(X))^2 \\right] \\\\\n& = E \\left[ X^2 - 2XE[X\\mid Y] + (E[X \\mid Y])^2 + (E[X \\mid Y])^2 - 2E(X)E(X|Y) + (E[X])^2 \\right] \\\\\n& = E[X^2] - 2 E[XE[X \\mid Y]] + 2E[(E[X \\mid Y])^2] -2E[X]E[E[X \\mid Y]] + (E[X])^2 \\\\\n& = E[X^2] - (E[X])^2 - 2E[XE[X \\mid Y]] + 2E[(E[X\\mid Y])^2] \\\\\n& = Var(X) - 2E[XE[X \\mid Y]] + 2E[(E[X \\mid Y])^2] \\\\\n\\end{align}\n\\]\nNow, if we can prove the law two terms sum to zero, we have proven the identity. In fact, we only need to show that \\[E[XE[X \\mid Y]] = E[(E[X \\mid Y])^2]\\]. Before, that, we will first show the following lemman is true.\n\nLemma 1 \\[\nE[X \\cdot g(Y)] = E[E[X \\mid Y] \\cdot g(Y)]\n\\]\n\nThe following gives the proof for continuous case in Lemma¬†1 and discrete case should follow closely. First, we again apply Theorem¬†5 (The Law of Iterated Expectations). \\[\nE[X \\cdot g(Y)] = E[E[X \\cdot g(Y) \\mid Y]]\n\\]\nNow, the following will fill in the proof for Lemma¬†1. \\[\n\\begin{align}\nE[X \\cdot g(Y) \\mid Y = y] & = E[X \\cdot g(y) \\mid Y = y] \\\\\n& = \\int_x xg(y) P[X = x \\mid Y = y] \\, dx \\\\\n& = g(y) \\int_x x P[X = x \\mid Y = y] \\, dx \\\\\n& = g(y) E[X \\mid Y = y]\n\\end{align}\n\\]\nTherefore, from the definition of random expectations (Definition¬†1), we know the following, \\[\nE[X \\cdot g(Y) \\mid Y] = g(Y) E[X \\mid Y = Y] = g(Y) E[X \\mid Y]\n\\]\nThen, we can simply apply Lemma¬†1 to the following by treating \\(g(Y) = E[X \\mid Y]\\), \\[\n\\begin{align}\nE[XE[X \\mid Y]] &= E[E[X\\cdot E[X \\mid Y] \\mid Y ]] \\\\\n&= E[E[X \\cdot g(Y) \\mid Y]] \\qquad (\\text{Let $g(Y) = E[X \\mid Y]$}) \\\\\n&= E[g(Y) E[X \\mid Y]] = E[(E[X \\mid Y])^2]\n\\end{align}\n\\] in which the lemman is applied in the second step.\n\n\n\n6.3.1.2 Proof of Theorem¬†7\n\nProof (Proof of Theorem¬†7). Similar to above, we will first expand the terms and see if there is any things we can reduce.\n\\[\n\\begin{align}\n\\text{RHS} &= E\\left[ E\\left[ (X - E[X \\mid Y])(Z - E[Z \\mid Y]) \\mid Y \\right] \\right] + E\\left[ (E[X \\mid Y] - E[E[X \\mid Y]])(E[Z \\mid Y] - E[E[Z \\mid Y]]) \\right] \\\\\n& = E[(X - E[X \\mid Y])(Z - E[Z \\mid Y])] + E\\left[ (E[X \\mid Y] - E[X])(E[Z \\mid Y] - E[Z]) \\right] \\\\\n\\end{align}\n\\]\nThe last step is arrived by using the law of iterated expectation. Now, let‚Äôs simply the first term first,\n\\[\n\\begin{align}\nE\\left[ (X - E[X \\mid Y])(Z - E[Z \\mid Y]) \\right] & = E[XZ - X E[Z \\mid Y] - ZE[X \\mid Y] + E[X\\mid Y]E[Z \\mid Y]] \\\\\n& = E[XZ] - E[XE[Z \\mid Y]] - E[Z E[X \\mid Y]] + E[E[X \\mid Y]E[Z \\mid Y]] \\\\\n& = E[XZ - E[X\\mid Y]E[Z \\mid Y]]\n\\end{align}\n\\]\nGoing from line (2) to line (3) is by using Lemma¬†1 as same way as it is applied in the last step in the proof of Theorem¬†6 above. Then, the original expression is simplified as,\n\\[\n\\begin{align}\n\\text{Exp} & = E[XZ - E[X\\mid Y]E[Z\\mid Y] + (E[X \\mid Y] - E[X])(E[Z \\mid Y] - E[Z])] \\\\\n& = E[XZ - E[X \\mid Y][Z \\mid Y] + E[X\\mid Y][Z \\mid Y] - E[X]E[Z \\mid Y] - E[Z]E[X \\mid Y] + E[X]E[Z]] \\\\\n& = E[XZ] - E[X]E[Z] - E[X]E[E[Z \\mid Y] + E[Z]E[E[X\\mid Y]]] \\\\\n& = E[XZ] - E[X]E[Z] - E[X]E[Z] + E[Z]E[X] \\\\\n& = E[XZ] - E[X]E[Z] = Cov(X, Z) \\\\\n\\end{align}\n\\]\n\n\n\n\n\n\n\nComment\n\n\n\nHence, we can see that the hard part is actually to see Lemma¬†1 which is done in the last proof. Hence, this proof is relatively simple.\n\n\n\n\n\n6.3.2 Examples\n\n\n\n\n\n\nExample 7\n\n\n\nTwenty bolts have just been randomly sampled from the production line in a factory. You are now going to count the number of defectives amongst them.\nFrom experience, you know that the proportion of defective bolts produced in the factory is constant throughout any given day, but varies from day to day in a uniform manner between \\(0.1\\) and \\(0.3\\).\nFind:\n\nHow many defective bolts do you expect to find?\nWhat is the variance of the number of defective bolts?\n\nSolution:\n\n\nHow many defective bolts do you expect to find?\n\nLet \\(X\\) be the number of defectives amongst the 20, and let \\(Y\\) be the proportion of defectives amongst all bolts produced in the factory today.\nThen \\((X | Y = y) \\sim \\text{Bin}(20, y)\\), and \\(Y \\sim U(0.1, 0.3)\\). So \\(E[X \\mid Y = y] = 20y \\implies E[X \\mid Y] = 20Y\\) and \\(E[Y] = 0.2\\).\nTherefore, \\(E[X] = E[E[X \\mid Y]] = E[20Y] = 20 \\times 0.2 = 4\\).\n\n\nWhat is the variance of the number of defective bolts?\n\nSimilarly, we will use Theorem¬†6 to determine the variance.\nFirst, \\[Var[Y] = \\frac{0.04}{12} = \\frac{1}{300} = 0.0033 \\hspace{30pt} E[Y^2] = Var(Y) + (E[Y])^2 = \\frac{13}{300} = 0.43\\]. Also, we now that \\[Var(X \\mid Y) = nY(1-Y)\\] since \\((X \\mid Y = y) \\sim \\text{Bin}(20, y)\\). Therefore, \\[\n\\begin{align}\nVar(X) &= E[Var(X \\mid Y)] + Var(E[X \\mid Y]) \\\\\n& = E[20Y(1 - Y)] + Var(20Y) \\\\\n& = E[20Y] - E[20Y^2] + 400Var(Y) \\\\\n& = 20 * 0.2 - 20 \\left(\\frac{13}{300}\\right) + 400 \\left( \\frac{1}{300} \\right) = \\frac{67}{15} = 4.4667 \\\\\n\\end{align}\n\\]\n\nI think this example question can easily become a bayesian estimate question by throwing another question about the distribution of \\(Y | X\\).",
    "crumbs": [
      "Home",
      "chapter-05",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#footnotes",
    "href": "contents/chapter-05/02-continuous-joint-probability-and-expectations-2.html#footnotes",
    "title": "Joint Continuous Distribution & Expectations (2)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI believe this is generally a plausible assumptions to make otherwise it is possible to run out of items when you are performing the trials.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "chapter-05",
      "Joint Continuous Distribution & Expectations (2)"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html",
    "href": "contents/chapter-05/01-distributions.html",
    "title": "Introduction",
    "section": "",
    "text": "Motivating Example\n\n\n\nA die is rolled. Let \\(X\\) = no. of 6‚Äôs and \\(Y\\) = no. of even numbers. Find the joint probability distribution of \\(X\\) and \\(Y\\).\n\n\n\n\nTable¬†1: Possible Outcomes\n\n\n\n\n\nNumber on Die\n1\n2\n3\n4\n5\n6\n\n\n\n\nValue of X\n0\n0\n0\n0\n0\n1\n\n\nValue of Y\n0\n1\n0\n1\n0\n1\n\n\n\n\n\n\nHence,\n\\[\n\\begin{align}\n   P(X = 1, Y = 1) &= P(6) = 1 / 6 \\\\\n   P(X = 0, Y = 1) &= P(2 \\text{ or } 4)  = 1/ 3 \\\\\n   P(X = 0, Y = 0) &= P(1 \\text{ or } 3 \\text{ or } 5) = 1/2 \\\\\n\\end{align}\n\\]\nWe say that \\(X\\) and \\(Y\\) have a joint probability distribution. The joint pmf of \\(X\\) and \\(Y\\) is\n\\[\np(x, y) = P(X = x, Y = y) = \\begin{cases}\n   1/2, & x = y = 0 \\\\\n   1/3, & x = 0, y = 1 \\\\\n   1/6, & x = y = 1 \\\\\n\\end{cases}\n\\]\nNote that the joint probability distribution of \\(X\\) and \\(Y\\) can be presented as,\n\n\n\nAnother way to present",
    "crumbs": [
      "Home",
      "chapter-05",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#properties",
    "href": "contents/chapter-05/01-distributions.html#properties",
    "title": "Introduction",
    "section": "1.1 Properties",
    "text": "1.1 Properties\n\n\\(0 \\leq p(x, y) \\leq 1\\) for all \\(x\\) and \\(y\\)\n\\(\\sum_{x, y} p(x, y) = 1\\)",
    "crumbs": [
      "Home",
      "chapter-05",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#properties-of-joint-cdfs",
    "href": "contents/chapter-05/01-distributions.html#properties-of-joint-cdfs",
    "title": "Introduction",
    "section": "2.1 Properties of joint CDFs",
    "text": "2.1 Properties of joint CDFs\n\n\\(F(x, y) \\to 0\\) as \\(x \\to -\\infty\\) or \\(y \\to -\\infty\\) (or both).\n\\(F(x, y) \\to 1\\) as \\(x \\to \\infty\\) and \\(y \\to \\infty\\)\n\\(F(x, y)\\) is nondecreasing in both \\(x\\) and \\(y\\) directions.\n\\(F(x, y)\\) is right-continuous in both \\(x\\) and \\(y\\) directions.\n\nNote that with their properties in mind, the joint cdf of \\(X\\) and \\(Y\\) in our example could be written more simply as\n\\[\nF(x, y) = \\begin{cases}\n   1/2, & x \\geq 0, 0 \\leq y &lt; 1 \\\\\n   5/6, & 0 \\leq x &lt; 1, y \\geq 1  \\\\\n\\end{cases}\n\\]",
    "crumbs": [
      "Home",
      "chapter-05",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#marginal-cdf",
    "href": "contents/chapter-05/01-distributions.html#marginal-cdf",
    "title": "Introduction",
    "section": "3.1 Marginal CDF",
    "text": "3.1 Marginal CDF\nThen, we can easily define the cdf of \\(X\\) with the above definition of the marginal pmf of \\(X\\) as \\[\nF(x) = P(X \\leq x)\n\\]",
    "crumbs": [
      "Home",
      "chapter-05",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#degenerate-distribution",
    "href": "contents/chapter-05/01-distributions.html#degenerate-distribution",
    "title": "Introduction",
    "section": "4.1 Degenerate Distribution",
    "text": "4.1 Degenerate Distribution\nIt is possible that the probability of \\(X\\) collapses to only one outcome and it is certain about that outcome with the given y-values.",
    "crumbs": [
      "Home",
      "chapter-05",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#covariance-and-correlation",
    "href": "contents/chapter-05/01-distributions.html#covariance-and-correlation",
    "title": "Introduction",
    "section": "6.1 Covariance and Correlation",
    "text": "6.1 Covariance and Correlation\n\nTheorem 1 (Another Expression of Covariance) The covariance between \\(X\\) and \\(Y\\) is \\[\nCov(X,Y) = E\\{ ( X - E(X))(Y - E(Y)) \\}\n\\]\n\nWhat‚Äôs the covariance between \\(X\\) and \\(Y\\) in our example?\nRecall that \\(X \\sim \\text{Bern}(1/6)\\) and \\(Y \\sim \\text{Bern}(1/2)\\). Therefore \\(E(X) = 1/6\\) and \\(E(Y) = 1/2\\).\nIt follows that \\[\n\\begin{align}\nCov(X, Y) & = \\sum_{x, y} \\left(x - \\frac{1}{6} \\right)\\left(y - \\frac{1}{2}\\right) p(x, y) \\\\\n& =\\frac{1}{12} \\frac{1}{2} + \\left(-\\frac{1}{12}\\right)\\frac{1}{3} + \\frac{5}{12}\\frac{1}{6} = \\frac{1}{12} \\\\\n\\end{align}\n\\]\nA useful result: \\[\nCov(X, Y) = E(XY) - E(X)E(Y)\n\\]\n\nProof. \\[\n\\begin{align}\n\\text{LHS} &= E\\{ (X - \\mu_X)(Y - \\mu_Y) \\} = E \\{ XY - X \\mu_X - Y \\mu_Y + \\mu_X \\mu_Y \\} \\\\\n& = E(XY) - E(X)\\mu_Y - E(Y)\\mu_X + \\mu_X \\mu_Y \\\\\n& = E(XY) - \\mu_X \\mu_Y = \\text{RHS}\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "chapter-05",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-05/01-distributions.html#correlation",
    "href": "contents/chapter-05/01-distributions.html#correlation",
    "title": "Introduction",
    "section": "6.2 Correlation",
    "text": "6.2 Correlation\nThe correlation between \\(X\\) and \\(Y\\) is \\[\n\\rho = Cor(X, Y) = \\frac{Cov(X, Y)}{SD(X)SD(Y)} = \\frac{Cov(X, Y)}{\\sqrt{Var(X)} \\sqrt{Var(Y)}}\n\\]\nNote that this is slightly more useful because this coefficient is ‚Äúnormalised‚Äù between \\(-1\\) and \\(1\\).\n\n6.2.1 Meaning\n\\(\\rho\\) provides information about the relationship between \\(X\\) and \\(Y\\). If \\(\\rho &gt; 0\\) then high values of \\(X\\) are associated with high values of \\(Y\\). If \\(\\rho &lt; 0\\), then high values of \\(X\\) are associated with low values of \\(Y\\).\n\\(-1 \\leq \\rho \\leq 1\\) (In contrast \\(Cov(X, Y) \\in [-\\infty, \\infty]\\).\n\nTheorem 2 \\[X \\perp Y \\implies \\rho = 0\\]\n\n\nProof. First, we can show that \\(Cov(X, Y) = 0\\) if the two random variables are independent.\n\\[\n\\begin{align}\nCov(X, Y) &= E(XY) - \\mu_X \\mu_Y \\\\\n& = E(X)E(Y) - \\mu_X \\mu_Y = 0\n\\end{align}\n\\]\nWhere as the first line is by Theorem¬†1 and the second line is by independence of the two random variables.\nNow, since \\(\\rho = \\frac{Cov(X, Y)}{SD(X)SD(Y)}\\), \\(\\rho = 0\\).",
    "crumbs": [
      "Home",
      "chapter-05",
      "Introduction"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html",
    "href": "contents/chapter-03/1rv.html",
    "title": "Known Discrete Distributions",
    "section": "",
    "text": "The first is the binomial distribution. This has to do with experiments which involve doing something several times, independently, and observing the number of ‚Äòsuccesses‚Äô.\n\n\nExample 1 A die is rolled 7 times. Let \\(Y\\) be the number of 6‚Äôs which come up. Find \\(Y\\)‚Äôs pmf.\n\\[\\begin{align*}\nP(Y = 3) & = P(Three 6's and four non-6's, in any order) \\\\\n& = P(6660000) + P(6606000) + \\cdots + P(0000666) \\\\\n& = \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 + \\left( \\frac{1}{6}\\right)^2 \\frac{5}{6} \\frac{1}{6} \\left( \\frac{5}{6}\\right)^3 + \\cdots + \\left( \\frac{5}{6}\\right)^4 \\left( \\frac{1}{6} \\right)^3 \\\\\n& = \\binom{7}{3} \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 \\approx 0.0781\n\\end{align*}\\]\n\n\nOverall, we can conclude that,\n\nTheorem 1 A random variable \\(Y\\) has the binomial distribution with parameters \\(n\\) and \\(p\\) if its pmf is of the form\n\\[\np(y) = \\binom{n}{y} p^y(1-p)^{n-y}, \\quad y = 0, 1, 2, \\ldots, n\n\\]\n\nWe write \\(Y \\sim \\text{Bin}(n, p)\\). We call \\(n\\) the number of trials and \\(p\\) the probability of success.\n\n\nExample 2 A coin is going to be tossed 10 times. Find the probability that 3 heads come up. Let \\(Y\\) be the number of heads that come up. Then \\(Y \\sim \\text{Bin}(10, 0.5)\\).\nThen this problem is simply evaluating \\(p(3)\\) by using the pm from Theorem¬†1.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#binomial-distribution",
    "href": "contents/chapter-03/1rv.html#binomial-distribution",
    "title": "Known Discrete Distributions",
    "section": "",
    "text": "The first is the binomial distribution. This has to do with experiments which involve doing something several times, independently, and observing the number of ‚Äòsuccesses‚Äô.\n\n\nExample 1 A die is rolled 7 times. Let \\(Y\\) be the number of 6‚Äôs which come up. Find \\(Y\\)‚Äôs pmf.\n\\[\\begin{align*}\nP(Y = 3) & = P(Three 6's and four non-6's, in any order) \\\\\n& = P(6660000) + P(6606000) + \\cdots + P(0000666) \\\\\n& = \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 + \\left( \\frac{1}{6}\\right)^2 \\frac{5}{6} \\frac{1}{6} \\left( \\frac{5}{6}\\right)^3 + \\cdots + \\left( \\frac{5}{6}\\right)^4 \\left( \\frac{1}{6} \\right)^3 \\\\\n& = \\binom{7}{3} \\left( \\frac{1}{6} \\right)^3 \\left( \\frac{5}{6} \\right)^4 \\approx 0.0781\n\\end{align*}\\]\n\n\nOverall, we can conclude that,\n\nTheorem 1 A random variable \\(Y\\) has the binomial distribution with parameters \\(n\\) and \\(p\\) if its pmf is of the form\n\\[\np(y) = \\binom{n}{y} p^y(1-p)^{n-y}, \\quad y = 0, 1, 2, \\ldots, n\n\\]\n\nWe write \\(Y \\sim \\text{Bin}(n, p)\\). We call \\(n\\) the number of trials and \\(p\\) the probability of success.\n\n\nExample 2 A coin is going to be tossed 10 times. Find the probability that 3 heads come up. Let \\(Y\\) be the number of heads that come up. Then \\(Y \\sim \\text{Bin}(10, 0.5)\\).\nThen this problem is simply evaluating \\(p(3)\\) by using the pm from Theorem¬†1.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#bernoulli-distribution",
    "href": "contents/chapter-03/1rv.html#bernoulli-distribution",
    "title": "Known Discrete Distributions",
    "section": "2 Bernoulli Distribution",
    "text": "2 Bernoulli Distribution\nThis is a special case of the binomial distribution when \\(n = 1\\). Hence, we can define a very simple form of pmf.1\n\nTheorem 2 It is easy to see from Theorem¬†1 that\n\\[\np(y) = \\begin{cases}\np & y = 1 \\\\\n1 - p & y = 0 \\\\\n\\end{cases}\n\\]\nwhere \\(0 \\leq p \\leq 1\\).\n\nWe write \\(Y \\sim \\text{Bern}(p)\\) and we cal \\(p\\) the probability of success, as before.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#geometric-distribution",
    "href": "contents/chapter-03/1rv.html#geometric-distribution",
    "title": "Known Discrete Distributions",
    "section": "3 Geometric Distribution",
    "text": "3 Geometric Distribution\nHere is a motivating example for geometric distribution.\n\n\nExample 3 A die is rolled repeated until the first 6 comes up. Find the pmf of \\(Y\\), the number of rolls.\n$P(Y = 3) = P() = P(006) = (5/6)^2(1/6) = 0.0231. Similarly, $P(Y = 4) = (5/6)^3(1/6) = 0.00386.\n\n\nNow, from the above example, we can see that \\(p(y) = (5/6)^{y-1}(1/6), \\quad y = 1, 2, \\ldots\\). We say that \\(Y\\) has a geometric distribution (with parameter \\(1/6\\)).\n\nTheorem 3 A random variable \\(Y\\) has the geometric distribution with parameter \\(p\\) if its pmf is of the form.\n\\[\np(y) = (1 - p)^{y-1}p, \\qquad y = 1, 2, 3, \\ldots\n\\]\nwhere \\(0 \\leq p \\leq 1\\).\n\nWe write \\(Y \\sim \\text{Geo}(p)\\). We call \\(p\\) the probability of success, as before.\n\nTheorem 4 Note that the above geometric pmf is proper.\n\n\nProof. \\[\\begin{align*}\n\\sum_{y=1}^\\infty (1 - p)^{y-1}p & = p \\sum_{x = 0}^{\\infty} (1 - p)^x \\tag{put $x = y - 1$} \\\\\n& = p \\times \\frac{1}{1 - (1 - p)} = 1 \\tag{Property 2}\n\\end{align*}\\]\n\n\n3.1 Application of Geometric Distribution\nNote that the geometric distribution can be used to model waiting times.\n\nExample 4 Suppose that the probability of an engine malfunctioning during any 1-hr period is 0.02. Find the pr that the engine will survive 2 hours.\nLet \\(Y\\) be the number of 1-hr periods until the first malfunction (including the 1-hr period in which that malfunction occurs). Then \\(Y \\sim \\text{Geo}(p)\\), where \\(p = 0.02\\)\nExample: A malfunction in the 3rd 1-hr period means that \\(Y = 3\\).\n\\[\\begin{align*}\nP(Y &gt; 2) & = \\sum_{y=3}^{\\infty} q^{y-1}p \\tag{$q = 1 - p = 0.98$} \\\\\n& = pq^2 \\sum_{y=3}^{\\infty} q^{y-3} \\\\\n& = pq^2 \\sum_{x=0}^{\\infty} q^x \\tag{after putting $x=y - 3$} \\\\\n& = pq^2 \\frac{1}{1 - q} = q^2 = 0.98^ = 0.9604 \\\\\n\\end{align*}\\]\nThis may be calculated more simply as: \\[\nP(Y &gt; 2) = 1 - P(Y \\leq 2) = 1 - (p(1) + p(2)) = 1 - (p + qp) = q^2\n\\]\nor even more simply as: \\[\nP(Y &gt; 2) = P(\\text{Survive 2 hours}) = P(\\text{No failures in first 2 hours}) = q^2\n\\]\n\n\n\n3.2 mgf of Geometric\n\nTheorem 5 (MGF of Geometric Distribution) \\[\\begin{align*}\nE(e^{Yt}) & = \\sum_{y=1}^\\infty e^{yt} (1 - p)^{y-1}p \\\\\n& = pe^t \\sum_{y = 1}^\\infty e^{(y - 1)t} (1 - p)^{y - 1} \\\\\n& = p e^t \\sum_{y = 1}^\\infty ((1 - p)e^t)^(y - 1) \\\\\n& = \\frac{p e^t}{1 - (1 - p)e^t} \\tag{Sum of geometric series} \\\\\n\\end{align*}\\]",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#hypergeometric-distribution",
    "href": "contents/chapter-03/1rv.html#hypergeometric-distribution",
    "title": "Known Discrete Distributions",
    "section": "4 Hypergeometric Distribution",
    "text": "4 Hypergeometric Distribution\n\nExample 5 The motivation of this hypergeometric distribution has to do with sampling objects from a box, without replacement, and observing how many have a certain characteristic.\nA box has 9 marbles, of which 3 are white and 6 are black. You randomly select 5 marbles from the box (without replacement). Find the pmf of \\(Y\\), the number of white marbles amongst the selected 5.\nNumber the 9 marbles \\(1, 2, \\ldots, 9\\) with the first 3 being white and the last 6 black. Then the sample points may be represented by writing 12345, 12346, ‚Ä¶, 56789.\nNote: We don‚Äôt write 13245, because this represents the same sample point as 12345. In other words, the distinct sample points correspond to strings of numbers in increasing order. Hence the total number of sample points is \\(n_S = \\binom{9}{5}\\).\nThe sample points associated with the event \\(Y = 2\\) are 12456, 12457, ‚Ä¶, 23789, and the number of these is $n_2 = . We require 2 numbers to be from 1,2,3, and the other 3 from 4,5,6,7,8,9.\n\\[\nP(Y = 2) = \\frac{n_2}{n_S} = \\frac{\\binom{3}{2}\\binom{6}{3}}{\\binom{9}{5}} = \\frac{3(20)}{126} = \\frac{10}{21} = 0.4762\n\\]\n\\[\nP(Y=1) = \\frac{n_1}{n_S} = \\frac{\\binom{3}{1} \\binom{6}{4}}{\\binom{9}{5}} = \\frac{3(15)}{126} = \\frac{5}{14} = 0.3571\n\\]\nWe see that \\(Y\\) has pmf \\[\np(y) = \\frac{\\binom{3}{y}\\binom{6}{5-y}}{\\binom{9}{5}}, \\quad y = 0,1,2,3.\n\\]\nWe say that \\(Y\\) has a hypergeometric distribution (with parameters 9, 3, and 5).\n\n\n\nTheorem 6 A random variable \\(Y\\) has the hypergeometric distribution with parameters \\(N\\), \\(r\\) and \\(n\\) if its pmf is of the form \\[\np(y) = \\frac{\\binom{r}{y}\\binom{N - r}{n - y}}{\\binom{N}{n}}, \\quad y = 0,1,2,\\ldots,r,\n\\]\nSubject to \\(0 \\leq n - y \\leq N - r\\) and \\(N = 1,2,3,\\ldots; \\; r = 1,2,\\ldots,N; n = 1,2,\\ldots, N\\).\nThe number of black balls sampled, \\(n-y\\), can‚Äôt be less than 0 or more than the total number of black balls in the box, \\(N - r\\).\n\nWe write \\(Y \\sim \\text{Hyp}(N, r, n)\\). We may call \\(N\\) ‚Äúthe number of balls‚Äù (parameter), \\(r\\) ‚Äúthe number of white balls‚Äù, and \\(n\\) ‚Äúthe number of sampled balls‚Äù.\n\n\nExample 6 There are 10 men and 15 women in a room. 8 people are chosen randomly to form a committee. Find the probability that the committee contains 6 women.\nLet \\(Y = \\text{number of women on the committee}\\). Then \\(Y \\sim \\text{Hyp}(25, 15, 8)\\) and so\n\\[\np(6) = \\frac{\\binom{15}{6}\\binom{10}{2}}{\\binom{25}{8}} = 0.2082\n\\]",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#poisson-distribution",
    "href": "contents/chapter-03/1rv.html#poisson-distribution",
    "title": "Known Discrete Distributions",
    "section": "5 Poisson Distribution",
    "text": "5 Poisson Distribution\nGenerally, one can think of the Poisson distribution being when \\(n \\to \\infty\\) version of the binomial distribution with the expected value being \\(\\lambda\\). The derivation is given in the below.\n\nTheorem 7 Poisson distribution is, in essence, a binomial distribution with \\(n \\to \\infty\\) and \\(p = \\lambda / n\\).\n\n\nProof. Now, suppose \\(X \\sim \\text{Bin}(n, \\lambda / n)\\). Then, the above description in the mathematical notation is,\n\\[\n\\begin{align*}\n\\lim_{n \\to \\infty} p_X(x) & = \\lim_{n \\to \\infty} \\binom{n}{x} \\left( \\frac{\\lambda}{n} \\right)^x \\left(1 - \\frac{\\lambda}{n}\\right)^{n-x} \\\\\n& = \\lim_{n \\to \\infty} \\frac{n!}{x! (n-x)!} \\left( \\frac{\\lambda}{n} \\right)^x \\left(1 - \\frac{\\lambda}{n}\\right)^{n-x} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left( \\frac{n!}{(n - x)!} \\frac{1}{n^x} \\right) \\left(1 - \\frac{\\lambda}{n} \\right)^{n - x} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{n - x} \\tag{First part evaluate to 1 with L'Hopital's} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{n} \\left(1 - \\frac{\\lambda}{n}\\right)^{-x} \\\\\n& = \\frac{\\lambda^x}{x!} \\lim_{n \\to \\infty} \\left(1 - \\frac{\\lambda}{n}\\right)^{n} \\tag{The second term is one as the power does not depend on $n$} \\\\\n& = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\\end{align*}\n\\]\nThen, we have two ways to go from here, simply declare that this is the pmf for Poisson or we can confirm this with the ‚Äúknown‚Äù poisson pmf which is, I guess for me, from thin air‚Ä¶\n\n\n\nCorollary 1 The pmf of Poisson distribution is \\[\np(x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\n\\]\n\n\nProof. This is simply a restatement of the results from Theorem¬†7.\n\n\nNow, I guess the remaining part is to show that the expectation is indeed \\(\\lambda\\).\n\nTheorem 8 X () E(X) = \n\n\nProof. \\[\\begin{align*}\nE(X) & = \\sum_{x = 0}^\\infty x \\frac{e^{-\\lambda} \\lambda^x}{x!} \\\\\n& = e^{-\\lambda}\\lambda \\sum_{x=1}^\\infty \\frac{\\lambda^{x-1}}{(y-1)!} \\\\\n& = e^{-\\lambda} \\lambda \\sum_{x=0}^\\infty \\frac{\\lambda^x}{x!} \\\\\n& = e^{-\\lambda}\\lambda e^{\\lambda} = \\lambda \\\\\n\\end{align*}\\]\n\n\nExample 7 \\[\\begin{align*}\nE(Y(Y - 1)) & = \\sum_{y = 0}^\\infty y(y-1) \\frac{\\lambda^y e^{-\\lambda}}{y!} \\\\\n& = \\lambda^2 \\sum_{y = 2}^\\infty \\frac{\\lambda^{y - 2} e^{-\\lambda}}{(y-2)!} \\tag{First two terms are 0} \\\\\n& = \\lambda^2 \\sum_{x=0}^\\infty \\frac{\\lambda^x e^{-\\lambda}}{x!} \\\\\n& = \\lambda^2 \\tag{The infinite sum is 1 as it is the sum of pmf of $X \\sim Pois(\\lambda)$} \\\\\n\\end{align*}\\]\n\nTherefore, \\(Var(Y) = E(Y(Y-1)) + E(Y) - (E(Y))^2 = \\lambda\\).\n\n\n5.1 Poisson Approximation to the Binomial\nThe Binomial distribution can be approximated by the poisson distribution with \\(\\lambda = np\\) when \\(n\\) is ‚Äúlarge‚Äù and \\(p\\) is ‚Äúsmall‚Äù.\nGenerally, the Poisson approximation should be considered only when the exact binomial probability is hard or impossible to calculate. As a rule of thumb, the Poisson approximation is ‚Äògood‚Äô if \\(n\\) is at least 20 and \\(p\\) is at most 0.05, or if \\(n\\) is at least 100 and \\(np\\) is at most 10.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#negative-binomial-distribution",
    "href": "contents/chapter-03/1rv.html#negative-binomial-distribution",
    "title": "Known Discrete Distributions",
    "section": "6 Negative Binomial Distribution",
    "text": "6 Negative Binomial Distribution\nSimilar to geometric distribution where we have independent and identical trials. We observe either success or fail on each trial. The probability of success on each trial is \\(p\\).\nThe geometric distribution handles the case where we are interested in the number of trial on which the first success occurs. \\(Y = 1,2,3,\\ldots\\) counts the number of trials until the first success.\nWhat if we are interested in knowing the number of the trial on which the second, third, or fourth success occurs? \\(Y = r, r+1, r+2, \\ldots\\) (\\(r = 1, 2, 3, \\ldots\\)). \\(r\\) is a parameter (\\(r =1\\) for geometric).\n\nTheorem 9 The pmf og negative binomial distribution is,\n\\[\np(y) = P(Y = y) = \\binom{y - 1}{r - 1} p^{r-1}q^{y-r}\n\\] , where \\(r\\) is the number of success; \\(p\\) and \\(q\\) defined as usual.\nBy simple counting methods as covered before.\n\n\n\nTheorem 10 (Mean of Negative Binomial) Suppose \\(Y \\sim \\text{NegBin}(r, p)\\), then \\(E(Y) = \\frac{r}{p}\\).\n\n\nProof. The direct proof is extremely hard. However, the trick of recognising that a negative binomial distribution is, in fact, nothing more than \\(r\\) geometric distribution put in sequence. Therefore, suppose \\(Y = Y_1 + Y_2 + \\cdots + Y_r\\), where each \\(Y_i\\) follows \\(\\text{Geo}(p)\\). Then,\n\\[\\begin{align*}\nE(Y) & = E(\\sum_{i = 1}^r Y_i) \\\\\n& = \\sum_{i=1}^r E(Y_i) \\\\\n& = \\sum_{i = 1}^r \\frac{1}{p} = \\frac{r}{p} \\\\\n\\end{align*}\\]\nThe last step relies on mgf and expectation from it as shown in Theorem¬†5.\n\n\nTheorem 11 (Variance of Negative Binomial) If \\(Y \\sim \\text{NegBin}(r, p)\\), then \\(Var(Y) = \\frac{r(1-p)}{p^2}\\).\n\n\nProof. Similar to above by using independency and directly decomposing the variance of a geometric distribution.\n\n\n\nTheorem 12 (MGF of Negative Binomial) Suppose \\(Y \\sim \\text{NegBin}(r, n)\\), then \\[\nm_Y(t) = \\left( \\frac{pe^t}{1 - (1 - p)e^t} \\right)^r\n\\]\n\n\nProof. The direct proof is relatively hard to see. However, using Theorem¬†5 with mgf of independent variable is obvious since negative binomial distribution is really just \\(r\\) independent geometric distribution puts in a series.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-03/1rv.html#footnotes",
    "href": "contents/chapter-03/1rv.html#footnotes",
    "title": "Known Discrete Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn fact, many people define this first and simply describe the binomial distribution as a repeated bernoulli trial with bernoulli distribution.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "chapter-03",
      "Known Discrete Distributions"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html",
    "href": "contents/chapter-06/index.html",
    "title": "CH06: Functions of Random Variables",
    "section": "",
    "text": "Transformations of Random Variables\nFind pdf and cdf of functions of randome variables",
    "crumbs": [
      "Home",
      "chapter-06"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#the-cdf-method",
    "href": "contents/chapter-06/index.html#the-cdf-method",
    "title": "CH06: Functions of Random Variables",
    "section": "3.1 The CDF Method",
    "text": "3.1 The CDF Method\n\n\n\n\n\n\nImportant\n\n\n\nThis consists of two steps:\n\nFind the cdf of the rv of interest\nDifferentiate this CDF to obtain the required pdf\n\n\n\n\n\nExample 3 Suppose that \\(Y \\sim U(0, 2)\\). Find the pdf of \\(X = 3Y - 1\\).\n\n\\(X\\) has cdf\n\n\\[\n\\begin{align}\nF_X(x) & = P(X &lt; x) \\\\\n& = P(XY - 1 &lt; x) \\\\\n& = P\\left( Y &lt; \\frac{x+1}{3} \\right) \\\\\n& = \\int_0^{(x+1)/3} \\frac{1}{2} \\, dy \\\\\n& = \\frac{x + 1}{6}, \\qquad -1 &lt; x &lt; 5 \\hspace{10pt} \\text{(since $3(0) - 1$ = -1 and $3(2) - 1 = 5$)} \\\\\n\\end{align}\n\\]\n\nSo \\(X\\) has pdf \\(f(x) = F'(x) = \\frac{1}{6}\\) for \\(-1 &lt; x &lt; 5\\). In other words, \\(X \\sim U(-1, 5)\\).\n\n\n\nExample 4 Suppose that \\(X, Y \\sim ^{iid} U(0, 1)\\). Find the pdf of \\(U = X + Y\\).\nFirst observe that \\(f(x, y) = 1\\), for \\(0 &lt; x &lt; 1\\), \\(0 &lt; y &lt; 1\\).\n\nShow the code\nimport { slider } from \"@jashkenas/inputs\"\n\nviewof u = Inputs.range([0, 2], {step: 0.01, label: \"u\"})\n\nfunction shadedArea(u) {\n  if (u &lt;= 0) return 0;\n  if (u &lt;= 1) return 0.5 * u * u;\n  if (u &lt;= 2) return 1 - 0.5 * (2 - u) * (2 - u);\n  return 1;\n}\n\nPlot.plot({\n  width: 400,\n  height: 400,\n  marginLeft: 40,\n  marginBottom: 40,\n  caption: \"Shaded region bounded by y = u - x and unit square\",\n  x: {\n    domain: [-0.1, 1.1],\n    label: \"x\",\n    ticks: 6\n  },\n  y: {\n    domain: [-0.1, 1.1],\n    label: \"y\",\n    ticks: 6\n  },\n  marks: [\n    // Shaded area under the line y = u - x, clipped to unit square\n    Plot.areaY(\n      d3.range(0, 1.01, 0.01).map(x =&gt; {\n        const y = Math.min(Math.max(u - x, 0), 1);\n        return { x, y };\n      }),\n      {\n        x: \"x\",\n        y: \"y\",\n        fill: \"steelblue\",\n        opacity: 0.5\n      }\n    ),\n\n    // The line y = u - x\n    Plot.line(\n      d3.range(0, 1.01, 0.01).map(x =&gt; ({ x, y: Math.min(1, Math.max(0, u - x)) })),\n      {\n        x: \"x\",\n        y: \"y\",\n        stroke: \"black\"\n      }\n    ),\n\n    // Draw the unit square as a closed path\n    Plot.line(\n      [\n        { x: 0, y: 0 },\n        { x: 1, y: 0 },\n        { x: 1, y: 1 },\n        { x: 0, y: 1 },\n        { x: 0, y: 0 }\n      ],\n      {\n        x: \"x\",\n        y: \"y\",\n        stroke: \"gray\",\n        strokeWidth: 1.5\n      }\n    )\n  ]\n})\nhtml`\n    &lt;p&gt;&lt;strong&gt;Shaded Area:&lt;/strong&gt; ${(shadedArea(u)).toFixed(4)}&lt;/p&gt;\n`\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\nSo \\(U\\) has cdf Now, from the interactive figure above, we see that what we need is exactly the area bounded by the unit square and the line \\(x + y = u\\). Therefore, first suppose \\(u &lt; 1\\), then \\[\n\\begin{align}\nF(u) & = P(U &lt; u) \\\\\n& = P(X + Y &lt; u) \\\\\n& = P(Y &lt; u - X) \\\\\n& = \\frac{1}{2}u^2 \\hspace{10pt} \\text{for $u \\in [0, 1]$}\n\\end{align}\n\\] Now, suppose \\(u &gt; 1\\), then more than half of the square is filled. Therefore, we can look at the not shaded part. The y-value at \\(x=1\\) is \\(u - 1\\). Since, the side lenght is \\(1\\), the length of the unshaded part is \\(1 - (u - 1) = 2 - u\\). Hence, the final area is \\(1 - \\frac{1}{2}(2-u)^2\\). Therefore, the cdf is, \\[\nF(u) = \\begin{cases}\n\\frac{u^2}{2}, & 0 \\leq u &lt; 1 \\\\\n1 - \\frac{1}{2}(2 - u)^2, & 1 \\leq u &lt; 2 \\\\\n\\end{cases}\n\\]\nTherefore \\(U\\) has pdf \\[\nf(u) = F'(u) = \\begin{cases}\nu, & 0 \\leq u &lt; 1 \\\\\n2 - u, & 1 \\leq y &lt; 2 \\\\\n\\end{cases}\n\\]\n\n\n\nExample 5 (Example: Non-monotonic Transformation) Let \\(Y \\sim U(0, 1)\\). Find the pdf of \\(X = Y(1 - Y)\\). \\[\n\\begin{align}\nF(x) &= P(X &lt; x) \\\\\n&= P(Y(1 - Y) &lt; x) \\\\\n&= P(Y - Y^2 - x &lt; 0) \\\\\n&= P\\left( \\left( Y - \\frac{1 + \\sqrt{1 - 4x}}{2} \\right) \\left( Y - \\frac{1 - \\sqrt{1 - 4x}}{2} \\right) \\right) &lt; 0 \\\\\n&= P(Y &lt; \\frac{1 - \\sqrt{1 - 4x}}{2} \\text{ or } Y &gt; \\frac{1 + \\sqrt{1 - 4x}}{2}) \\\\\n&= \\frac{1 - \\sqrt{1 - 4x}}{2} + (1 - \\frac{1 + \\sqrt{1 - 4x}}{2}) \\\\\n&= 1 - \\sqrt{1 - 4x} \\\\\n\\end{align}\n\\]\nNow, the pdf is \\(f(x) = F'(x) = 2(1 - 4x)^{-1/2}\\).",
    "crumbs": [
      "Home",
      "chapter-06"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#the-transformation-method",
    "href": "contents/chapter-06/index.html#the-transformation-method",
    "title": "CH06: Functions of Random Variables",
    "section": "3.2 The Transformation Method",
    "text": "3.2 The Transformation Method\nSuppose that \\(Y\\) is a continuous random variable with pdf \\(f(y)\\), and \\(x = g(y)\\) is a function which is strictly monotonic, for all possible values \\(y\\) of \\(Y\\). Then \\(X = g(Y)\\) has pdf\\[f(x) = f(y) \\left\\lvert \\frac{dy}{dx} \\right\\rvert\\] where \\(y = g^{-1}(x)\\). (This is the inverse function of \\(g\\))\n\nExample 6 (Example 6) Suppose that \\(Y \\sim U(0, 2)\\).\nFind the pdf of \\(X = 3Y - 1\\). (The same as Example¬†3.)\nHere \\(x = 3y - 1\\) is strictly increasing. Therefore \\(y = \\frac{x + 1}{3}\\) and \\(\\frac{dy}{dx} = \\frac{1}{3}\\). Therefore, \\(f(x) = f(y) \\left\\lvert \\frac{1}{3} \\right\\rvert = \\frac{1}{6}\\), the range of \\(x\\) is \\([-1, 5]\\).\n\n\nExample 7 (Example 7) \\(Y \\sim \\mathcal{N}(a, b^2)\\). Find the distribution of \\(Z = \\frac{Y - a}{b}\\).\nNote that this transformation is always strictly monotonic because it is clear that \\(b\\) is positive.\nThen, \\(y = a + bz\\) and, hence, \\(\\frac{dy}{dz} = b\\). Therefore \\[\n\\begin{align}\nf(z) = f(y) \\left\\lvert \\frac{dy}{dz} \\right\\rvert & = \\frac{1}{b \\sqrt{2\\pi}} e^{-\\frac{1}{2b^2} (a + bz - a)^2} \\lvert b \\rvert \\\\\n& = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} z^2}, \\hspace{10pt} -\\infty &lt; z &lt; \\infty\n\\end{align}\n\\]\nThus \\(Z \\sim \\mathcal{N}(0, 1)\\).\n\n\n3.2.1 Special Example of Non-monotonic Transformation\nSuppose \\(Z \\sim \\mathcal{N}(0, 1)\\). Find the distribution of \\(X = Z^2\\).\nIn this case, \\(x = z^2\\) is neither strictly increasing nor strictly decreasing. So the transformation method cannot be directly used, but a alternatives can be used. We could find the pdf of \\(X\\) using the cdf method. We can also use the mgf method as shown later. But before that, we need to develop an idea why transformation method even work.\n\nRemark 1 (Why Transformation Work). Now, we can separate this into two cases ‚Äî strictly increasing and strictly decreasing.\nCase 1: x = g(y) is strictly increasing. This, in particular, refers to region with positive \\(z\\) values. \\[\nx = g(y) \\Leftrightarrow y = g^{-1}(x)\n\\]\nTherefore, if we want to know when is \\(g(y) \\leq x\\), we can use \\(y \\leq g^{-1}(x)\\). Therefore,\\[P(g(Y) \\leq x) = P(Y \\leq g^{-1}(x)) = F_Y(g^{-1}(x))\\]\nHence, \\[\n\\begin{align}\nf_X(x) & = \\frac{dF_X(x)}{dx} = \\frac{dF_Y(g^{-1}(x)}{dx} \\\\\n& = f_Y(g^{-1}(x)) \\cdot \\frac{dg^{-1}(x)}{dx} \\\\\n& = f_Y(y) \\frac{dy}{dx} \\\\\n\\end{align}\n\\]\nCase 2: \\(x = g(y)\\) is strictly decreasing. \\[\nx = g(y) \\Leftrightarrow y = g^{-1}(x)\n\\]\nThen similarly, we know that \\(P(g(Y) \\leq x) = P(Y \\geq g^{-1}(x)) = 1 - F_Y(g^{-1}(x))\\)\n\\[\n\\begin{align}\nf_X(x) & = \\frac{dF_X(x)}{dx} = \\frac{d}{dx}(1 - F_Y(g^{-1}(x))) \\\\\n& = -f_Y(g^{-1}(x)) \\cdot \\frac{dg^{-1}(x)}{dx} \\\\\n& = -f_Y(y) \\frac{dy}{dx} = f_Y(y) \\left\\lvert \\frac{dy}{dx} \\right\\rvert\n\\end{align}\n\\]\nNote that \\(\\frac{dy}{dx} &lt; 0\\) as it is decreasing. Now, we have used the CDF method to essentially shows why the transformation should work.\n\n\nExample 8 (The Distribution of The Square of a Standard Normal) Now, we can come back to our original problem of finding the pdf of \\(X = Z^2\\). From Remark¬†1 above and combined with Example¬†5, we may conject the following formula. \\[\nf_X(x) = \\sum_{g(z) = x} f_Z(z) \\left\\lvert \\frac{dz}{dx} \\right\\rvert\n\\] which \\(Z \\sim \\mathcal{N}(0, 1)\\). Find the distribution of \\(X = Z^2\\).\nTwo roots: \\(z = \\sqrt{x}\\) or \\(z = -\\sqrt{x}\\). Therefore, \\(\\left\\lvert \\frac{dz}{dx} \\right\\rvert = \\frac{1}{2\\sqrt{x}}\\). Therefore, \\[\n\\begin{align}\nf_X(x) = \\sum_{z^2 = x} f_Z(z) \\left\\lvert \\frac{dz}{dx} \\right\\rvert & = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x} \\frac{1}{2\\sqrt{x}} + \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2} x} \\frac{1}{2\\sqrt{x}} \\\\\n& = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x} x^{-\\frac{1}{2}} \\hspace{10pt} \\text{for $0 &lt; x &lt; \\infty$} \\\\\n& = \\frac{1}{\\sqrt{2}\\Gamma(1/2)} e^{-\\frac{1}{2}x} x^{-\\frac{1}{2}} \\hspace{10pt} \\text{for $0 &lt; x \\infty$}\n\\end{align}\n\\]\nThis is the pdf of the gamma distribution with \\(a = 1/2\\), \\(b = 2\\) such that \\(X \\sim Gam(1/2, 2) = \\chi^2(1)\\).",
    "crumbs": [
      "Home",
      "chapter-06"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#the-moment-generating-function-method",
    "href": "contents/chapter-06/index.html#the-moment-generating-function-method",
    "title": "CH06: Functions of Random Variables",
    "section": "3.3 The Moment Generating Function Method",
    "text": "3.3 The Moment Generating Function Method\nRecall that the mgf of a r.v. can uniquely identify the distribution of the random variable \\(X\\). Recall its definition being \\[\nm_X(t) = E\\left( e^{Xt} \\right)\n\\]\n\nExample 9 (The Distribution of The Square of a Standard Normal ‚Äî Revisited) Now, we will try to use the mgf method for the same problem as above.\n\\[\n\\begin{align}\nm_X(t) = E\\left( x^{Xt} \\right) = E\\left( e^{Z^2 t} \\right) & = \\int_{-\\infty}^{\\infty} e^{z^2} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}z^2} \\, dz \\\\\n& = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}z^2(1 - 2t)} \\, dz \\\\\n& = c \\int_{-\\infty}^{\\infty} \\frac{1}{c\\sqrt{2\\pi}} e^{-\\frac{1}{2c^2}z^2} \\, dz \\\\, \\hspace{20pt} \\text{where $c^2 = \\frac{1}{1 - 2t}$} \\\\\n& = c\n\\end{align}\n\\]\nThe last step is true becuase it is the pdf of the random variable with distribution of \\(\\mathcal{N}(0, c^2)\\).\nTherefore, \\(m_X(t) = (1 - 2t)^{-1/2}\\). However, this is the mgf of \\(Gam(1/2, 2)\\). Therefore, it must follows the Chi-Square distribution.\n\nAnother method of working with Example¬†8 and Example¬†9 is by considering the folded normal distribution with \\(Y = \\lvert Z \\rvert\\). Its cdf is relatively easy to obtain by the symmetry of \\(Z\\).\n\nShow the code\nviewof x = Inputs.range([0, 5], {step: 0.0001, label: \"Y\"})\n\nfunction standardNormalPDF(x) {\n  return (1 / Math.sqrt(2 * Math.PI)) * Math.exp(-0.5 * x * x);\n}\n\nfunction normalCDF(y) {\n  return 0.5 * (1 + erf(y / Math.sqrt(2)));\n}\n\n// Approximation of the error function\nfunction erf(x) {\n  // Abramowitz & Stegun formula 7.1.26\n  const sign = x &lt; 0 ? -1 : 1;\n  const a1 =  0.254829592, a2 = -0.284496736, a3 =  1.421413741;\n  const a4 = -1.453152027, a5 =  1.061405429;\n  const p  =  0.3275911;\n  const t = 1 / (1 + p * Math.abs(x));\n  const val = 1 - (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t * Math.exp(-x * x);\n  return sign * val;\n}\n\nxs = d3.range(-4, 4.01, 0.001);\npdfData = xs.map(x =&gt; ({ x, y: standardNormalPDF(x) }));\nshaded = pdfData.filter(d =&gt; d.x &gt;= -x && d.x &lt;= x);\nexcluded_left = pdfData.filter(d =&gt; d.x &lt;= -x);\nexcluded_right = pdfData.filter(d =&gt; d.x &gt;= x);\n\nPlot.plot({\n  width: 500,\n  height: 300,\n  marginLeft: 40,\n  marginBottom: 40,\n  title: \"P(|Z| ‚â§ y)\",\n  x: {\n    domain: [-4, 4],\n    label: \"x\"\n  },\n  y: {\n    label: \"Density\"\n  },\n  marks: [\n    Plot.areaY(shaded, { x: \"x\", y: \"y\", fill: \"steelblue\", opacity: 0.6 }),\n    Plot.areaY(excluded_left, { x: \"x\", y: \"y\", fill: \"lightcoral\", opacity: 0.6 }),\n    Plot.areaY(excluded_right, { x: \"x\", y: \"y\", fill: \"lightcoral\", opacity: 0.6 }),\n    Plot.line(pdfData, { x: \"x\", y: \"y\", stroke: \"black\" })\n  ]\n})\nhtml`&lt;p&gt;&lt;strong&gt;Area P(-y ‚â§ Z ‚â§ y):&lt;/strong&gt; ${(normalCDF(x) - normalCDF(-x)).toFixed(4)}&lt;/p&gt;`\n\n\n\n\n¬†\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n¬†\n\n\n\n\nRemark 2 (Yet Another Method to Arrive to Chi-Square Distribution). Therefore, from the above graph, we can obtain the following,\n\\[\n\\begin{align}\nF_Y(y) = P(Y &lt; y) & = P(\\lvert Z \\rvert &lt; y) \\hspace{20pt} \\text{(The blue region)} \\\\\n& = P(Z &lt; y \\text{ and } Z &gt; -y) \\hspace{20pt} \\text{(The blue region)} \\\\\n& = 1 - 2P(Z &gt; y) \\hspace{20pt} \\text{(Blue = 1 - 2 * Red)} \\\\\n& = 1 - 2 (1 - \\Phi(y)) \\\\\n& = 2 \\Phi(y) - 1 \\\\\nf(y) & = F'(y) = 2\\Phi'(y) = 2\\phi(y) \\\\\n\\end{align}\n\\]\nThen, we can use the basic transformation that \\(X = Z^2 = Y^2\\) which we do not need to deal non-monotonicity as it above. Hence, \\[\n\\left\\lvert \\frac{dy}{dx} \\right\\rvert = \\frac{1}{2\\sqrt{x}}\n\\]\nTherefore, \\[\nf_X(x) = f_Y(y) \\left\\lvert \\frac{dy}{dx} \\right\\rvert = \\frac{2}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x} \\frac{1}{2\\sqrt{x}}, \\qquad x &gt; 0\n\\]\n\n\n3.3.1 Two Useful Results when Applying the MGF Technique\n\nIf \\(X = a + bY\\), then \\[\nm_X(t) = e^{at}m_Y(bt)\n\\]\nIf \\(Y_1, Y_2, \\ldots , Y_n\\) are independent random variables and \\(X = Y_1 + Y_2 + \\cdots + Y_n\\), then \\[\nm_X(t) = m_{Y_1}(t)m_{Y_2}(t) \\ldots m_{Y_n}(t)\n\\]\n\n\nExample 10 \\(Y \\sim N(0, 1)\\). Find the distribution of \\(X = a + bY\\).\n\\[\n\\begin{align}\nm_X(t) &= e^{at} m_Y(bt) \\\\\n& = e^{at} e^{\\frac{1}{2}(bt)^2} \\\\\n& = e^{at + \\frac{1}{2}b^2t^2} \\\\\n\\end{align}\n\\]\nTherefore, \\(X \\sim \\mathcal{N}(a, b^2)\\).\n\n\nExample 11 Suppose that \\(Y_1, Y_2, \\ldots, Y_n\\) are independent gamma rv‚Äôs, such that the \\(i\\)th one has parameters \\(a_i\\) and \\(b\\). Find the distribution of \\(X = Y_1 + Y_2 + \\cdots + Y_n\\).\n\\[\n\\begin{align}\nm_X(t) &= m_{Y_1}(t) m_{Y_2}(t) \\ldots m_{Y_n}(t) \\\\\n& = (1 - bt)^{-a_1} \\cdots (1 - bt)^{-a_n} \\\\\n& = (1 - bt)^{-a}\n\\end{align}\n\\]\nHence \\(X \\sim Gam(a, b)\\) where \\(a = \\sum_i a_i\\).\n\n\nCorollary 1 Since \\(\\chi^2\\) is essentially a gamma distribution, we have \\[\nY_1, \\ldots , Y_n \\sim^{\\text{iid}} \\chi^2(1) \\implies \\sum_i Y_i \\sim \\chi^2(n).\n\\]",
    "crumbs": [
      "Home",
      "chapter-06"
    ]
  },
  {
    "objectID": "contents/chapter-06/index.html#general-formula",
    "href": "contents/chapter-06/index.html#general-formula",
    "title": "CH06: Functions of Random Variables",
    "section": "4.1 General Formula",
    "text": "4.1 General Formula\n\nTheorem 2 (General Formula for Order Statistics) If \\(Y_1, Y_2, \\ldots, Y_n\\) are continuous and iid, then the pdf of the \\(k\\)th order statistic \\(U_k\\) is \\[\nf_{U_k}(u) = \\frac{n!}{(k - 1)!(n-k)!} F(u)^{k - 1} \\left( 1 - F(u) \\right)^{n-k} f(u)\n\\] where \\(f(y)\\) and \\(F(y)\\) are the pdf and cdf of \\(Y_1\\) respectively.\n\n\nProof. First, we will derive the cdf. For \\(P(U_k &lt; u)\\), it requires essentially the \\(k\\)-largest value to be less than \\(u\\). To achieve this, we only need at least \\(k\\) values to be less than \\(u\\) out of all the order statistics. Therefore, \\[\nF_{U_k}(u) = P(U_k &lt; u) = \\sum_{j = k}^n \\binom{n}{j} (F(u))^{j} (1 - F(u))^{n - j}\n\\], where \\(F\\) is the cdf of any \\(Y\\) (as they are all the same).\nNow, we apply the routine algebraic to obtain the pdf. Teh following is a proof provided by Stephen Ge on this blog page hosted on StackExchange. \\[\n\\begin{align}\nf_{U_k}(u) & = \\frac{d}{du}\\left[ \\sum_{j = k}^n \\binom{n}{j} (F(u))^{j} (1 - F(u))^{n - j} \\right] \\\\\n& = \\frac{d}{du}\\left[ \\left( \\sum_{j = k}^{n-1} \\binom{n}{j} (F(u))^{j} (1 - F(u))^{n - j} \\right) + (F(u))^n \\right] \\\\\n& = \\left(\\sum_{j = k}^{n-1} \\binom{n}{j} j f(u) (F(u))^{j-1} (1 - F(u))^{n - j} \\right) \\\\\n& \\qquad - \\left( \\sum_{j = k}^{n-1} \\binom{n}{j} (n - j) f(u) (F(u))^{j} (1 - F(u))^{n - j - 1} \\right) \\\\\n& \\qquad + nf(u)(F(u))^{n-1} \\\\\n& = \\frac{n!}{(k - 1)! (n - k)!}f(u) (F(u))^{k-1} (1 - F(u))^{n - k} \\\\\n& \\qquad + \\left(\\sum_{j = k + 1}^{n-1} \\frac{n!}{(j-1)!(n-j)!} f(u) (F(u))^{j-1} (1 - F(u))^{n - j} \\right) \\\\\n& \\qquad - \\left( \\sum_{j = k}^{n-2} \\frac{n!}{j!(n - j - 1)!} f(u) (F(u))^{j} (1 - F(u))^{n - j - 1} \\right) \\\\\n& \\qquad - n f(u) (F(u))^{n-1} + nf(u)(F(u))^{n-1} \\\\\n& = \\frac{n!}{(k - 1)! (n - k)!}f(u) (F(u))^{k-1} (1 - F(u))^{n - k} \\\\\n\\end{align}\n\\]\nIn the second last step, the two summations would cancel out because they form a telescoping sequence.",
    "crumbs": [
      "Home",
      "chapter-06"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html",
    "href": "contents/chapter-07/index.html",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "",
    "text": "Theorem 1 Suppose that \\(Y_1, Y_2, \\ldots, Y_n \\sim^{\\text{iid}} N(\\mu, \\sigma^2)\\). Let \\[\\bar{Y} = \\frac{1}{n} \\sum_{i = 1}^n y_i \\hspace{20pt} \\text{(the sample mean)}\\]. Then \\[\\bar{Y} \\sim N(\\mu , \\frac{\\sigma^2}{n})\\]\n\n\nProof. In Chapter 6, we showed that linear combinations of normal rv‚Äôs are also normal. So it only remains to find the mean and variance of \\(\\bar{Y}\\).\n\\[\n\\begin{align}\nE[\\bar{Y}] & = E\\left[\\frac{1}{n} \\sum_{i = 1}^n Y_i\\right] \\\\\n& = \\frac{1}{n} \\sum_{i = 1}^n \\mu = \\frac{1}{n}n\\mu = \\mu\nVar(\\bar{Y}) &= \\frac{1}{n^2}\\sum_{i=1}^n Var(Y_i) \\\\\n&= \\frac{1}{n^2} \\sum_{i = 1}^n \\sigma^2 \\\\\n& = \\frac{1}{n^2}n\\sigma^2 = \\frac{\\sigma^2}{n} \\\\\n\\end{align}\n\\]",
    "crumbs": [
      "Home",
      "chapter-07"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#the-t-distribution",
    "href": "contents/chapter-07/index.html#the-t-distribution",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "2.1 The \\(T\\) Distribution",
    "text": "2.1 The \\(T\\) Distribution\n\nDefinition 2 (\\(t\\) Distribution) Suppose that \\(Z \\sim \\mathcal{N}(0, 1)\\), \\(Y \\sim \\chi^2(k)\\) and \\(Z \\perp U\\). We say that the random variable \\[\nY = \\frac{Z}{\\sqrt{U/k}}\n\\] where \\(k\\) being the only parameters has the \\(t\\)-distribution with \\(k\\) degrees of freedom. The pdf of \\(Y\\) is \\[\nf(y) = \\frac{\\Gamma(\\frac{k+1}{2})}{\\sqrt{k\\pi}\\Gamma(k/2)}(1 + \\frac{y^2}{k})^{-\\frac{1}{2}(k+1)} \\hspace{10pt} , \\hspace{10pt} \\infty &lt; y \\infty\n\\]\nWe write \\(Y \\sim t(k)\\) or \\(Y \\sim t_k\\)\n\n\nTheorem 3 (Pdf of \\(t\\) Distribution) \\[\nf(y) = \\frac{\\Gamma(\\frac{k+1}{2})}{\\sqrt{k\\pi}\\Gamma(k/2)}\\left(1 + \\frac{y^2}{k}\\right)^{-\\frac{1}{2}(k+1)} \\hspace{10pt} , \\hspace{10pt} \\infty &lt; y \\infty\n\\]\n\nThe \\(t\\) pdf looks like a standard normal pdf but with ‚Äòfatter‚Äô tails. The \\(t\\) distribution converges to the standard normal distribution as \\(k\\) tends to infinity.\n\nTheorem 4 (Convergence of the \\(t\\) Distribution) \\(t\\) distribution converges to standard normal distributions as degree of freedom tends to infinity.\n\n\nProof (Convergence to Standard Normal). The pdf of \\(Y\\) can be written \\(f(y) = c_k A_k(y) B_k(y)\\), where \\(c_k\\) is a constant (which does not depend on y), \\[\nA_k(y) = \\left[ \\left(1 + \\frac{y^2}{k} \\right)^k \\right]^{-\\frac{1}{2}} \\qquad B_k(y) = \\left( 1 + \\frac{y^2}{k} \\right) ^{-1/2}\n\\] Now, as \\(k \\to \\infty\\), \\(B_k(y) \\to 1\\) and \\(A_k(y) \\to \\left[ e^{y^2} \\right]^{-1/2} = e^{-\\frac{1}{2} y^2}\\). Therefore, as \\(k \\to \\infty\\), the pdf of \\(Y \\sim t(k)\\) converges porportionally to \\(e^{-\\frac{1}{2}y^2}\\), which is the kernel of the \\(\\mathcal{N}(0, 1)\\).\nIn fact it is also possible to show that \\(c_k \\to 1 / \\sqrt{2\\pi}\\). However, I think since we know that the results will be a probability density function, the only plausible \\(c_k\\) really can only be \\(1 / \\sqrt{2\\pi}\\).\n\n\nTheorem 5 (Standardise with Sample Statistic) Suppose that \\(Y_1, Y_2. \\ldots , Y_n \\sim^{\\text{iid}} \\mathcal{N}(\\mu, \\sigma^2)\\). Let \\[\nT = \\frac{\\overline{Y} - \\mu}{S / \\sqrt{n}}\n\\] Then, \\(T \\sim t(n-1)\\).\n\n\nProof. Observe the following facts:\n\nThe standardised random variable with known variance by Corollary¬†1 is, \\[Z = \\frac{\\overline{Y} - \\mu}{\\sigma / \\sqrt{n}}\\]\nThe sampling distribution of the sample variance by Theorem¬†2 is \\[U = \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2(n-1)\\]\n\\(Z \\perp U\\) by Theorem¬†2\n\nIt follows by definition of the \\(t\\) distribution that \\[\nY = \\frac{Z}{\\sqrt{U/(n-1)}} \\sim t(n - 1)\n\\] But \\[\nT = \\frac{\\overline{Y} - \\mu}{S / \\sqrt{n}} = \\frac{\\frac{\\overline{Y} - \\mu}{\\sigma / \\sqrt{n}}}{\\sqrt{\\frac{(n - 1)S^2}{\\sigma^2} / (n - 1)}}  = Y \\sim t(n-1)\n\\]\n\n\n\nExample 3 (T-statistic in action) Setting as Example¬†1. Find the probability that the mean of the \\(9\\) sample volumes will be distant from the population mean by no more than half the sample standard deviation of those \\(9\\) volumes.\n\\[\n\\begin{align}\nP\\left(\\left\\lvert \\overline{Y} - \\mu \\right\\rvert &lt; \\frac{1}{2} S\\right) & = P\\left(-\\frac{1}{2} S &lt; \\overline{Y} - \\mu &lt; \\frac{1}{2} S \\right) \\\\\n& = P\\left(-\\frac{1}{2} &lt; \\frac{\\overline{Y} - \\mu}{S} &lt; \\frac{1}{2} \\right) \\\\\n& = P\\left(-\\frac{3}{2} &lt; \\frac{\\overline{Y} - \\mu}{S / \\sqrt{n}} &lt; \\frac{3}{2} \\right) \\\\\n& = P\\left( -\\frac{3}{2} &lt; T &lt; \\frac{3}{2} \\right) \\\\\n& = 1 - P(T &lt; -1.5)\n\\end{align}\n\\]\nNow, by tables, \\(P(T &lt; -1.397) = 0.1\\) and \\(P(T &lt; -1.860) = 0.05\\). Therefore, \\(P(T &lt; -1.5)\\) is between \\(0.05\\) and \\(0.10\\). So \\(1 - 2P(T &lt; -1.5)\\) is between \\(0.8\\) and \\(0.9\\).",
    "crumbs": [
      "Home",
      "chapter-07"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#the-f-distribution",
    "href": "contents/chapter-07/index.html#the-f-distribution",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "2.2 The \\(F\\) Distribution",
    "text": "2.2 The \\(F\\) Distribution\n\nDefinition 3 Suppose that \\(U \\sim \\chi^2(a)\\), \\(V \\sim \\chi^2(b)\\) and \\(U \\perp V\\). We say that the random variable \\(Y = \\frac{U / a}{V / b}\\) ahs the \\(F\\)-distribution with \\(a\\) numerator and \\(b\\) denominator degrees of freedom.\nWe write \\(Y \\sim F(a, b)\\) or \\(Y \\sim F_{a, b}\\).\n\n\nTheorem 6 The pdf of an \\(F\\) distribution is \\[\nf(y) = \\frac{\\Gamma(\\frac{a+b}{2})}{\\Gamma(a/2)\\Gamma(b/2)} a^{\\frac{a}{2}}b^{\\frac{b}{2}} y^{\\frac{a}{2} - 1} (b + ay) ^{-\\frac{1}{2}(a + b)} \\; , \\hspace{20pt} y &gt; 0\n\\]\n\n\n\nTheorem 7 \\[\nY \\sim F(a, b) \\implies 1/Y \\sim F(b, a)\n\\]\n\n\nProof. Easily proved.\n\n\n\nTheorem 8 (Sampling Distribution of Ratio of Sample Variance) Suppose that: \\[\n\\begin{align}\nX_1, X_2, \\ldots, X_n &\\sim^{\\text{iid}} \\mathcal{N}(\\mu_X, \\sigma_X^2) \\\\\nY_1, Y_2, \\ldots, Y_n &\\sim^{\\text{iid}} \\mathcal{N}(\\mu_Y, \\sigma_Y^2) \\\\\n(X_1, X_2, \\ldots, X_n) &\\perp (Y_1, Y_2, \\ldots , Y_m) \\\\\n\\end{align}\n\\]\nThen \\[\nW = \\frac{S_X^2 / \\sigma_X^2}{S_Y^2 / \\sigma_{Y}^2} \\sim F(n-1, ,m-1)\n\\] where \\[\n\\begin{align}\n\\overline{X} & = \\frac{1}{n}\\sum_{i=1}^n X_i \\\\\n\\overline{Y} & = \\frac{1}{m}\\sum_{i=1}^m Y_i \\\\\nS_X^2 & = \\frac{1}{n-1}\\sum_{i=1}^n(X_i - \\overline{X})^2 \\\\\nS_Y^2 & = \\frac{1}{m-1}\\sum_{i=1}^m(Y_i - \\overline{Y})^2 \\\\\n\\end{align}\n\\]\n\n\nProof. By Theorem¬†2, \\[\n\\begin{align}\n\\frac{(n-1)S_X^2}{\\sigma_X^2} & \\sim \\chi^2(n-1) \\\\\n\\frac{(m-1)S_Y^2}{\\sigma_Y^2} & \\sim \\chi^2(m-1) \\\\\n\\end{align}\n\\]\nBoth are indepndent of each other because the two samples are independent. Hence, by definition, \\[\nW = \\frac{\\frac{(n-1)S_X^2}{\\sigma_X^2}}{\\frac{(m-1)S_Y^2}{\\sigma_Y^2}} \\sim F(n-1, m-1)\n\\]\n\n\n\nExample 4 Same setting as Example¬†1. Suppose that another sample of \\(5\\) bottles is to be taken from the outpu of the same bottling machine. Find the probability that the sample variance of the volumes in these \\(5\\) bottles will be at least \\(7\\) times as large as the sample variance of the volumes in the \\(9\\) bottles that were initially sampled.\n\\[\n\\begin{align}\nP(S_X^2 \\geq Y S_Y^2) & = P\\left( \\frac{S_X^2}{S_Y^2} &gt; 7 \\right) \\\\\n& = P\\left( \\frac{S_X^2 / \\sigma_X^2}{S_Y^2 / \\sigma_Y^2} &gt; 7 \\right) \\\\\n& = P(U &gt; 7) \\\\\n& \\approx P(U &gt; 7.01)\n= 0.010\n\\end{align}\n\\]\nNote that we can simply introduce \\(\\sigma_X\\) and \\(\\sigma_Y\\) because the two samples are know to from the same distribution and should, therefore, have the same population variance.",
    "crumbs": [
      "Home",
      "chapter-07"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#alternative",
    "href": "contents/chapter-07/index.html#alternative",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "3.1 Alternative",
    "text": "3.1 Alternative\nYet another way to think about the CLT is \\(\\sumrv{Y} \\approx \\NormalDist(n\\mu, n\\sigma^2)\\), where \\(\\sumrv{Y} = Y_1 + Y_2 + \\ldots + Y_n\\)\n\nExample 6 A dies is about to be rolled 50 times, and each time you will win as many dollars as the number which comes up. Find the probability that you will win a total of at least $200.\n\nSolution\nlet \\(Y_i\\) be the number of dollars you will win on the \\(i\\)-th roll. Then \\(Y_1, Y_2, \\ldots, Y_n \\; \\iid (\\mu, \\sigma^2)\\), where: \\[\\begin{align}\n\\mu & = \\E{Y_i} = 3.5 \\\\\n\\sigma^2 & = \\Var{Y_i} = 2.9167 \\\\\n\\end{align}\\]\nTherefore, \\(\\P{\\sumrv{Y} \\geq 200} \\approx \\P{U &gt; 200}\\), where \\(U \\sim \\NormalDist(50 (3.5), 50(2.9167)) = \\NormalDist(175, 145.83)\\).\nThen \\(\\P{\\dot{Y} \\geq 200} \\approx \\P{Z &gt; \\frac{200 - 175}{\\sqrt{145.83}}} = \\P{Z &gt; 2.07) = 0.0192\\)",
    "crumbs": [
      "Home",
      "chapter-07"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#normal-approximation-to-binomialn-p",
    "href": "contents/chapter-07/index.html#normal-approximation-to-binomialn-p",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "3.2 Normal Approximation to \\(\\Binomial(n, p)\\)",
    "text": "3.2 Normal Approximation to \\(\\Binomial(n, p)\\)\nSuppose that \\(Y \\sim \\Binomial(n, p)\\), then \\(Y = Y_1 + Y_2 + \\ldots + Y_n\\), where \\(Y_1, \\ldots Y_2 \\sim^\\iid \\Bernoulli(p)\\). So \\(Y_1, Y_2, \\ldots, Y_n \\; \\iid (\\mu, \\sigma^2)\\), where: \\[\\begin{gather*}\n\\mu = \\E{Y_i} = p \\\\\n\\sigma^2 = \\Var{Y_i} = p(1 - p) \\\\\n\\end{gather*}\\] It follows by the CLT that \\(Y \\approx \\NormalDist(np, np(1 - p))\\).\n\n\nExample 7 (Normal Approximation (to everything?)) A die is rolled \\(n = 120\\) times. Find the probability that at least 27 sixes come up.\n\nSolution\nLet \\(Y\\) be the number of \\(6\\)‚Äôs. Then \\(U \\triangleq Y \\sim \\Binomial(120, 1/6)\\). So \\(Y \\approx \\NormalDist(120 (1/6), 120 (1/6)(5/6)\\)\nHence, \\[\\begin{align*}\n\\P{Z \\geq 27} & \\approx \\P{U &gt; 27} \\\\\n& = \\P{Z &gt; \\frac{27 - 20}{\\sqrt{16.67}}} = \\P{Z &gt; 1.71} = 0.0436 \\\\\n\\end{align*}\\]\n\n\n3.2.1 The Continuity Correction\nHowever, we need to take a closer look at the approximation made when we are applying to discrete cases. In Figure¬†1 below, the shaded red area is the area calculated as \\(\\P{U &gt; 27}\\) after normal approximation while the blue boxes underlay is the actual binomial distribution probability. Therefore, we can see that almost half of the column for \\(x = 27\\) is missed when we directly use the \\(\\NormalDist\\). Hence, a better approximation would then be \\[\\begin{equation*}\nP(Y \\geq 27) = P(U &gt; 26.5)\n\\end{equation*}\\]\n\n\nShow the code\nlibrary(ggplot2)\n\n# ÂèÉÊï∏Ë®≠ÂÆö\nn &lt;- 120\np &lt;- 1/6\nmu &lt;- n * p\nsigma &lt;- sqrt(n * p * (1 - p))\n\n# x ÂÄº\nx_binom &lt;- 27:40\nx_norm &lt;- seq(26, 40, length.out = 400)\n\n# ÂàÜÂ∏É\nbinom_probs &lt;- dbinom(x_binom, size = n, prob = p)\nnorm_density &lt;- dnorm(x_norm, mean = mu, sd = sigma)\n\n# Ë≥áÊñôÊ°ÜÔºöÊØèÂÄãÈÉΩÂä†‰∏ä 'type' Ê¨Ñ‰Ωç\ndf_binom &lt;- data.frame(x = x_binom, y = binom_probs, type = \"Binomial PMF\")\ndf_norm &lt;- data.frame(x = x_norm, y = norm_density, type = \"Normal PDF\")\ndf_shade &lt;- data.frame(x = x_norm[x_norm &gt;= 27],\n                       y = norm_density[x_norm &gt;= 27],\n                       type = \"Normal Tail\")\n\n# 1. Exact Binomial tail probability: P(Y ‚â• 27)\np_binom &lt;- sum(dbinom(27:n, size = n, prob = p))\n\n# 2. Normal approximation without continuity correction: P(U ‚â• 27)\np_norm_naive &lt;- pnorm(27, mean = mu, sd = sigma, lower.tail = FALSE)\n\n# 3. Normal approximation with continuity correction: P(U ‚â• 26.5)\np_norm_corrected &lt;- pnorm(26.5, mean = mu, sd = sigma, lower.tail = FALSE)\n\n# Print results\n# cat(sprintf(\"Binomial: P(Y ‚â• 27) ‚âà %.5f\\n\", p_binom))\n# cat(sprintf(\"Normal Approx (naive): P(U ‚â• 27) ‚âà %.5f\\n\", p_norm_naive))\n# cat(sprintf(\"Normal Approx (corrected): P(U ‚â• 26.5) ‚âà %.5f\\n\", p_norm_corrected))\n\n# Áï´Âúñ\nggplot() +\n  geom_col(data = df_binom, aes(x = x, y = y, fill = type), color = \"black\", width = 0.9, alpha=0.5) +\n  geom_line(data = df_norm, aes(x = x, y = y, color = type), linewidth = 1.2) +\n  geom_vline(xintercept = 27, linetype = \"dashed\", color = \"black\") +\n  geom_area(data = df_shade, aes(x = x, y = y, fill = type), alpha = 0.95) +\n  annotate(\"text\", x = 27.5, y = max(df_norm$y)*0.9, label = \"x = 27\", hjust = 0, size = 4) +\n  annotate(\"text\", x = 35, y = 0.03,\n           label = sprintf(\"Binomial: P(Y ‚â• 27) ‚âà %.5f\", p_binom),\n           hjust = 0, size = 4) +\n  annotate(\"text\", x = 35, y = 0.026,\n           label = sprintf(\"Normal: P(U ‚â• 27) ‚âà %.5f\", p_norm_naive),\n           hjust = 0, size = 4) +\n  annotate(\"text\", x = 35, y = 0.022,\n           label = sprintf(\"Normal: P(U ‚â• 26.5) ‚âà %.5f\", p_norm_corrected),\n           hjust = 0, size = 4) + \n  scale_fill_manual(\n    name = \"Distribution\",\n    values = c(\n      \"Binomial PMF\" = \"skyblue\",\n      \"Normal Tail\" = \"pink\"\n    )\n  ) +\n  scale_color_manual(\n    name = \"Distribution\",\n    values = c(\n      \"Normal PDF\" = \"red\"\n    )\n  ) +\n  labs(\n    title = \"Binomial (n = 120, p = 1/6) and Normal Approximation\",\n    x = \"x\", y = \"Probability / Density\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nFigure¬†1: Why we need to have continuity correction?\n\n\n\n\n\n\n\nShow the code\n# Parameters\nn &lt;- 120\np &lt;- 1/6\nmu &lt;- n * p\nsigma &lt;- sqrt(n * p * (1 - p))",
    "crumbs": [
      "Home",
      "chapter-07"
    ]
  },
  {
    "objectID": "contents/chapter-07/index.html#footnotes",
    "href": "contents/chapter-07/index.html#footnotes",
    "title": "Sampling Distributions and Central Limit Theorem",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis proof is in reference to this material published by the Duke University which I found on Google somehow. If this material should not be public, please contact me with details here‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "chapter-07"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About This Site",
    "section": "",
    "text": "This website serves as a comprehensive revision resource for students enrolled in STAT2001: Introductory Mathematical Statistics at the Australian National University. It aims to distill complex statistical concepts into digestible summaries and provide practical examples to enhance learning.\n\n\n\n\nTo offer clear and concise summaries of each topic covered in STAT2001.\nTo provide practical examples and exercises that reinforce theoretical concepts.\nTo serve as a supplementary resource alongside official course materials.\n\n\n\n\n\nThis site is created and maintained by a fellow student passionate about statistics and education. The goal is to foster a collaborative learning environment where students can access quality revision materials.\n\n\n\n\nYour feedback is invaluable. If you have suggestions, spot errors, or wish to contribute, please reach out via the contact form on the Contact page.\n\nDisclaimer: This site is independently developed and is not officially endorsed by the Australian National University."
  },
  {
    "objectID": "about.html#purpose",
    "href": "about.html#purpose",
    "title": "About This Site",
    "section": "",
    "text": "To offer clear and concise summaries of each topic covered in STAT2001.\nTo provide practical examples and exercises that reinforce theoretical concepts.\nTo serve as a supplementary resource alongside official course materials."
  },
  {
    "objectID": "about.html#whos-behind-this",
    "href": "about.html#whos-behind-this",
    "title": "About This Site",
    "section": "",
    "text": "This site is created and maintained by a fellow student passionate about statistics and education. The goal is to foster a collaborative learning environment where students can access quality revision materials."
  },
  {
    "objectID": "about.html#feedback-and-contributions",
    "href": "about.html#feedback-and-contributions",
    "title": "About This Site",
    "section": "",
    "text": "Your feedback is invaluable. If you have suggestions, spot errors, or wish to contribute, please reach out via the contact form on the Contact page.\n\nDisclaimer: This site is independently developed and is not officially endorsed by the Australian National University."
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "",
    "text": "As mentioned in the body content of this chapter, we have come to realisation that sum of random variables can actually be captured using the convolution operation quite nicely. Here, let‚Äôs give take a deeper dive into it.\nThis article is based on this article on wayback machine, reimbursed for mordern website.",
    "crumbs": [
      "Home",
      "chapter-07",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#n-fold-sums",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#n-fold-sums",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "3.1 \\(n\\)-fold sums",
    "text": "3.1 \\(n\\)-fold sums\nBecause convolution is associative, the density of \\(\\mathbf S_n=\\sum_{k=1}^{n}\\mathbf X_k\\) (independent, not necessarily identically distributed) is \\[\\begin{equation*}\nf_{\\mathbf S_n}=f_{\\mathbf X_1}f_{\\mathbf X_2}\\cdots*f_{\\mathbf X_n}.\\tag{C.2}\\label{eq:C2}\n\\end{equation*}\\] If all \\(\\mathbf X_k\\) share a common density \\(f\\) we simply write \\(f^{*n}\\) (the \\(n\\)-fold convolution power).",
    "crumbs": [
      "Home",
      "chapter-07",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#characteristic-function-shortcut",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#characteristic-function-shortcut",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "3.2 Characteristic-function shortcut",
    "text": "3.2 Characteristic-function shortcut\nFor any vector \\(\\boldsymbol t\\in\\mathbb R^d\\) the characteristic function is \\[\\begin{equation*}\n\\varphi_{\\mathbf X}(\\boldsymbol t)=\\mathbb E\\bigl[e^{i\\langle\\boldsymbol t,\\mathbf X\\rangle}\\bigr]\n\\end{equation*}\\] Independence gives \\[\\begin{equation*}\n\\varphi_{\\mathbf S_n}(\\boldsymbol t)=\\prod_{k=1}^{n}\\varphi_{\\mathbf X_k}(\\boldsymbol t),\n\\end{equation*}\\] whose inverse Fourier transform reproduces \\(\\eqref{eq:C2}\\). This frequency-space view powers the multivariate Central Limit Theorem and stable-law theory.",
    "crumbs": [
      "Home",
      "chapter-07",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#example-covariance-additivity-of-gaussians",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#example-covariance-additivity-of-gaussians",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "3.3 Example ‚ñ∏ Covariance additivity of Gaussians",
    "text": "3.3 Example ‚ñ∏ Covariance additivity of Gaussians\nIf \\(\\mathbf X_k\\sim\\mathcal N_d(\\boldsymbol\\mu_k,\\Sigma_k)\\) are independent, then by \\(\\eqref{eq:C2}\\) \\[\\begin{equation*}\n\\mathbf S_n\\sim\\mathcal N_d\\Bigl(\\sum_{k=1}^{n}\\boldsymbol\\mu_k\\,,\\;\\sum_{k=1}^{n}\\Sigma_k\\Bigr).\n\\end{equation*}\\] The mean vectors and covariance matrices simply add.",
    "crumbs": [
      "Home",
      "chapter-07",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-07/sums-of-continuous-random-variables.html#further-reading",
    "href": "contents/chapter-07/sums-of-continuous-random-variables.html#further-reading",
    "title": "Sum of Continuous Random Variables [Optional]",
    "section": "3.4 Further reading",
    "text": "3.4 Further reading\n\nP. Billingsley, Probability & Measure, ¬ß17 ‚Äî product measures & convolution.\nG. Folland, Real Analysis, Ch. 8 ‚Äî Fourier transform on \\(\\mathbb R^d\\).\nGnedenko & Kolmogorov, Limit Distributions for Sums ‚Ä¶, Ch. 3 ‚Äî multivariate limits.\nHall, Philip. ‚ÄúThe Distribution of Means for Samples of Size N Drawn from a Population in Which the Variate Takes Values Between 0 and 1, All Such Values Being Equally Probable.‚Äù Biometrika, vol.¬†19, no. 3/4, 1927, pp.¬†240‚Äì45. JSTOR, https://doi.org/10.2307/2331961. Accessed 4 June 2025.\nBates, Grace E. ‚ÄúJoint Distributions of Time Intervals for the Occurrence of Successive Accidents in a Generalized Polya Scheme.‚Äù The Annals of Mathematical Statistics, vol.¬†26, no. 4, 1955, pp.¬†705‚Äì20. JSTOR, http://www.jstor.org/stable/2236383. Accessed 4 June 2025.",
    "crumbs": [
      "Home",
      "chapter-07",
      "Sum of Continuous Random Variables [Optional]"
    ]
  },
  {
    "objectID": "contents/chapter-02/index.html",
    "href": "contents/chapter-02/index.html",
    "title": "CH02: Probability",
    "section": "",
    "text": "1 Probability functions\nFor a given experiement and associated sample space \\(S\\), a probability function \\(P\\) is a real-valued function whose domain is the power set of the sample space, \\(S\\), and satisfies the following:\n\n\\(P(A) \\geq 0\\) for all \\(A \\subset S\\) (probability can‚Äôt be negative)\n\\(P(S) = 1\\) (Something must happen)\nSuppose \\(A_1, A_2, \\ldots\\) is an infinite sequence of disjoint events. Then \\(P(A_1 \\cup A_2 \\cup \\ldots) = P(A_1) + P(A_2) + \\ldots\\)\n\nThese three conditions are known as the three axioms of probabiliyt. They do not completely specify \\(P\\), but merely ensure that \\(P\\) is ‚Äòsensible‚Äô. It remains for \\(P\\) to be precisely defined in any given situation. Typically, \\(P\\) is defined by assigning ‚Äòreasonable‚Äô probabilities to each of the same points (or simple events) in \\(S\\).\n\nIf the die is fair, then all of the possible outcomes 1, 2, 3, 4, 5, 6 are equally likely.\nSo it is reasonable to assign probability function \\(P\\) in case by \\[\nP(\\{1\\}) = P(\\{2\\}) = \\cdots = P(\\{6\\}) = 1 / 6\n\\]\nEquivalently, we may write \\(P(\\{k\\}) = 1/6\\), \\(k=1, \\ldots, 6\\) or \\(P(\\{k\\}) = 1/6 \\; \\forall k = S\\).\n\n\n\nTheorem 1 \\(P(\\emptyset) = 0\\)\n\n\nProof. Apply Axiom 3 with \\(A_i = \\emptyset\\) for all \\(i\\).\n\\(\\emptyset = \\emptyset \\cup \\emptyset \\cup \\ldots\\) Also \\(\\emptyset \\cap \\emptyset = \\emptyset\\) (i.e.¬†\\(\\emptyset\\) and \\(\\emptyset\\) are disjoint). It follows that \\(P(\\emptyset) = P(\\emptyset \\cup \\emptyset \\cup \\ldots) = P(\\emptyset) + P(\\emptyset) + \\cdots\\). We now subtract \\(P(\\emptyset)\\) from both sides. Hence \\(0 = P(\\emptyset) + P(\\emptyset) + \\cdots\\). Therefore, \\(P(\\emptyset) = 0\\).\n\n\n\nTheorem 2 Axiom 3 also holds for finite sequences. Thus if \\(A_1, A_2, \\ldots, A_n\\) are disjoint events, then\n\\[\nP(A_1 \\cup A_2 \\cup \\ldots \\cup A_n) = P(A_1) + P(A_2) + \\cdots + P(A_n)\n\\]\n\n\nProof. Apply Axiom 3 and Theorem¬†1, with \\(A_i = \\emptyset\\) for all \\(i = n + 1, n + 2, \\ldots\\).\n\n\n\nTheorem 3 \\[\nP(\\bar{A}) = 1 - P(A)\n\\]\n\n\nProof. \\[\\begin{align*}\n\n1 & = P(S) \\tag{by Axiom 2} \\\\\n  & = P(A \\cup \\bar{A}) \\tag{by the definition of complementation} \\\\\n  & = P(A) + P(\\bar{A}) \\tag{by Theorem 2 with $n = 2$, since $A$ and $\\bar{A}$ are disjoint.}\n\n\\end{align*}\\]",
    "crumbs": [
      "Home",
      "chapter-02"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html",
    "href": "contents/chapter-03/2measures.html",
    "title": "Measures Related to Distribution",
    "section": "",
    "text": "Now, we want to ask a question about what is the ‚Äúexpected value‚Äù of the outcome of a certain random variable.\n\nDefinition 1 Suppose \\(Y\\) is a discrete random variable with pmf \\(p(y)\\). Then the expected value (or mean) of \\(Y\\) is \\[\n\\mathbb{E}(Y) = \\sum_y y p(y)\n\\]\nThe sum is over all possible values \\(y\\) of the rv \\(Y\\). We may also write \\(Y\\)‚Äôs mean as \\(\\mu_Y\\) or \\(\\mu\\).\n\n\\(\\mu\\) is a measure of central tendency, in the sense that it represents the average of a hypothetically infinite number of independent realisations of \\(Y\\).\n\n\nExample 1 Find the mean of the Bernoulli distribution.\nLet \\(Y \\sim \\text{Bern}(p)\\). Then\n\\[\n\\mu = \\sum_{y=0}^{1} yp(y) = 0p(0) + 1p(1) = 0(1-p) + 1p = p\n\\]\nThus for example, if we toss a fair coin thousands of times, and each time write 1 when a head comes up and 0 otherwise, we will get a sequence like 0,0,1,0,1,1,1,0,‚Ä¶ The average of these 1‚Äôs and 0‚Äôs will be about 1/2, corresponding to the fact that each such number has a Bernoulli distribution with parameter 1/2 and thus a mean of 1/2.\n\n\n\nTheorem 1 If \\(Y \\sim \\text{Bin}(n, p)\\). Then \\(Y\\) has expectation \\(np\\).\n\n\nProof. \\[\\begin{align*}\n\\mu & = \\sum_{y=0}^{n} y \\binom{n}{y} p^y (1- p)^{n-y} \\\\\n& = \\sum_{y=1}^{n} y \\frac{n!}{y! (n-y)!} p^y (1-p)^{n-y} \\tag{the first term is zero} \\\\\n& = np \\sum_{y=1}^{n} \\frac{(n-1)!}{(y-1)!(n-1-(y-1))!}p^{y-1}(1-p)^{n-1-(y-1)} \\\\\n& = np \\sum_{x=0}^{m} \\frac{m!}{x! (m - x)!} p^x (1 - p)^{m-x} \\tag{$x = y - 1$ and $m = n - 1$} \\\\\n& = np \\tag{since the sum equals 1, by the binomial theorem}\n\\end{align*}\\]\nThis makes sense. For example, if we roll a die 60 times, we can expect 60(1/6) = 10 sixes.\n\n\n\n\n\nDefinition 2 Suppose that \\(Y\\) is a discrete random variable with pmf \\(p(y)\\), and \\(g(t)\\) is a function. Then the expected value (or mean) of \\(g(Y)\\) is defined to be \\[\n\\mathbb{E}(g(Y)) = \\sum_y g(y)p(y)\n\\]\n\nHere, we have simply taken this as a definition, so no need for a proof. otherwise, refer to Law of the Unconscious Statistician.\n\n\nExample 2 Suppose that \\(Y \\sim \\text{Bern}(p)\\). Find \\(\\mathbb{E}[Y^2]\\).\n\\[\n\\mathbb{E}\\left[Y^2\\right] = \\sum_y y^2 p(y) = 0^2(1-p) + 1^2p = p\n\\]\n\n\nCorollary 1 It is clear to see that the above procedures can be applied to \\(\\mathbb{E}\\left[Y^k\\right] = p\\).\n\n\n\n\n\n\nIf \\(c\\) is constant, then \\(\\mathbb{E}\\left[c\\right] = c\\)\n\\(\\mathbb{E}\\left[c g(Y) \\right] = c \\mathbb{E}\\left[ g(Y) \\right]\\)\n\\(\\mathbb{E}\\left[ \\sum_{i = 1}^{k} g_i(Y) \\right] = \\sum_{i=1}^k \\mathbb{E}\\left[ g_i(Y) \\right]\\)\n\n\nProof. \\[\n\\mathbb{E}[c] = \\sum_y cp(y) = c \\sum_y p(y) = c \\cdot (1) = c\n\\]\n\n\nProof. \\[\\begin{align*}\n\\mathbb{E}\\left[ cg(Y) \\right] & = \\sum_y cg(y) p(y) \\\\\n& = c \\sum_y g(y) p(y) \\\\\n& = c \\mathbb{E}\\left[ g(Y) \\right] \\\\\n\\end{align*}\\]\n\n\nProof. \\[\n\\mathbb{E} \\left[ \\sum_{i=1}^k g_i(Y) \\right] = \\sum_y \\left( \\sum_{i=1}^k g_i(Y) \\right) p(y) = \\sum_{i=1}^k \\sum_y \\left( g_i(Y) p(Y) \\right) = \\sum_{i=1}^k \\mathbb{E}\\left[g_i(Y)\\right]\n\\]\n\n\n\n\n\nThe \\(k\\)-th raw moment of \\(Y\\) is \\(\\mu_k' = \\mathbb{E}\\left[Y^k\\right]\\)\nThe \\(k\\)-th central moment of \\(Y\\) is $_k = \nThe variance of \\(Y\\) is $(Y) = ^2 = _2 = \nThe standard deviation of \\(Y\\) is simply the square root of variance.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#expectations-of-functions-of-rv",
    "href": "contents/chapter-03/2measures.html#expectations-of-functions-of-rv",
    "title": "Measures Related to Distribution",
    "section": "",
    "text": "Definition 2 Suppose that \\(Y\\) is a discrete random variable with pmf \\(p(y)\\), and \\(g(t)\\) is a function. Then the expected value (or mean) of \\(g(Y)\\) is defined to be \\[\n\\mathbb{E}(g(Y)) = \\sum_y g(y)p(y)\n\\]\n\nHere, we have simply taken this as a definition, so no need for a proof. otherwise, refer to Law of the Unconscious Statistician.\n\n\nExample 2 Suppose that \\(Y \\sim \\text{Bern}(p)\\). Find \\(\\mathbb{E}[Y^2]\\).\n\\[\n\\mathbb{E}\\left[Y^2\\right] = \\sum_y y^2 p(y) = 0^2(1-p) + 1^2p = p\n\\]\n\n\nCorollary 1 It is clear to see that the above procedures can be applied to \\(\\mathbb{E}\\left[Y^k\\right] = p\\).",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#laws-of-expectation",
    "href": "contents/chapter-03/2measures.html#laws-of-expectation",
    "title": "Measures Related to Distribution",
    "section": "",
    "text": "If \\(c\\) is constant, then \\(\\mathbb{E}\\left[c\\right] = c\\)\n\\(\\mathbb{E}\\left[c g(Y) \\right] = c \\mathbb{E}\\left[ g(Y) \\right]\\)\n\\(\\mathbb{E}\\left[ \\sum_{i = 1}^{k} g_i(Y) \\right] = \\sum_{i=1}^k \\mathbb{E}\\left[ g_i(Y) \\right]\\)\n\n\nProof. \\[\n\\mathbb{E}[c] = \\sum_y cp(y) = c \\sum_y p(y) = c \\cdot (1) = c\n\\]\n\n\nProof. \\[\\begin{align*}\n\\mathbb{E}\\left[ cg(Y) \\right] & = \\sum_y cg(y) p(y) \\\\\n& = c \\sum_y g(y) p(y) \\\\\n& = c \\mathbb{E}\\left[ g(Y) \\right] \\\\\n\\end{align*}\\]\n\n\nProof. \\[\n\\mathbb{E} \\left[ \\sum_{i=1}^k g_i(Y) \\right] = \\sum_y \\left( \\sum_{i=1}^k g_i(Y) \\right) p(y) = \\sum_{i=1}^k \\sum_y \\left( g_i(Y) p(Y) \\right) = \\sum_{i=1}^k \\mathbb{E}\\left[g_i(Y)\\right]\n\\]",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#special-expectations",
    "href": "contents/chapter-03/2measures.html#special-expectations",
    "title": "Measures Related to Distribution",
    "section": "",
    "text": "The \\(k\\)-th raw moment of \\(Y\\) is \\(\\mu_k' = \\mathbb{E}\\left[Y^k\\right]\\)\nThe \\(k\\)-th central moment of \\(Y\\) is $_k = \nThe variance of \\(Y\\) is $(Y) = ^2 = _2 = \nThe standard deviation of \\(Y\\) is simply the square root of variance.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#two-important-results",
    "href": "contents/chapter-03/2measures.html#two-important-results",
    "title": "Measures Related to Distribution",
    "section": "2.1 Two Important Results",
    "text": "2.1 Two Important Results\n\n\\(\\text{Var}(Y) = \\mathbb{E}\\left[ Y^2 \\right] - \\left(\\mathbb{E}[Y]\\right)^2\\)\n\\(\\text{Var}(a + bY) = b^2 \\text{Var}(Y)\\)\n\n\nProof. 1:\n\\[\nVar(Y) = E((Y - \\mu)^2) = E(Y^2) - 2\\mu E(Y) + \\mu^2 = E(Y^2) - \\mu^2\n\\]\n2:\n\\[\nVar(a + bY) = E((a + bY - E(a+ bY))^2) = E(b^2(Y - E(Y))^2) = b^2E((Y - \\mu)^2) = b^2 Var(Y)\n\\]",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#two-important-application-of-mgf",
    "href": "contents/chapter-03/2measures.html#two-important-application-of-mgf",
    "title": "Measures Related to Distribution",
    "section": "3.1 Two Important Application of MGF",
    "text": "3.1 Two Important Application of MGF\n\nto compute raw moments, according to the formula: \\[\n\\mu_k' = m^{(k)}(0)\n\\]\nTo uniquely identify distributions.\n\n\nProof. 1:\n\\[\\begin{align*}\nm^{(k)}(t) & = \\frac{d^k}{dt^k} E(e^{Yt}) \\\\\n& = \\frac{d^k}{dt^k} \\left( \\sum_y e^{yt} p(y) \\right) \\\\\n& = \\sum_y y^k e^{(yt)} p(y) \\\\\n\\end{align*}\\]\nThen, evaluating the above at \\(t = 0\\) indicates, \\[\nm^{(k)}(0) = \\sum_y y^k e^0 p(y) = E(Y^k) = \\mu_k'\n\\]\n\nNote that proof of 2. is actually much harder than I expected so the proof is skipped. For interested reader, refer to this.\n\n\nExample 3 Use the mgf technique to find the mean and variance of the binomial distribution.\nLet \\(Y \\sim \\text{Bin}(n, p)\\). Then \\(Y\\) has mgf,\n\\[\\begin{align*}\nm(t) & = E(e^{Yt}) \\\\\n& = \\sum_{y = 0}^n e^{yt} \\binom{n}{y} p^y (1 - p)^{n-y} \\\\\n& = \\sum_{y = 0}^n \\binom{n}{y} (pe^t) (1 - p)^{n - y} \\\\\n& = \\left( (pe^t) + (1 - p) \\right) ^n \\tag{By the binomial theorem.}\n\\end{align*}\\]\nThus, \\(m(t) = (1 - p + pe^t)^n\\).\nThen, \\(m'(t) = \\frac{dm(t)}{dt} = n(1 - p + pe^t)^{n-1}pe^t\\). Then, \\(m''(t) = n(1 - p + pe^t)pe^t + n(n-1)(1 - p + pe^t)^{n-2}p^2e^2t\\). Hence,\n\\[\\begin{align*}\nE(Y) = m'(0) = n (1 - p + p)^{n-1} p e^0 = np \\\\\nm''(0) = np + n(n-1)p^2 \\\\\nVar(Y) = m''(0) - (m'(0))^2 = np + n(n-1)p^2 - (np)^2 = np - np^2 = np(1-p) \\\\\n\\end{align*}\\]\nThis is the same result as we have derived before.\n\n\n\nExample 4 A random variable \\(Y\\) has the mgf \\(m(t) = \\frac{1}{8}(1 + e^t)^3\\). Find the probability that \\(Y\\) equals three.\n\\[\nm(t) = (1 - \\frac{1}{2} + \\frac{1}{2}e^t)^3 = (1 - p + pe^t)^n, \\quad \\text{where $n = 3$ and $p = 1/2$}\n\\]\nThus \\(m(t)\\) is the mgf of a random variable whose distribution is binomial with parameters 3 and \\(1/2\\). Therefore \\(Y \\sim \\text{Bin}(3, 1/2)\\), and so \\(P(Y = 3) = 1/8\\).\n\n\n\n\n\n\n\nSome of my takeaway\n\n\n\nI think it is somewhat important to recognise the known mgf form and transform it whenever a similar question is give in the exam.\n\n\n\n\nTheorem 2 Suppose \\(Y_1, Y_2, \\ldots, Y_n\\) are independent and \\(Y = \\sum_i Y_i\\). Then,\n\\[\nm_Y(t) = m_{Y_1 + Y_2 + \\cdots + Y_n} (t)\n\\]",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#model",
    "href": "contents/chapter-03/2measures.html#model",
    "title": "Measures Related to Distribution",
    "section": "5.1 Model",
    "text": "5.1 Model\nThe mode of a rv \\(Y\\) is any value \\(y\\) at which \\(Y\\)‚Äôs pmg, \\(p(y)\\) is a maximum.\nIt is possible to have multiple modes, and the mode may then also b defined as the set of all such modes.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/2measures.html#median",
    "href": "contents/chapter-03/2measures.html#median",
    "title": "Measures Related to Distribution",
    "section": "5.2 Median",
    "text": "5.2 Median\nThe median of a rv \\(Y\\) is any value \\(y\\) such that \\[\nP(X \\leq Y) \\geq \\frac{1}{2} \\qquad \\text{and} \\qquad P(Y \\geq y) \\geq \\frac{1}{2}\n\\]\nThere may be more than one median, and the median may then also be defined as the set of all such medians.",
    "crumbs": [
      "Home",
      "chapter-03",
      "Measures Related to Distribution"
    ]
  },
  {
    "objectID": "contents/chapter-03/index.html",
    "href": "contents/chapter-03/index.html",
    "title": "CH03: Discrete R.V.",
    "section": "",
    "text": "Definition 1 A random variable (rv) is a numerical variable whose value depends on the outcome of an experiment.\n\nA random variable must be a number; it cannot be a letter, say. More precisely, a random variable is a ‚Äúreal-valued function for which the domain is a sample space‚Äù.\n\nExample 1 A coin is tossed twice and the sequence of \\(H\\)‚Äôs and \\(T\\)‚Äôs is observed. Let \\(Y\\) be the number of \\(H\\)‚Äôs which come up. Show that \\(Y\\) is a random variable. The experiment here has 4 possible outcomes: \\(TT\\), \\(TH\\), \\(HT\\), \\(HH\\).\n\\(Y = 0\\) if the outcome is \\(TT\\)\n\\(Y = 1\\) if the outcome is \\(TH\\) or \\(HT\\)\n\\(Y = 2\\) if the outcome is \\(HH\\)\n\n\n\nThe probability that a discrete random variable \\(Y\\) takes on a particular value \\(y\\) is the sum of the probabilities of all sample points in the sample space \\(S\\) that are associated with \\(y\\).\nWe write this probability \\(P(Y = y)\\).\nThe probability distribution of a discrete random variable \\(Y\\) is any information which provides \\(P(Y = y)\\) for each possible value \\(y\\) of \\(Y\\). This information may take the form of a list, table function (formula) or graph.\n\n\n\nIt is conventional to denote rv‚Äôs by upper case letters (e.g., \\(Y\\), \\(X\\), \\(U\\)) and possible values of those rv‚Äôs by the corrsponding lower case letters (e.g., \\(y\\), \\(x\\), \\(u\\)).\n\\(P(Y = y)\\) is called the probability mass function (pmf) of \\(Y\\) and is often written \\(p(y)\\) or \\(p_Y(y)\\).\n\n\n\n\\(0 \\leq p(y) \\leq 1\\) for all \\(y\\)\n\\(\\sum_y p(y) = 1\\)\n\n\n\nExample 2 A coin is repeatedly tossed until the first head comes up. Let \\(Y\\) be the number of tosses. Derive the pmf of \\(Y\\), and check that it satisfies the two properties of discrete pmf‚Äôs.\nThen \\(Y\\) has pmf, \\[\np(y) = \\left( \\frac{1}{2} \\right)^y\n\\]\nWe should also observe that Property 1 is satisfied, since 1/2, 1/4, 1/8, ‚Ä¶ are all between o and 1. Also,\n\\[\n\\sum_y p(y) = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\cdots = 1\n\\]\nThus Property 2 is also satisfied.\n\\(Y\\) is a discrete rv in this example because \\(\\{1,2,3,\\ldots\\}\\) is a countably infinite set (its elements can be listed). A pmf uniquely defines a rv or pr dsn. Thus a rv can t have 2 or more different pmf‚Äôs. Note that not all functions are valid pmf‚Äôs.",
    "crumbs": [
      "Home",
      "chapter-03"
    ]
  },
  {
    "objectID": "contents/chapter-03/index.html#probability-distribution",
    "href": "contents/chapter-03/index.html#probability-distribution",
    "title": "CH03: Discrete R.V.",
    "section": "",
    "text": "The probability that a discrete random variable \\(Y\\) takes on a particular value \\(y\\) is the sum of the probabilities of all sample points in the sample space \\(S\\) that are associated with \\(y\\).\nWe write this probability \\(P(Y = y)\\).\nThe probability distribution of a discrete random variable \\(Y\\) is any information which provides \\(P(Y = y)\\) for each possible value \\(y\\) of \\(Y\\). This information may take the form of a list, table function (formula) or graph.",
    "crumbs": [
      "Home",
      "chapter-03"
    ]
  },
  {
    "objectID": "contents/chapter-03/index.html#probability-mass-function",
    "href": "contents/chapter-03/index.html#probability-mass-function",
    "title": "CH03: Discrete R.V.",
    "section": "",
    "text": "It is conventional to denote rv‚Äôs by upper case letters (e.g., \\(Y\\), \\(X\\), \\(U\\)) and possible values of those rv‚Äôs by the corrsponding lower case letters (e.g., \\(y\\), \\(x\\), \\(u\\)).\n\\(P(Y = y)\\) is called the probability mass function (pmf) of \\(Y\\) and is often written \\(p(y)\\) or \\(p_Y(y)\\).\n\n\n\n\\(0 \\leq p(y) \\leq 1\\) for all \\(y\\)\n\\(\\sum_y p(y) = 1\\)\n\n\n\nExample 2 A coin is repeatedly tossed until the first head comes up. Let \\(Y\\) be the number of tosses. Derive the pmf of \\(Y\\), and check that it satisfies the two properties of discrete pmf‚Äôs.\nThen \\(Y\\) has pmf, \\[\np(y) = \\left( \\frac{1}{2} \\right)^y\n\\]\nWe should also observe that Property 1 is satisfied, since 1/2, 1/4, 1/8, ‚Ä¶ are all between o and 1. Also,\n\\[\n\\sum_y p(y) = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} + \\cdots = 1\n\\]\nThus Property 2 is also satisfied.\n\\(Y\\) is a discrete rv in this example because \\(\\{1,2,3,\\ldots\\}\\) is a countably infinite set (its elements can be listed). A pmf uniquely defines a rv or pr dsn. Thus a rv can t have 2 or more different pmf‚Äôs. Note that not all functions are valid pmf‚Äôs.",
    "crumbs": [
      "Home",
      "chapter-03"
    ]
  },
  {
    "objectID": "contents/chapter-05/index.html",
    "href": "contents/chapter-05/index.html",
    "title": "CH05: Multivariate Distributions",
    "section": "",
    "text": "1 Learning Goals\n\nMore than one random variable\nJoint PMF/PDF or CDF\nBoth Discrete and Continuous\nExpectations, Variance, etc.",
    "crumbs": [
      "Home",
      "chapter-05"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html",
    "href": "contents/chapter-04/2measures.html",
    "title": "Expectations",
    "section": "",
    "text": "As foreshadowed in previous discrete section, it is natural to believe that most of the results can be directly imported. (Otherwise, we wouldn‚Äôt have spend so much time.)",
    "crumbs": [
      "Home",
      "chapter-04",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html#results",
    "href": "contents/chapter-04/2measures.html#results",
    "title": "Expectations",
    "section": "1.1 Results",
    "text": "1.1 Results\n\nI will try my best to include all the proofs for the results here. However, these proofs are done by me likely to contain relatively high amounts of mistakes.\n\n\nTheorem 1 (Three Properties) For \\(c \\in \\mathbb{R}\\), and \\(Y\\) continuous r.v.\n\n\\(E(c) = c\\)\n\\(E(cg(Y)) = cE(g(Y))\\)\n\\(E(g_1(Y) + \\cdots + g_k(Y)) = \\sum_{i=1}^k E(g_i(Y))\\)\n\n\n\nProof. \n\n\n\n\\[\\begin{align*}\nE(c) &= \\int_{-\\infty}^\\infty c f(y) \\, dy \\\\\n&= c \\int_{-\\infty}^\\infty f(y) \\, dy \\\\\n&= c\n\\end{align*}\\]\nThe last step is a result of the fact that the pdf also integrate to 1 by definition.\n\n\nProof. \n\n\n\n\\[\\begin{align*}\nE(cg(Y)) &= \\int_{-\\infty}^\\infty c g(y) f(y) \\, dy \\\\\n&= c \\int_{-\\infty}^\\infty g(y)f(y) \\, dy \\\\\n&= c E(g(Y))\n\\end{align*}\\]\n\n\nProof. \n\n\n\n\\[\\begin{align*}\nE(\\sum_{i=1}^k g_i(Y)) &= \\int_{-\\infty}^\\infty \\left( \\sum_{i=1}^k g_i(y) f(y) \\right) \\, dy \\\\\n&= \\sum_{i = 1}^k \\left( \\int_{-\\infty}^\\infty g_i(y) f(y) \\, dy \\right) \\\\\n& = \\sum_{i=1}^k E(g_i(Y)) \\\\\n\\end{align*}\\]\nThe second line is by linearity of the integration operation.\n\n\nAs I have mentioned when we were proving the discrete version of the Chebyshev‚Äôs Theorem, there is a continuous version that is exactly the same. Now, here is the statement and the proof.\n\nTheorem 2 (Continuous Version of Chebyshev‚Äôs) If \\(Y\\) is continuous r.v., then \\[\nP(\\lvert Y - \\mu \\rvert &lt; k\\sigma) \\geq 1 - 1 / k^2\n\\]\n\n\nProof. \\[\\begin{align*}\n\\sigma^2 & = \\int_{-\\infty}^\\infty (Y - \\mu)^2 f(y) \\, dy \\\\\n& = \\int_{-\\infty}^{k\\sigma - \\mu} (y - \\mu)^2f(y) \\, dy + \\int_{k\\sigma + \\mu}^\\infty (y - \\mu)^2 f(y) \\, dy \\\\\n& = \\int_{-\\infty}^{k\\sigma - \\mu} (k\\sigma)^2 f(y) \\, dy + \\int_{k\\sigma + \\mu}^\\infty (k\\sigma)^2 f(y) \\, dy \\\\\n& = (k\\sigma)^2 \\left( \\int_{-\\infty}^{k - \\mu} f(y) \\, dy + \\int_{k + \\mu}^\\infty f(y) \\, dy \\right) \\\\\n& = (k\\sigma)^2 P(Y \\leq k\\sigma - \\mu \\cup Y \\geq k\\sigma + \\mu) \\\\\n& = (k\\sigma)^2 P(\\lvert Y - \\mu \\rvert \\leq k\\sigma)\n\\end{align*}\\]\nTherefore,\n\\[\nP(\\lvert Y - \\mu \\rvert \\leq k\\sigma) \\leq 1 / k^2\n\\]\nTherefore, obtaining the following,\n\\[\nP\\left(\\lvert Y - \\mu \\rvert &gt; k \\sigma \\right) &gt; 1 - \\frac{1}{k^2}\n\\]",
    "crumbs": [
      "Home",
      "chapter-04",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html#working-examples",
    "href": "contents/chapter-04/2measures.html#working-examples",
    "title": "Expectations",
    "section": "1.2 Working Examples",
    "text": "1.2 Working Examples\n\nExample 1 Find the mean and variance of the standard uniform distribution\nSuppose that \\(Y \\sim U(0, 1)\\). Then \\(Y\\) has pdf \\(f(y) = 1\\), \\(0 &lt; y &lt; 1\\). Therefore, \\[\n\\mu = \\int_0^1 yf(y) dy = \\int_0^1 y 1 dy = \\left[ \\frac{y^2}{2} \\middle\\vert _{y=0}^1 \\right] = \\frac{1}{2}\n\\]\nAlso, \\[\n\\mu_2' = \\int_0^1 y^2 1 \\, dy = \\left[ \\frac{y^3}{3} \\middle\\vert _{y=0}^1 \\right] = \\frac{1}{3}\n\\]\nTherefore, \\[\n\\sigma^2 = \\frac{1}{3} \\left( \\frac{1}{2} \\right)^2 = \\frac{1}{12}\n\\]\nNote: We could use the mgf method here, but it is problematic in this case. This is because, \\[\nm(t) = \\frac{e^t - 1}{t} \\implies m'(t) = \\frac{e^t(t - 1) + 1}{t^2}\n\\] , which is undefined at \\(t = 0\\). So use L‚ÄôHopital‚Äôs rule (twice) to get \\[\n\\mu = \\lim_{t \\to 0} m'(t) = \\lim_{t \\to 0} \\frac{\\frac{d}{dt}(e^t(t-1) + 1)}{\\frac{d}{dt} t^2} = \\lim_{t \\to 0} \\frac{t e^t}{2t} = \\lim_{t \\to 0} \\frac{\\frac{d}{dt} (t e^t)}{\\frac{d}{dt} (2t)} = \\lim_{t \\to 0} \\frac{e^t(t+1)}{2} = \\frac{1}{2}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think the evaluation can be simpler by using the following\n\\[\n\\mu = \\lim_{t \\to 0} m'(t) = \\lim_{t \\to 0} \\frac{\\frac{d}{dt}(e^t(t-1) + 1)}{\\frac{d}{dt} t^2} = \\lim_{t \\to 0} \\frac{t e^t}{2t} = \\lim_{t \\to 0} \\frac{e^t}{2} = \\frac{1}{2}\n\\]\n\n\n\n\n\n\nExample 2 Find the mean and variance of the exponential distribution.\nIn this case the mgf method works well1.\nBy using the mgf of exponential distribution, we have \\[\nm'(t) = - (1 - bt)^{-2} (-b) = b(1 - bt)^{-2}\n\\]\nAnd \\[\nm''(t) = (-2) b(1-bt)^{-3} (-b) = 2b^2(1- bt)^{-3}\n\\]\nTherefore, \\(\\mu_1' = m'(0) = b\\) and \\(\\mu_2' = m''(0) = 2b^2\\). Hence, variance is \\(2b^2 - b^2 = b^2\\).\n\n\n\n\n\n\n\nAlternative Methods\n\n\n\nNote that it is possible to directly use integration by part to obtain the result, but it is clearly much more tedious.",
    "crumbs": [
      "Home",
      "chapter-04",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/2measures.html#footnotes",
    "href": "contents/chapter-04/2measures.html#footnotes",
    "title": "Expectations",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that we did not really find the mgf before. Therefore, refer to Theorem¬†4 for the proof.‚Ü©Ô∏é",
    "crumbs": [
      "Home",
      "chapter-04",
      "Expectations"
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html",
    "href": "contents/chapter-04/index.html",
    "title": "CH04: Continuous R.V.",
    "section": "",
    "text": "Note that we will follow a very similar structure as we have done in the chapter for discrete variable. And, indeed, a lot of the theorems can be directly transported to the continuous case. However, analysis of the continuous variables are slightly harder since, as one might expect, all the summation no becomes integral.\nThis chapter will first goes from the definition of continuous random variable with link established via the cumulative distribution functions. Then, we will go over some of the common continuous distributions.",
    "crumbs": [
      "Home",
      "chapter-04"
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html#two-properties-of-a-continuous-pdf",
    "href": "contents/chapter-04/index.html#two-properties-of-a-continuous-pdf",
    "title": "CH04: Continuous R.V.",
    "section": "4.1 Two Properties of a Continuous pdf",
    "text": "4.1 Two Properties of a Continuous pdf\n\nTheorem 2 (Two Properties of a Continuous PDF) If \\(f(y)\\) is the pdf of a continuous random variable then:\n\n\\(f(y) \\geq 0\\) for all \\(y\\)\n\\(\\int f(y) \\, dy = 1\\) (By default, the integral is over the whole real line.)",
    "crumbs": [
      "Home",
      "chapter-04"
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html#cdf-from-pdf",
    "href": "contents/chapter-04/index.html#cdf-from-pdf",
    "title": "CH04: Continuous R.V.",
    "section": "4.2 CDF from PDF",
    "text": "4.2 CDF from PDF\nIn general, the cdf \\(F(y)\\) of a continuous random variable \\(Y\\) can be obtained from its pdf \\(f(y)\\) via the equation\n\\[\nF(y) = \\int_{-\\infty}^{y} f(t) \\, dt\n\\]",
    "crumbs": [
      "Home",
      "chapter-04"
    ]
  },
  {
    "objectID": "contents/chapter-04/index.html#computing-probability-using-pdf",
    "href": "contents/chapter-04/index.html#computing-probability-using-pdf",
    "title": "CH04: Continuous R.V.",
    "section": "4.3 Computing Probability using PDF",
    "text": "4.3 Computing Probability using PDF\nIn general, to compute the probability of a given range for a continuous random variable, we can use\n\\[\nP(a &lt; Y &lt; b) = \\int_a^b f(y) \\, dy\n\\]",
    "crumbs": [
      "Home",
      "chapter-04"
    ]
  },
  {
    "objectID": "topics.html",
    "href": "topics.html",
    "title": "STAT2001 Weekly Topics",
    "section": "",
    "text": "This page summarizes the weekly structure of STAT2001: Introductory Mathematical Statistics, including chapter coverage and additional notes. Use this as a guide to plan your revision and track key assessments and resources.\n\n\nWeekly Study Plan\n\n\n\n\n\n\n\nWeek\nTopic\nExtra Information\n\n\n\n\n1\nCH1 Statistics; CH2 Probability\nCalculus notes\n\n\n2\nCH2 Probability\nRefresher Quiz 1, Refresher Quiz 2 on combinatorics\n\n\n3\nCH2 Probability\n\n\n\n4\nCH3 Discrete Random Variables\nMakeup Tue 11/3, Formula sheet, Binomial distribution\n\n\n5\nCH4 Continuous Random Variables\nAssessable Quiz due Fri 21/3, Gamma distribution, R and random variables\n\n\n6\nCH5 Multivariate Probability\nAssignment 1 available\n\n\n‚Äî\nTeaching Break\n\n\n\n7\nCH6 Functions of Random Variables\nAssignment 1 due\n\n\n8\nCH7 Sampling Distributions & CLT\nMakeup Tue 22/4\n\n\n9*\nCH8 Estimation\nAssignment 2 available\n\n\n10\nCH9 Point Estimation\n\n\n\n11\nCH16 Bayesian Methods; CH10\nAssignment 2 due\n\n\n12\nCH10 Hypothesis Testing\nNon-exhaustive summary\n\n\n\n\n\n\n\nChapters refer to the textbook used in the course (check Wattle or course outline for details).\nMakeups and assignments are based on 2025 dates; confirm current year‚Äôs schedule on Wattle.\nThis schedule is intended for student revision and is not officially endorsed by ANU."
  },
  {
    "objectID": "topics.html#notes",
    "href": "topics.html#notes",
    "title": "STAT2001 Weekly Topics",
    "section": "",
    "text": "Chapters refer to the textbook used in the course (check Wattle or course outline for details).\nMakeups and assignments are based on 2025 dates; confirm current year‚Äôs schedule on Wattle.\nThis schedule is intended for student revision and is not officially endorsed by ANU."
  }
]